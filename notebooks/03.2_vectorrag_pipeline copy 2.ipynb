{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec0bd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Append retrievers to the Python path (not just src)\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "\n",
    "# Import pipeline components\n",
    "from retrievers.vectorrag.index_faiss import build_faiss_index_from_json\n",
    "from retrievers.vectorrag.document_loader import load_json_documents\n",
    "from retrievers.vectorrag.chunker import chunk_documents\n",
    "from retrievers.vectorrag.embedder import init_embedder\n",
    "from retrievers.vectorrag.index_faiss import build_faiss_index, load_faiss_index\n",
    "from retrievers.vectorrag.retriever import rerank_search\n",
    "\n",
    "from generator.generator import ChatGPTGenerator \n",
    "import numpy as np\n",
    "import json\n",
    "from retrievers.vectorrag.reranker import CrossEncoderReranker\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c969bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10130 documents\n",
      "{\n",
      "  \"chunk_id\": \"row_0_chunk_0\",\n",
      "  \"text\": \"Cboe Global Markets, Inc. and Subsidiaries\\n\\nConsolidated Statements of Income\\n\\nYears ended December 31, 2023, 2022, and 2021\\n\\n(In millions, except per share data)\\n\\n\\n    \\n\\n2023\\n\\n    \\n\\n2022\\n\\n    \\n\\n2021\\n\\n \\n\\nRevenues:\\n\\nCash and spot markets\\n\\n\\n$\\n\\n1,445.1\\n\\n\\n$\\n\\n1,777.6\\n\\n\\n$\\n\\n1,660.5\\n\\n\\nData and access solutions\\n\\n539.2\\n\\n497.0\\n\\n427.7\\n\\n\\nDerivatives markets\\n\\n\\n \\n\\n1,789.2\\n\\n\\n \\n\\n1,683.9\\n\\n\\n \\n\\n1,406.6\\n\\n\\nTotal revenues\\n\\n\\n \\n\\n3,773.5\\n\\n\\n \\n\\n3,958.5\\n\\n\\n \\n\\n3,494.8\\n\\n\\nCost of revenues:\\n\\n  Liquidity payments\\n\\n\\n \\n\\n1,385.8\\n\\n\\n \\n\\n1,670.2\\n\\n\\n \\n\\n1,650.7\\n\\n\\n  Routing and clearing\\n\\n79.1\\n\\n83.2\\n\\n87.8\\n\\n\\n  Section 31 fees\\n\\n185.7\\n\\n329.8\\n\\n179.6\\n\\n\\n  Royalty fees and other cost of revenues\\n\\n\\n \\n\\n204.9\\n\\n\\n \\n\\n133.6\\n\\n\\n \\n\\n100.6\\n\\n\\nTotal cost of revenues\\n\\n\\n \\n\\n1,855.5\\n\\n\\n \\n\\n2,216.8\\n\\n\\n \\n\\n2,018.7\\n\\n\\nRevenues less cost of revenues\\n\\n\\n \\n\\n1,918.0\\n\\n\\n \\n\\n1,741.7\\n\\n\\n \\n\\n1,476.1\\n\\n\\nOperating expenses:\\n\\n  Compensation and benefits\\n\\n\\n \\n\\n425.8\\n\\n\\n \\n\\n363.0\\n\\n\\n \\n\\n288.5\\n\\n\\n  Depreciation and amortization\\n\\n\\n \\n\\n158.0\\n\\n\\n \\n\\n166.8\\n\\n\\n \\n\\n167.4\\n\\n\\n  Technology support services\\n\\n\\n \\n\\n99.7\\n\\n\\n \\n\\n77.7\\n\\n\\n \\n\\n66.7\\n\\n\\n  Professional fees and outside services\\n\\n\\n \\n\\n92.0\\n\\n\\n \\n\\n89.0\\n\\n\\n \\n\\n83.7\\n\\n\\n  Travel and promotional expenses\\n\\n\\n \\n\\n37.6\\n\\n\\n \\n\\n23.7\\n\\n\\n \\n\\n9.7\\n\\n\\n  Facilities costs\\n\\n\\n \\n\\n25.7\\n\\n\\n \\n\\n25.1\\n\\n\\n \\n\\n22.2\\n\\n\\n  Acquisition-related costs\\n\\n\\n \\n\\n7.4\\n\\n\\n \\n\\n19.9\\n\\n\\n \\n\\n15.6\\n\\n\\n  Goodwill impairment\\n\\n\\u2014\\n\\n460.9\\n\\n\\u2014\\n\\n\\n  Other expenses\\n\\n13.9\\n\\n26.0\\n\\n16.4\\n\\n\\nTotal operating expenses\\n\\n\\n \\n\\n860.1\\n\\n\\n \\n\\n1,252.1\\n\\n\\n \\n\\n670.2\\n\\n\\nOperating income\\n\\n\\n \\n\\n1,057.9\\n\\n\\n \\n\\n489.6\\n\\n\\n \\n\\n805.9\",\n",
      "  \"source\": \"Finder\",\n",
      "  \"source_id\": \"b33fcee7\",\n",
      "  \"ticker\": null,\n",
      "  \"year\": null,\n",
      "  \"page\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load enriched corpus\n",
    "path = \"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/existing_embeddings_with_meta_data.jsonl\"\n",
    "docs = []\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            docs.append(json.loads(line))\n",
    "\n",
    "# Quick check\n",
    "print(f\"Loaded {len(docs)} documents\")\n",
    "print(json.dumps(docs[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c005ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ embedded_chunks.json\n",
      "Type: <class 'list'>\n",
      "Loaded 10130 entries\n",
      "Sample entry:\n",
      "{\n",
      "  \"chunk_id\": \"row_0_chunk_0\",\n",
      "  \"row_index\": 0,\n",
      "  \"text\": \"Cboe Global Markets, Inc. and Subsidiaries\\n\\nConsolidated Statements of Income\\n\\nYears ended December 31, 2023, 2022, and 2021\\n\\n(In millions, except per share data)\\n\\n\\n    \\n\\n2023\\n\\n    \\n\\n2022\\n\\n    \\n\\n2021\\n\\n \\n\\nRevenues:\\n\\nCash and spot markets\\n\\n\\n$\\n\\n1,445.1\\n\\n\\n$\\n\\n1,777.6\\n\\n\\n$\\n\\n1,660.5\\n\\n\\nData and access solutions\\n\\n539.2\\n\\n497.0\\n\\n427.7\\n\\n\\nDerivatives markets\\n\\n\\n \\n\\n1,789.2\\n\\n\\n \\n\\n1,683.9\\n\\n\\n \\n\\n1,406.6\\n\\n\\nTotal revenues\\n\\n\\n \\n\\n3,773.5\\n\\n\\n \\n\\n3,958.5\\n\\n\\n \\n\\n3,494.8\\n\\n\\nCost of revenues:\\n\\n  Liquidity payments\\n\\n\\n \\n\\n1,385.8\\n\\n\\n \\n\\n1,670.2\\n\\n\\n \\n\\n1,650.7\\n\\n\\n  Routing and clearing\\n\\n79.1\\n\\n83.2\\n\\n87.8\\n\\n\\n  Section 31 fees\\n\\n185.7\\n\\n329.8\\n\\n179.6\\n\\n\\n  Royalty fees and other cost of revenues\\n\\n\\n \\n\\n204.9\\n\\n\\n \\n\\n133.6\\n\\n\\n \\n\\n100.6\\n\\n\\nTotal cost of revenues\\n\\n\\n \\n\\n1,855.5\\n\\n\\n \\n\\n2,216.8\\n\\n\\n \\n\\n2,018.7\\n\\n\\nRevenues less cost of revenues\\n\\n\\n \\n\\n1,918.0\\n\\n\\n \\n\\n1,741.7\\n\\n\\n \\n\\n1,476.1\\n\\n\\nOperating expenses:\\n\\n  Compensation and benefits\\n\\n\\n \\n\\n425.8\\n\\n\\n \\n\\n363.0\\n\\n\\n \\n\\n288.5\\n\\n\\n  Depreciation and amortization\\n\\n\\n \\n\\n158.0\\n\\n\\n \\n\\n166.8\\n\\n\\n \\n\\n167.4\\n\\n\\n  Technology support services\\n\\n\\n \\n\\n99.7\\n\\n\\n \\n\\n77.7\\n\\n\\n \\n\\n66.7\\n\\n\\n  Professional fees and outside services\\n\\n\\n \\n\\n92.0\\n\\n\\n \\n\\n89.0\\n\\n\\n \\n\\n83.7\\n\\n\\n  Travel and promotional expenses\\n\\n\\n \\n\\n37.6\\n\\n\\n \\n\\n23.7\\n\\n\\n \\n\\n9.7\\n\\n\\n  Facilities costs\\n\\n\\n \\n\\n25.7\\n\\n\\n \\n\\n25.1\\n\\n\\n \\n\\n22.2\\n\\n\\n  Acquisition-related costs\\n\\n\\n \\n\\n7.4\\n\\n\\n \\n\\n19.9\\n\\n\\n \\n\\n15.6\\n\\n\\n  Goodwill impairment\\n\\n\\u2014\\n\\n460.9\\n\\n\\u2014\\n\\n\\n  Other expenses\\n\\n13.9\\n\\n26.0\\n\\n16.4\\n\\n\\nTotal operating expenses\\n\\n\\n \\n\\n860.1\\n\\n\\n \\n\\n1,252.1\\n\\n\\n \\n\\n670.2\\n\\n\\nOperating income\\n\\n\\n \\n\\n1,057.9\\n\\n\\n \\n\\n489.6\\n\\n\\n \\n\\n805.9\",\n",
      "  \"embedding\": [\n",
      "    -0.017099883407354355,\n",
      "    -0.029146641492843628,\n",
      "    -0.007286660373210907,\n",
      "    -0.0010003692004829645,\n",
      "    -0.013238409534096718,\n",
      "    0.012287692166864872,\n",
      "    -0.013231897726655006,\n",
      "    -0.009077394381165504,\n",
      "    -0.017178025096654892,\n",
      "    -0.02703683078289032,\n",
      "    0.03604910895228386,\n",
      "    0.023624667897820473,\n",
      "    0.0021912073716521263,\n",
      "    -0.006345710717141628,\n",
      "    0.0016865460202097893,\n",
      "    0.03630957752466202,\n",
      "    0.01270444504916668,\n",
      "    -0.03050108626484871,\n",
      "    0.00539499381557107,\n",
      "    -0.00564569653943181,\n",
      "    -0.015458920039236546,\n",
      "    0.024445150047540665,\n",
      "    -0.031022027134895325,\n",
      "    -0.015836602076888084,\n",
      "    0.02771405316889286,\n",
      "    -0.004382414743304253,\n",
      "    0.009357400238513947,\n",
      "    0.0015327056171372533,\n",
      "    0.029980145394802094,\n",
      "    -0.0009450192446820438,\n",
      "    -0.004724282305687666,\n",
      "    0.01950923539698124,\n",
      "    -0.009793688543140888,\n",
      "    0.019925987347960472,\n",
      "    -0.016240330412983894,\n",
      "    -0.029797816649079323,\n",
      "    -0.0005075103254057467,\n",
      "    -0.0045777675695717335,\n",
      "    0.003221693681553006,\n",
      "    0.00927925854921341,\n",
      "    0.012984450906515121,\n",
      "    0.0077099245972931385,\n",
      "    -0.016683131456375122,\n",
      "    0.006251290440559387,\n",
      "    -0.001730500371195376,\n",
      "    0.025838665664196014,\n",
      "    0.006850372068583965,\n",
      "    -0.012567698024213314,\n",
      "    -0.008185283280909061,\n",
      "    0.013153756968677044,\n",
      "    -0.004594047088176012,\n",
      "    0.039851974695920944,\n",
      "    -0.02234836295247078,\n",
      "    -0.020199481397867203,\n",
      "    0.02397630363702774,\n",
      "    0.00824388861656189,\n",
      "    0.013010498136281967,\n",
      "    0.015524037182331085,\n",
      "    -0.014833791181445122,\n",
      "    -0.02117624506354332,\n",
      "    0.0137398149818182,\n",
      "    0.005945237353444099,\n",
      "    -0.013752838596701622,\n",
      "    0.0055154613219201565,\n",
      "    -0.0431859977543354,\n",
      "    -0.025356795638799667,\n",
      "    -0.004753585439175367,\n",
      "    0.002891221782192588,\n",
      "    0.003418674459680915,\n",
      "    -0.00219609122723341,\n",
      "    0.028469417244195938,\n",
      "    0.015797531232237816,\n",
      "    -0.011506280861794949,\n",
      "    -0.006534551735967398,\n",
      "    0.01040579378604889,\n",
      "    -0.01739942468702793,\n",
      "    -0.009461588226258755,\n",
      "    0.007937836460769176,\n",
      "    0.01009322889149189,\n",
      "    -0.007664342410862446,\n",
      "    0.019717611372470856,\n",
      "    0.010659752413630486,\n",
      "    -0.010132299736142159,\n",
      "    0.010158346965909004,\n",
      "    0.016735225915908813,\n",
      "    2.5958015612559393e-05,\n",
      "    0.013192826882004738,\n",
      "    0.03698680177330971,\n",
      "    -0.029355017468333244,\n",
      "    0.008322030305862427,\n",
      "    0.026802407577633858,\n",
      "    0.01676127128303051,\n",
      "    0.003688912373036146,\n",
      "    0.0137398149818182,\n",
      "    -0.008543429896235466,\n",
      "    0.017503613606095314,\n",
      "    -0.051755473017692566,\n",
      "    0.02505725435912609,\n",
      "    -0.02148880995810032,\n",
      "    -0.016149166971445084,\n",
      "    0.000799725588876754,\n",
      "    -0.019522259011864662,\n",
      "    -0.01067928783595562,\n",
      "    -0.010939758270978928,\n",
      "    -0.027870336547493935,\n",
      "    0.006361990235745907,\n",
      "    -0.0014496807707473636,\n",
      "    -9.187687101075426e-05,\n",
      "    0.008029000833630562,\n",
      "    0.0006992003181949258,\n",
      "    -0.001483867526985705,\n",
      "    -0.007013166323304176,\n",
      "    0.003506583161652088,\n",
      "    -0.014390991069376469,\n",
      "    0.027323348447680473,\n",
      "    -0.01815478876233101,\n",
      "    0.0049228910356760025,\n",
      "    0.0006784440483897924,\n",
      "    -0.0028977335896342993,\n",
      "    -0.028443370014429092,\n",
      "    -0.0006279779481701553,\n",
      "    0.019769705832004547,\n",
      "    0.026476819068193436,\n",
      "    -0.030657369643449783,\n",
      "    0.01595381461083889,\n",
      "    -0.025565171614289284,\n",
      "    -0.011577910743653774,\n",
      "    -0.024705620482563972,\n",
      "    0.011936057358980179,\n",
      "    0.00211306638084352,\n",
      "    0.024041419848799706,\n",
      "    0.01325143314898014,\n",
      "    0.016774294897913933,\n",
      "    0.01308863889425993,\n",
      "    -0.008263424038887024,\n",
      "    0.017868271097540855,\n",
      "    0.003184251021593809,\n",
      "    0.03604910895228386,\n",
      "    -0.019392022863030434,\n",
      "    -0.02613820694386959,\n",
      "    -0.005847561173141003,\n",
      "    0.005870352499186993,\n",
      "    0.00577918766066432,\n",
      "    0.004056826699525118,\n",
      "    0.013752838596701622,\n",
      "    0.026698218658566475,\n",
      "    0.012450486421585083,\n",
      "    0.009383447468280792,\n",
      "    0.015237520448863506,\n",
      "    -0.02789638191461563,\n",
      "    0.012834680266678333,\n",
      "    -0.021553928032517433,\n",
      "    -0.011460699141025543,\n",
      "    0.016735225915908813,\n",
      "    0.04063338786363602,\n",
      "    -0.015029143542051315,\n",
      "    0.014612390659749508,\n",
      "    0.04013849422335625,\n",
      "    0.001676778425462544,\n",
      "    -0.014065403491258621,\n",
      "    -0.007006654515862465,\n",
      "    0.02324698492884636,\n",
      "    -0.010327652096748352,\n",
      "    0.026880547404289246,\n",
      "    -0.0010671147610992193,\n",
      "    0.002170044230297208,\n",
      "    0.0006519900634884834,\n",
      "    0.000542511057574302,\n",
      "    -0.016005907207727432,\n",
      "    -0.010816034860908985,\n",
      "    -0.0023556293454021215,\n",
      "    -0.016474755480885506,\n",
      "    -0.0026747058145701885,\n",
      "    0.013283992186188698,\n",
      "    -0.02505725435912609,\n",
      "    0.03956545889377594,\n",
      "    0.013003986328840256,\n",
      "    0.004050315357744694,\n",
      "    -0.0305531807243824,\n",
      "    -0.02212696336209774,\n",
      "    0.008107142522931099,\n",
      "    0.012815144844353199,\n",
      "    0.016331495717167854,\n",
      "    0.020472975447773933,\n",
      "    0.008745294995605946,\n",
      "    -0.003395883133634925,\n",
      "    0.02329907938838005,\n",
      "    -0.018623635172843933,\n",
      "    -0.0015961953904479742,\n",
      "    -0.025174466893076897,\n",
      "    0.010457887314260006,\n",
      "    0.018727824091911316,\n",
      "    0.014729602262377739,\n",
      "    -0.0033275096211582422,\n",
      "    -0.6130431890487671,\n",
      "    0.004831726662814617,\n",
      "    -0.009468100033700466,\n",
      "    -0.020577164366841316,\n",
      "    0.012535138987004757,\n",
      "    0.012105363421142101,\n",
      "    0.025708431378006935,\n",
      "    0.0022791163064539433,\n",
      "    -0.04407159611582756,\n",
      "    -0.0026665660552680492,\n",
      "    -0.0002981165307573974,\n",
      "    0.017646871507167816,\n",
      "    0.010106252506375313,\n",
      "    -0.03289741650223732,\n",
      "    -0.0035033272579312325,\n",
      "    -0.029849911108613014,\n",
      "    -0.011740704998373985,\n",
      "    0.00028163366368971765,\n",
      "    -0.02225719764828682,\n",
      "    0.022322315722703934,\n",
      "    0.006052681710571051,\n",
      "    -0.011421628296375275,\n",
      "    0.007553642615675926,\n",
      "    0.022908374667167664,\n",
      "    0.016930578276515007,\n",
      "    0.010470910929143429,\n",
      "    0.02135857567191124,\n",
      "    -0.06876419484615326,\n",
      "    0.010373234748840332,\n",
      "    -0.00528429402038455,\n",
      "    -0.016839412972331047,\n",
      "    0.005124755669385195,\n",
      "    0.04912472143769264,\n",
      "    -0.008380635641515255,\n",
      "    0.030266663059592247,\n",
      "    0.0026258674915879965,\n",
      "    -0.01351841539144516,\n",
      "    0.008061559870839119,\n",
      "    0.025265632197260857,\n",
      "    0.05178152024745941,\n",
      "    -0.040581293404102325,\n",
      "    -0.008934135548770428,\n",
      "    -0.0014504947466775775,\n",
      "    0.007026189938187599,\n",
      "    -0.007742483634501696,\n",
      "    0.03401743620634079,\n",
      "    0.043238092213869095,\n",
      "    -0.00899274181574583,\n",
      "    0.008042024448513985,\n",
      "    -0.032923463732004166,\n",
      "    -0.007358289789408445,\n",
      "    -0.018050599843263626,\n",
      "    -0.002684473292902112,\n",
      "    -0.011415116488933563,\n",
      "    0.003016573144122958,\n",
      "    -0.0171259306371212,\n",
      "    -0.002241673646494746,\n",
      "    -0.009800199419260025,\n",
      "    0.017607800662517548,\n",
      "    0.0021895794197916985,\n",
      "    0.01036021113395691,\n",
      "    -0.0060201226733624935,\n",
      "    0.0035000713542103767,\n",
      "    -0.030266663059592247,\n",
      "    -0.007573177572339773,\n",
      "    0.010724869556725025,\n",
      "    -0.017764084041118622,\n",
      "    -0.009559264406561852,\n",
      "    0.03190762922167778,\n",
      "    0.028287088498473167,\n",
      "    -0.00706526031717658,\n",
      "    -0.009715546853840351,\n",
      "    -0.008543429896235466,\n",
      "    -0.008237377740442753,\n",
      "    0.020889727398753166,\n",
      "    0.009142512455582619,\n",
      "    0.03448628634214401,\n",
      "    -0.011206740513443947,\n",
      "    -0.016031954437494278,\n",
      "    0.0007232124335132539,\n",
      "    0.004082873929291964,\n",
      "    -0.014924955554306507,\n",
      "    0.002013762015849352,\n",
      "    -0.01716500148177147,\n",
      "    0.009669964201748371,\n",
      "    0.0019453885033726692,\n",
      "    -0.003431697841733694,\n",
      "    -0.006482457742094994,\n",
      "    0.004063338506966829,\n",
      "    0.02163206972181797,\n",
      "    0.012925844639539719,\n",
      "    0.028104759752750397,\n",
      "    0.0016035210574045777,\n",
      "    -0.006778743118047714,\n",
      "    0.011571398936212063,\n",
      "    0.020525069907307625,\n",
      "    -0.024575384333729744,\n",
      "    0.007169448304921389,\n",
      "    -0.012795609422028065,\n",
      "    -0.005486158188432455,\n",
      "    -0.017698965966701508,\n",
      "    0.010653240606188774,\n",
      "    0.012456998229026794,\n",
      "    0.0014903792180120945,\n",
      "    0.01716500148177147,\n",
      "    0.009018788114190102,\n",
      "    -3.072736944886856e-05,\n",
      "    -0.004831726662814617,\n",
      "    0.027062878012657166,\n",
      "    -0.044410206377506256,\n",
      "    -0.002632379299029708,\n",
      "    -0.022100916132330894,\n",
      "    -0.01982180029153824,\n",
      "    -0.018623635172843933,\n",
      "    -0.02406746707856655,\n",
      "    -0.029042452573776245,\n",
      "    0.03586677834391594,\n",
      "    0.0030214569997042418,\n",
      "    -0.0030491319485008717,\n",
      "    -0.006355478428304195,\n",
      "    0.01128488127142191,\n",
      "    -0.003535886062309146,\n",
      "    0.018766894936561584,\n",
      "    -0.03307974338531494,\n",
      "    0.006013610865920782,\n",
      "    -0.0024142353795468807,\n",
      "    0.006466178223490715,\n",
      "    -0.009109953418374062,\n",
      "    0.006863395683467388,\n",
      "    0.007735971827059984,\n",
      "    0.01090719923377037,\n",
      "    0.002772382227703929,\n",
      "    0.013329573906958103,\n",
      "    -0.010210440494120121,\n",
      "    0.0005412900936789811,\n",
      "    -0.004704746883362532,\n",
      "    0.012456998229026794,\n",
      "    -0.013427251018583775,\n",
      "    -0.00591267878189683,\n",
      "    -0.019001318141818047,\n",
      "    0.000145191908814013,\n",
      "    0.0006678624777123332,\n",
      "    0.0015107284998521209,\n",
      "    0.005782443564385176,\n",
      "    -0.02167113870382309,\n",
      "    -0.01829804666340351,\n",
      "    -0.0071629369631409645,\n",
      "    0.008094118908047676,\n",
      "    0.005437320098280907,\n",
      "    0.02392420917749405,\n",
      "    -0.005134523380547762,\n",
      "    -0.0054503437131643295,\n",
      "    0.0019665516447275877,\n",
      "    -0.01013881154358387,\n",
      "    0.02172323316335678,\n",
      "    -0.012723980471491814,\n",
      "    0.004180550575256348,\n",
      "    -0.010223464109003544,\n",
      "    -0.028052665293216705,\n",
      "    -0.0052680145017802715,\n",
      "    0.004883820656687021,\n",
      "    -0.010965804569423199,\n",
      "    -0.010731381364166737,\n",
      "    0.004662420600652695,\n",
      "    -0.02315582148730755,\n",
      "    0.008165747858583927,\n",
      "    -0.016618013381958008,\n",
      "    0.01901434175670147,\n",
      "    0.008536918088793755,\n",
      "    -0.010236487723886967,\n",
      "    -0.0012445602333173156,\n",
      "    -0.0023588852491229773,\n",
      "    0.009396471083164215,\n",
      "    0.007722948212176561,\n",
      "    0.014924955554306507,\n",
      "    0.015693344175815582,\n",
      "    0.004870797041803598,\n",
      "    -0.022921398282051086,\n",
      "    -0.0023312103003263474,\n",
      "    -0.0287038404494524,\n",
      "    0.037872400134801865,\n",
      "    0.022153010591864586,\n",
      "    -0.011200228706002235,\n",
      "    -0.015107285231351852,\n",
      "    0.02505725435912609,\n",
      "    0.013479344546794891,\n",
      "    -0.0044182296842336655,\n",
      "    0.006622460670769215,\n",
      "    0.010731381364166737,\n",
      "    0.012020709924399853,\n",
      "    -0.0022774883545935154,\n",
      "    0.01914457604289055,\n",
      "    -0.005629417020827532,\n",
      "    0.01738640107214451,\n",
      "    0.012958403676748276,\n",
      "    0.024314913898706436,\n",
      "    -0.005385226104408503,\n",
      "    -0.0021260897628962994,\n",
      "    -0.004997776355594397,\n",
      "    0.007149913348257542,\n",
      "    0.031152263283729553,\n",
      "    0.014677508734166622,\n",
      "    -0.0027414511423557997,\n",
      "    0.019274812191724777,\n",
      "    0.0105685880407691,\n",
      "    -0.01270444504916668,\n",
      "    -0.003653097664937377,\n",
      "    -0.020538093522191048,\n",
      "    0.005863840691745281,\n",
      "    0.019886916503310204,\n",
      "    0.04881215840578079,\n",
      "    -0.021827422082424164,\n",
      "    -0.010353699326515198,\n",
      "    0.02249162085354328,\n",
      "    -0.0051052202470600605,\n",
      "    0.006599669344723225,\n",
      "    0.012606768868863583,\n",
      "    0.013427251018583775,\n",
      "    0.009585311636328697,\n",
      "    0.004108921159058809,\n",
      "    0.02104601077735424,\n",
      "    -0.017607800662517548,\n",
      "    0.010835569351911545,\n",
      "    -0.029902005568146706,\n",
      "    -0.004027524031698704,\n",
      "    0.010640216991305351,\n",
      "    0.005639184731990099,\n",
      "    0.021931609138846397,\n",
      "    0.014794720336794853,\n",
      "    0.012984450906515121,\n",
      "    -0.022504644468426704,\n",
      "    0.017269188538193703,\n",
      "    0.016604989767074585,\n",
      "    0.00760573660954833,\n",
      "    0.0003298613883089274,\n",
      "    -0.003389371559023857,\n",
      "    0.03581468388438225,\n",
      "    -0.028781982138752937,\n",
      "    0.036075152456760406,\n",
      "    -0.005792211275547743,\n",
      "    -0.017646871507167816,\n",
      "    0.03159506246447563,\n",
      "    0.029146641492843628,\n",
      "    -0.009748105891048908,\n",
      "    -0.013147245161235332,\n",
      "    -0.0076382951810956,\n",
      "    -0.007807601243257523,\n",
      "    0.019339928403496742,\n",
      "    -0.03128249943256378,\n",
      "    0.010171370580792427,\n",
      "    -0.020394833758473396,\n",
      "    0.012795609422028065,\n",
      "    0.009930434636771679,\n",
      "    -0.029849911108613014,\n",
      "    0.012528627179563046,\n",
      "    -0.003675888990983367,\n",
      "    0.00851738266646862,\n",
      "    0.014182615093886852,\n",
      "    0.023351173847913742,\n",
      "    0.013075615279376507,\n",
      "    0.010340675711631775,\n",
      "    -0.018936200067400932,\n",
      "    0.03383510932326317,\n",
      "    0.018871081992983818,\n",
      "    0.017204072326421738,\n",
      "    0.02072042226791382,\n",
      "    -0.023260008543729782,\n",
      "    0.010047647170722485,\n",
      "    -0.001599451177753508,\n",
      "    -0.012235598638653755,\n",
      "    0.002087019383907318,\n",
      "    -0.0015986372018232942,\n",
      "    -0.00211306638084352,\n",
      "    0.012886774726212025,\n",
      "    0.028052665293216705,\n",
      "    -0.0084066828712821,\n",
      "    0.01370074413716793,\n",
      "    -0.030162476003170013,\n",
      "    0.00260307639837265,\n",
      "    0.030657369643449783,\n",
      "    -0.008973206393420696,\n",
      "    -0.011695122346282005,\n",
      "    -0.0030523878522217274,\n",
      "    0.006208963692188263,\n",
      "    -0.007078283932060003,\n",
      "    0.005404761526733637,\n",
      "    0.014872861094772816,\n",
      "    -0.021423691883683205,\n",
      "    0.015524037182331085,\n",
      "    0.020381810143589973,\n",
      "    -0.022999538108706474,\n",
      "    0.006733160465955734,\n",
      "    -0.0011851404560729861,\n",
      "    -0.0066550192423164845,\n",
      "    0.01097231637686491,\n",
      "    -0.011864428408443928,\n",
      "    0.008732271380722523,\n",
      "    -0.008953670971095562,\n",
      "    -0.022048821672797203,\n",
      "    -0.01097231637686491,\n",
      "    -0.00023910371237434447,\n",
      "    -0.024679573252797127,\n",
      "    0.010809523053467274,\n",
      "    0.020264599472284317,\n",
      "    0.04498324170708656,\n",
      "    -0.0014154940145090222,\n",
      "    -0.010926734656095505,\n",
      "    -0.015550084412097931,\n",
      "    -0.013160268776118755,\n",
      "    0.0028440114110708237,\n",
      "    0.033861156553030014,\n",
      "    -0.020746469497680664,\n",
      "    -0.05871003493666649,\n",
      "    0.02622937224805355,\n",
      "    0.016552895307540894,\n",
      "    -0.023846067488193512,\n",
      "    -0.014208661392331123,\n",
      "    -0.008282959461212158,\n",
      "    0.0002946571621578187,\n",
      "    -0.01690453104674816,\n",
      "    -0.021619046106934547,\n",
      "    -0.01626637764275074,\n",
      "    -0.030579227954149246,\n",
      "    0.004454044159501791,\n",
      "    0.05683464556932449,\n",
      "    0.030839698389172554,\n",
      "    -0.02207486890256405,\n",
      "    0.01577148400247097,\n",
      "    0.008745294995605946,\n",
      "    -0.00802248902618885,\n",
      "    -0.013909121043980122,\n",
      "    -0.030344804748892784,\n",
      "    -0.003828915301710367,\n",
      "    -0.012886774726212025,\n",
      "    -0.01097231637686491,\n",
      "    -0.008393659256398678,\n",
      "    -0.01086161658167839,\n",
      "    0.018545495346188545,\n",
      "    -0.003552165348082781,\n",
      "    -0.004284738563001156,\n",
      "    -0.027740100398659706,\n",
      "    -0.015888696536421776,\n",
      "    0.02081158757209778,\n",
      "    0.008276447653770447,\n",
      "    -0.021215315908193588,\n",
      "    0.015081238001585007,\n",
      "    -0.016552895307540894,\n",
      "    0.050270792096853256,\n",
      "    0.012567698024213314,\n",
      "    0.002490748418495059,\n",
      "    0.018102694302797318,\n",
      "    0.03438209742307663,\n",
      "    0.0031695994548499584,\n",
      "    -0.010464399121701717,\n",
      "    -0.021606022492051125,\n",
      "    0.020472975447773933,\n",
      "    0.0058377934619784355,\n",
      "    0.024705620482563972,\n",
      "    -0.010496958158910275,\n",
      "    -0.007091307546943426,\n",
      "    0.010073693469166756,\n",
      "    -0.015888696536421776,\n",
      "    0.0026112159248441458,\n",
      "    0.01956132985651493,\n",
      "    0.01571938954293728,\n",
      "    -0.0003455303085502237,\n",
      "    0.014729602262377739,\n",
      "    -0.010640216991305351,\n",
      "    -0.012587233446538448,\n",
      "    -0.020941821858286858,\n",
      "    -0.026203325018286705,\n",
      "    0.023937232792377472,\n",
      "    -0.005919190589338541,\n",
      "    0.019496211782097816,\n",
      "    0.018324093893170357,\n",
      "    -0.014417038299143314,\n",
      "    -0.023754902184009552,\n",
      "    -0.012997474521398544,\n",
      "    0.007338754367083311,\n",
      "    -0.011597446165978909,\n",
      "    -0.014143544249236584,\n",
      "    -0.032246239483356476,\n",
      "    0.007482013199478388,\n",
      "    -0.0478484183549881,\n",
      "    -0.011890474706888199,\n",
      "    -0.04480091482400894,\n",
      "    0.02401537261903286,\n",
      "    -0.010516493581235409,\n",
      "    -0.017047788947820663,\n",
      "    -0.027193112298846245,\n",
      "    -0.03446023911237717,\n",
      "    0.003174483310431242,\n",
      "    -0.04961961507797241,\n",
      "    0.009761129505932331,\n",
      "    0.007026189938187599,\n",
      "    -0.029459204524755478,\n",
      "    -0.01379190944135189,\n",
      "    -0.01571938954293728,\n",
      "    0.0177510604262352,\n",
      "    -0.007612248416990042,\n",
      "    0.012216063216328621,\n",
      "    0.007996441796422005,\n",
      "    0.013883073814213276,\n",
      "    0.019027365371584892,\n",
      "    -0.021189268678426743,\n",
      "    -0.023286055773496628,\n",
      "    -0.0271670650690794,\n",
      "    -0.006811301689594984,\n",
      "    -0.004134967923164368,\n",
      "    0.00833505392074585,\n",
      "    0.011076505295932293,\n",
      "    -0.013817955739796162,\n",
      "    -0.01806362345814705,\n",
      "    0.013948190957307816,\n",
      "    -0.023468386381864548,\n",
      "    -0.015302637591958046,\n",
      "    0.004616838414222002,\n",
      "    -0.020381810143589973,\n",
      "    0.020785540342330933,\n",
      "    -0.018688753247261047,\n",
      "    0.013440273702144623,\n",
      "    0.014260755851864815,\n",
      "    -0.00619594007730484,\n",
      "    0.020446928218007088,\n",
      "    0.021918587386608124,\n",
      "    0.013414227403700352,\n",
      "    -0.014338896609842777,\n",
      "    -0.013505391776561737,\n",
      "    0.009416005574166775,\n",
      "    0.00928577035665512,\n",
      "    0.019079457968473434,\n",
      "    -0.0027919174171984196,\n",
      "    -0.001717476872727275,\n",
      "    0.002925408538430929,\n",
      "    0.005069405771791935,\n",
      "    -0.01690453104674816,\n",
      "    -0.0005482088308781385,\n",
      "    -0.005863840691745281,\n",
      "    -0.01793338917195797,\n",
      "    -0.013713767752051353,\n",
      "    0.014000285416841507,\n",
      "    0.00025985995307564735,\n",
      "    -0.006599669344723225,\n",
      "    -0.009357400238513947,\n",
      "    0.014195638708770275,\n",
      "    -9.055417467607185e-05,\n",
      "    0.010288582183420658,\n",
      "    0.00047128868754953146,\n",
      "    -0.001407354255206883,\n",
      "    0.0007573991897515953,\n",
      "    -0.02992805279791355,\n",
      "    -0.022921398282051086,\n",
      "    -0.021202292293310165,\n",
      "    0.03438209742307663,\n",
      "    -0.005635928828269243,\n",
      "    0.02104601077735424,\n",
      "    -0.027505677193403244,\n",
      "    -0.010835569351911545,\n",
      "    0.014990072697401047,\n",
      "    -0.026776360347867012,\n",
      "    -0.004112177062779665,\n",
      "    -0.005313596688210964,\n",
      "    -0.01367469783872366,\n",
      "    -0.00027837775996886194,\n",
      "    0.004581023473292589,\n",
      "    -0.010132299736142159,\n",
      "    0.008387147448956966,\n",
      "    -0.009429029189050198,\n",
      "    0.03821101039648056,\n",
      "    -0.036257483065128326,\n",
      "    -0.010640216991305351,\n",
      "    -0.013596556149423122,\n",
      "    0.021957656368613243,\n",
      "    0.033366262912750244,\n",
      "    0.006632228381931782,\n",
      "    -0.011252322234213352,\n",
      "    -0.019261788576841354,\n",
      "    0.027427535504102707,\n",
      "    -0.027792194858193398,\n",
      "    -0.01685243658721447,\n",
      "    0.0048284707590937614,\n",
      "    -0.011421628296375275,\n",
      "    0.015979859977960587,\n",
      "    0.02501818537712097,\n",
      "    0.0385756716132164,\n",
      "    0.008354589343070984,\n",
      "    0.00806807167828083,\n",
      "    0.015250543132424355,\n",
      "    0.003933103289455175,\n",
      "    -0.027245206758379936,\n",
      "    0.005688022822141647,\n",
      "    0.027688005939126015,\n",
      "    -0.019118528813123703,\n",
      "    0.0020609721541404724,\n",
      "    -0.004753585439175367,\n",
      "    0.00845226552337408,\n",
      "    -0.02307767979800701,\n",
      "    -0.02126741036772728,\n",
      "    0.01123929861932993,\n",
      "    -0.005088941194117069,\n",
      "    -0.008478312753140926,\n",
      "    -0.0026747058145701885,\n",
      "    -0.02658100798726082,\n",
      "    -0.014612390659749508,\n",
      "    0.009774153120815754,\n",
      "    -0.014208661392331123,\n",
      "    -7.101889059413224e-05,\n",
      "    0.01162349246442318,\n",
      "    -0.0506354495882988,\n",
      "    -0.02355954982340336,\n",
      "    0.037377506494522095,\n",
      "    0.0154328728094697,\n",
      "    0.03586677834391594,\n",
      "    -0.011760239489376545,\n",
      "    0.012880262918770313,\n",
      "    -0.0011037434451282024,\n",
      "    0.030943887308239937,\n",
      "    0.0055154613219201565,\n",
      "    -0.024536313489079475,\n",
      "    0.010607657954096794,\n",
      "    -0.01752965897321701,\n",
      "    -0.04248272627592087,\n",
      "    -0.028234994038939476,\n",
      "    -0.008530406281352043,\n",
      "    -0.012951891869306564,\n",
      "    0.02550005540251732,\n",
      "    -0.010496958158910275,\n",
      "    0.0023702809121459723,\n",
      "    0.01112859882414341,\n",
      "    0.011395581066608429,\n",
      "    -0.018285024911165237,\n",
      "    0.0008896692888811231,\n",
      "    0.02654193714261055,\n",
      "    0.0014993329532444477,\n",
      "    -0.0052224318496882915,\n",
      "    -0.034173719584941864,\n",
      "    -0.017959436401724815,\n",
      "    0.00384193891659379,\n",
      "    0.006134078372269869,\n",
      "    0.019001318141818047,\n",
      "    0.0003150064148940146,\n",
      "    -0.002412607427686453,\n",
      "    -0.021397646516561508,\n",
      "    -0.03031875751912594,\n",
      "    0.0314648263156414,\n",
      "    0.00028611047309823334,\n",
      "    0.016930578276515007,\n",
      "    -0.00760573660954833,\n",
      "    0.028287088498473167,\n",
      "    0.020199481397867203,\n",
      "    0.00621873140335083,\n",
      "    -0.013896097429096699,\n",
      "    -0.008647617883980274,\n",
      "    -0.014885884709656239,\n",
      "    -0.003228205256164074,\n",
      "    0.03875799849629402,\n",
      "    0.05907469242811203,\n",
      "    -0.02564331330358982,\n",
      "    -0.011480234563350677,\n",
      "    -0.01133046392351389,\n",
      "    0.011434651911258698,\n",
      "    -0.02518749050796032,\n",
      "    -0.000670711335260421,\n",
      "    0.02018645778298378,\n",
      "    0.025890760123729706,\n",
      "    0.004138223826885223,\n",
      "    -0.005336388014256954,\n",
      "    0.004773120395839214,\n",
      "    -0.007924812845885754,\n",
      "    0.011968616396188736,\n",
      "    0.005056382156908512,\n",
      "    0.02329907938838005,\n",
      "    0.014495179057121277,\n",
      "    -0.006417340133339167,\n",
      "    0.0009051347151398659,\n",
      "    0.03930498659610748,\n",
      "    0.011486745439469814,\n",
      "    0.008250400424003601,\n",
      "    0.0002201789029641077,\n",
      "    -0.010392770171165466,\n",
      "    -0.014651461504399776,\n",
      "    -0.006101519800722599,\n",
      "    -0.005593602545559406,\n",
      "    0.009989040903747082,\n",
      "    -0.019978081807494164,\n",
      "    0.02771405316889286,\n",
      "    -0.023546526208519936,\n",
      "    0.0036693771835416555,\n",
      "    -0.0011981639545410872,\n",
      "    -0.0015164262149482965,\n",
      "    -0.01838921196758747,\n",
      "    -0.005603370256721973,\n",
      "    0.0015725902048870921,\n",
      "    0.015667296946048737,\n",
      "    -0.014534249901771545,\n",
      "    -0.023494431748986244,\n",
      "    0.03136064112186432,\n",
      "    -0.00526150269433856,\n",
      "    -0.02081158757209778,\n",
      "    0.00268610124476254,\n",
      "    -0.017451519146561623,\n",
      "    -0.01036672294139862,\n",
      "    -0.013270968571305275,\n",
      "    0.007273636758327484,\n",
      "    0.014521226286888123,\n",
      "    0.011415116488933563,\n",
      "    -0.022543715313076973,\n",
      "    -0.0032949508167803288,\n",
      "    0.011701634153723717,\n",
      "    -0.013557486236095428,\n",
      "    -0.024353984743356705,\n",
      "    -0.016097072511911392,\n",
      "    0.025291679427027702,\n",
      "    -0.015576131641864777,\n",
      "    -0.01002811174839735,\n",
      "    0.02262185700237751,\n",
      "    -0.003646586090326309,\n",
      "    0.02410653792321682,\n",
      "    -0.007872718386352062,\n",
      "    0.0033828597515821457,\n",
      "    0.011441163718700409,\n",
      "    0.013323062099516392,\n",
      "    -0.004161015152931213,\n",
      "    0.026515889912843704,\n",
      "    -0.001508286572061479,\n",
      "    0.013922144658863544,\n",
      "    -0.03709099069237709,\n",
      "    0.0006369315669871867,\n",
      "    -0.0215929988771677,\n",
      "    0.0005221618339419365,\n",
      "    0.007110842503607273,\n",
      "    -0.015380778349936008,\n",
      "    -0.021827422082424164,\n",
      "    -0.023129774257540703,\n",
      "    -0.010060669854283333,\n",
      "    0.007547130808234215,\n",
      "    -0.002093530958518386,\n",
      "    0.029355017468333244,\n",
      "    0.006013610865920782,\n",
      "    0.027375441044569016,\n",
      "    -0.015263566747307777,\n",
      "    -0.008074583485722542,\n",
      "    -0.016370566561818123,\n",
      "    0.05295363813638687,\n",
      "    0.0005087312893010676,\n",
      "    -0.01906643621623516,\n",
      "    0.010451375506818295,\n",
      "    -0.005951749160885811,\n",
      "    0.0549592599272728,\n",
      "    -0.0031044818460941315,\n",
      "    -0.008556453511118889,\n",
      "    0.009272747673094273,\n",
      "    0.013505391776561737,\n",
      "    -0.016383590176701546,\n",
      "    0.0021765560377389193,\n",
      "    0.03469466045498848,\n",
      "    -0.026255419477820396,\n",
      "    0.0007753064855933189,\n",
      "    -0.025539126247167587,\n",
      "    -0.033861156553030014,\n",
      "    0.00878436490893364,\n",
      "    0.005863840691745281,\n",
      "    0.016474755480885506,\n",
      "    -0.002021901775151491,\n",
      "    0.01020392868667841,\n",
      "    0.007390848360955715,\n",
      "    0.023715833202004433,\n",
      "    -0.0013251432683318853,\n",
      "    -0.007312707137316465,\n",
      "    -0.021527880802750587,\n",
      "    -0.022856280207633972,\n",
      "    0.0008009465527720749,\n",
      "    -0.03925289213657379,\n",
      "    -0.010731381364166737,\n",
      "    0.019496211782097816,\n",
      "    0.03753378987312317,\n",
      "    -0.004196829628199339,\n",
      "    -0.019483188167214394,\n",
      "    -0.02771405316889286,\n",
      "    -1.5605332009727135e-05,\n",
      "    -0.020342741161584854,\n",
      "    -0.005886631552129984,\n",
      "    -0.0154328728094697,\n",
      "    0.021215315908193588,\n",
      "    0.03276718035340309,\n",
      "    0.019222717732191086,\n",
      "    -0.0009645545505918562,\n",
      "    0.053057827055454254,\n",
      "    -0.013883073814213276,\n",
      "    0.0015294498298317194,\n",
      "    -0.061575207859277725,\n",
      "    0.007833648473024368,\n",
      "    0.041701316833496094,\n",
      "    -0.0035196065437048674,\n",
      "    0.011343487538397312,\n",
      "    0.005059638060629368,\n",
      "    -0.018688753247261047,\n",
      "    -0.0076448069885373116,\n",
      "    0.01471657957881689,\n",
      "    0.006277337204664946,\n",
      "    0.008927623741328716,\n",
      "    0.036439813673496246,\n",
      "    -0.0018232930451631546,\n",
      "    -0.024184679612517357,\n",
      "    0.00822435412555933,\n",
      "    0.005049870349466801,\n",
      "    0.0022205105051398277,\n",
      "    0.010933246463537216,\n",
      "    -0.00537220248952508,\n",
      "    -0.05844956263899803,\n",
      "    -0.0018412002827972174,\n",
      "    0.032011814415454865,\n",
      "    -0.0031419245060533285,\n",
      "    0.007078283932060003,\n",
      "    -0.011265345849096775,\n",
      "    0.006026634480804205,\n",
      "    -0.02032971754670143,\n",
      "    0.004047059454023838,\n",
      "    -0.020746469497680664,\n",
      "    -0.002966107102110982,\n",
      "    0.0031533201690763235,\n",
      "    -0.0035782125778496265,\n",
      "    0.0043531120754778385,\n",
      "    0.04579070210456848,\n",
      "    -0.01379190944135189,\n",
      "    0.039539411664009094,\n",
      "    0.02108508162200451,\n",
      "    -0.03313183784484863,\n",
      "    0.012339786626398563,\n",
      "    0.019183646887540817,\n",
      "    -0.026932641863822937,\n",
      "    -0.02131950482726097,\n",
      "    0.0012982822954654694,\n",
      "    0.008419706486165524,\n",
      "    0.014364943839609623,\n",
      "    -0.005463367328047752,\n",
      "    -0.011493257246911526,\n",
      "    0.013622603379189968,\n",
      "    -0.025877736508846283,\n",
      "    -0.021892540156841278,\n",
      "    0.004141479730606079,\n",
      "    -0.03193367272615433,\n",
      "    0.010685799643397331,\n",
      "    0.0026909851003438234,\n",
      "    -0.0611063614487648,\n",
      "    0.012645839713513851,\n",
      "    -0.006104775704443455,\n",
      "    -0.01568032056093216,\n",
      "    0.015537060797214508,\n",
      "    -0.0061080316081643105,\n",
      "    -0.009507170878350735,\n",
      "    -0.037429600954055786,\n",
      "    -0.028000570833683014,\n",
      "    0.02163206972181797,\n",
      "    -0.019183646887540817,\n",
      "    -0.03722122311592102,\n",
      "    -8.327931573148817e-05,\n",
      "    0.0096439179033041,\n",
      "    -0.020941821858286858,\n",
      "    0.020381810143589973,\n",
      "    0.19462350010871887,\n",
      "    0.008960182778537273,\n",
      "    0.001857479684986174,\n",
      "    0.04685863107442856,\n",
      "    -0.0011126970639452338,\n",
      "    -0.004633117932826281,\n",
      "    0.010132299736142159,\n",
      "    -0.010542540811002254,\n",
      "    -0.0055382526479661465,\n",
      "    0.011929545551538467,\n",
      "    -0.020564140751957893,\n",
      "    0.01302352175116539,\n",
      "    -0.002800057176500559,\n",
      "    0.0056684878654778,\n",
      "    0.02306465618312359,\n",
      "    -0.01151279266923666,\n",
      "    -0.04771818220615387,\n",
      "    -0.009240188635885715,\n",
      "    -0.046025123447179794,\n",
      "    0.03878404572606087,\n",
      "    -0.00021366715373005718,\n",
      "    0.0069350250996649265,\n",
      "    -0.006746184080839157,\n",
      "    -0.009305305778980255,\n",
      "    -0.0010760684963315725,\n",
      "    -0.0018428282346576452,\n",
      "    -0.010216952301561832,\n",
      "    0.004333576653152704,\n",
      "    0.016162190586328506,\n",
      "    0.012001174502074718,\n",
      "    -0.016461731866002083,\n",
      "    0.022296268492937088,\n",
      "    -0.01644870825111866,\n",
      "    -0.0009482751484028995,\n",
      "    -0.024119561538100243,\n",
      "    -0.0035586771555244923,\n",
      "    -0.014872861094772816,\n",
      "    -0.015042167156934738,\n",
      "    7.707279291935265e-05,\n",
      "    0.030709464102983475,\n",
      "    0.011349999345839024,\n",
      "    0.00012351995974313468,\n",
      "    -0.014000285416841507,\n",
      "    -0.018493400886654854,\n",
      "    0.014677508734166622,\n",
      "    -0.011206740513443947,\n",
      "    0.008413194678723812,\n",
      "    0.01248304545879364,\n",
      "    -0.019300859421491623,\n",
      "    0.010041135363280773,\n",
      "    -0.033236026763916016,\n",
      "    0.02062925696372986,\n",
      "    0.010829058475792408,\n",
      "    0.022791162133216858,\n",
      "    0.00722154276445508,\n",
      "    -0.014469131827354431,\n",
      "    0.0260861124843359,\n",
      "    -0.0011835125042125583,\n",
      "    -0.012763051316142082,\n",
      "    -0.01031462848186493,\n",
      "    -0.006772231310606003,\n",
      "    0.007996441796422005,\n",
      "    -0.018779918551445007,\n",
      "    0.017998507246375084,\n",
      "    0.0012763050617650151,\n",
      "    -0.011096039786934853,\n",
      "    -0.0009564148494973779,\n",
      "    0.022361386567354202,\n",
      "    0.008680176921188831,\n",
      "    -0.04123247042298317,\n",
      "    -0.0024972602259367704,\n",
      "    0.009207629598677158,\n",
      "    -0.029276875779032707,\n",
      "    -0.008530406281352043,\n",
      "    -0.02126741036772728,\n",
      "    0.0062024518847465515,\n",
      "    0.03253275528550148,\n",
      "    0.005785699468106031,\n",
      "    0.008256912231445312,\n",
      "    -0.006143846083432436,\n",
      "    0.001984459115192294,\n",
      "    -8.592471567681059e-05,\n",
      "    -0.009663453325629234,\n",
      "    0.007156425155699253,\n",
      "    0.00021102174650877714,\n",
      "    0.00040271171019412577,\n",
      "    0.028495464473962784,\n",
      "    0.0021635324228554964,\n",
      "    0.004584279377013445,\n",
      "    -0.015263566747307777,\n",
      "    0.0037963564973324537,\n",
      "    0.009949970059096813,\n",
      "    -0.008361101150512695,\n",
      "    -0.009546240791678429,\n",
      "    -0.0011818845523521304,\n",
      "    0.0010174625786021352,\n",
      "    -0.024406079202890396,\n",
      "    0.008139700628817081,\n",
      "    -0.024835854768753052,\n",
      "    -0.0048577734269201756,\n",
      "    -0.0029628511983901262,\n",
      "    0.0710042417049408,\n",
      "    0.014482155442237854,\n",
      "    -0.029120594263076782,\n",
      "    -0.003601003671064973,\n",
      "    -0.029355017468333244,\n",
      "    -0.0008896692888811231,\n",
      "    0.000516464002430439,\n",
      "    0.017425471916794777,\n",
      "    -0.005658720154315233,\n",
      "    -0.020564140751957893,\n",
      "    -0.025851689279079437,\n",
      "    0.0015774740604683757,\n",
      "    -0.01564124971628189,\n",
      "    -0.002028413349762559,\n",
      "    -0.0200562234967947,\n",
      "    0.01613614335656166,\n",
      "    -0.023090703412890434,\n",
      "    0.004903355613350868,\n",
      "    -0.004554976709187031,\n",
      "    -0.006954560521990061,\n",
      "    -0.021514857187867165,\n",
      "    0.0025965645909309387,\n",
      "    0.010164858773350716,\n",
      "    -0.003045876044780016,\n",
      "    -0.01608404889702797,\n",
      "    0.018167812377214432,\n",
      "    -0.024458173662424088,\n",
      "    -0.0050107999704778194,\n",
      "    -0.050948016345500946,\n",
      "    0.01200768630951643,\n",
      "    -0.0030621555633842945,\n",
      "    0.011460699141025543,\n",
      "    -0.0009083906188607216,\n",
      "    0.021658116951584816,\n",
      "    0.015563108026981354,\n",
      "    0.03375696763396263,\n",
      "    0.018376188352704048,\n",
      "    -0.022205103188753128,\n",
      "    -0.0032607640605419874,\n",
      "    -0.01582357846200466,\n",
      "    0.020420880988240242,\n",
      "    -0.006843860261142254,\n",
      "    -0.013765862211585045,\n",
      "    0.024640502408146858,\n",
      "    -0.01960039883852005,\n",
      "    0.006498737260699272,\n",
      "    -0.013922144658863544,\n",
      "    -0.003806124208495021,\n",
      "    -0.009246700443327427,\n",
      "    -0.02802661806344986,\n",
      "    -0.0019437605515122414,\n",
      "    0.0074103837832808495,\n",
      "    0.011069993488490582,\n",
      "    0.03313183784484863,\n",
      "    -0.023129774257540703,\n",
      "    -0.011278369463980198,\n",
      "    -0.025929830968379974,\n",
      "    -0.002412607427686453,\n",
      "    -0.003146808361634612,\n",
      "    -0.04435811564326286,\n",
      "    -0.0024858645629137754,\n",
      "    0.01973063498735428,\n",
      "    0.0005136151448823512,\n",
      "    -0.025356795638799667,\n",
      "    0.0021863237489014864,\n",
      "    -0.1618042290210724,\n",
      "    0.03433000296354294,\n",
      "    0.007814113050699234,\n",
      "    0.025656336918473244,\n",
      "    0.005274526309221983,\n",
      "    0.005867096595466137,\n",
      "    0.023637691512703896,\n",
      "    -0.0348769910633564,\n",
      "    0.005808490328490734,\n",
      "    -0.015484967269003391,\n",
      "    0.02654193714261055,\n",
      "    -0.0035684448666870594,\n",
      "    -0.03834124654531479,\n",
      "    -0.0029872702434659004,\n",
      "    0.019574353471398354,\n",
      "    -0.026958689093589783,\n",
      "    -0.021462762728333473,\n",
      "    0.017047788947820663,\n",
      "    0.013687720522284508,\n",
      "    0.022517668083310127,\n",
      "    0.02938106469810009,\n",
      "    -0.01379190944135189,\n",
      "    0.0030768068972975016,\n",
      "    -0.020967869088053703,\n",
      "    0.0068178134970366955,\n",
      "    0.008549941703677177,\n",
      "    -0.0308657456189394,\n",
      "    -0.008009465411305428,\n",
      "    -0.003737750696018338,\n",
      "    -0.015263566747307777,\n",
      "    -0.03636167198419571,\n",
      "    0.0016930578276515007,\n",
      "    0.006423851940780878,\n",
      "    0.0012567698722705245,\n",
      "    -0.010008576326072216,\n",
      "    0.017829200252890587,\n",
      "    -0.0211371760815382,\n",
      "    0.0023051633033901453,\n",
      "    -0.0033470450434833765,\n",
      "    0.010868128389120102,\n",
      "    0.01811571791768074,\n",
      "    0.003029596759006381,\n",
      "    0.006179661024361849,\n",
      "    0.004541953094303608,\n",
      "    -0.02247859723865986,\n",
      "    -0.015406825579702854,\n",
      "    0.02833918295800686,\n",
      "    0.01599288359284401,\n",
      "    0.01228118035942316,\n",
      "    0.009682987816631794,\n",
      "    0.015302637591958046,\n",
      "    -0.049281004816293716,\n",
      "    0.03347045183181763,\n",
      "    0.0017011974705383182,\n",
      "    0.009611358866095543,\n",
      "    0.03740355372428894,\n",
      "    0.004323808941990137,\n",
      "    0.008211330510675907,\n",
      "    0.00760573660954833,\n",
      "    -0.04013849422335625,\n",
      "    -0.00760573660954833,\n",
      "    -0.01648777723312378,\n",
      "    -0.0054731350392103195,\n",
      "    -0.02108508162200451,\n",
      "    0.004724282305687666,\n",
      "    -0.011004875414073467,\n",
      "    -0.001560380682349205,\n",
      "    -0.0023963279090821743,\n",
      "    -0.04000825807452202,\n",
      "    0.039721738547086716,\n",
      "    0.009090417996048927,\n",
      "    -0.013218874111771584,\n",
      "    -0.0039656623266637325,\n",
      "    -0.01124581042677164,\n",
      "    -0.006309896241873503,\n",
      "    0.008230865933001041,\n",
      "    -0.01500309631228447,\n",
      "    -0.0009604847291484475,\n",
      "    0.018141765147447586,\n",
      "    0.012951891869306564,\n",
      "    -0.019886916503310204,\n",
      "    0.02355954982340336,\n",
      "    -0.018962247297167778,\n",
      "    0.0007887370302341878,\n",
      "    -0.006580134388059378,\n",
      "    0.0053526670671999454,\n",
      "    0.017321282997727394,\n",
      "    0.017594777047634125,\n",
      "    0.01725616492331028,\n",
      "    0.007651318795979023,\n",
      "    0.006974095478653908,\n",
      "    -0.017998507246375084,\n",
      "    0.012378857471048832,\n",
      "    0.0024598175659775734,\n",
      "    0.003202158259227872,\n",
      "    0.005241967272013426,\n",
      "    -0.001057347166351974,\n",
      "    0.006599669344723225,\n",
      "    0.00916855875402689,\n",
      "    -0.000316023884806782,\n",
      "    -0.00023747577506583184,\n",
      "    -0.009149023331701756,\n",
      "    -0.012346298433840275,\n",
      "    -0.006798278074711561,\n",
      "    0.03375696763396263,\n",
      "    0.016214285045862198,\n",
      "    -0.03315788507461548,\n",
      "    0.014951002784073353,\n",
      "    0.01509426161646843,\n",
      "    -0.006104775704443455,\n",
      "    -0.056261613965034485,\n",
      "    0.006007099058479071,\n",
      "    0.02771405316889286,\n",
      "    -0.009559264406561852,\n",
      "    -0.00899274181574583,\n",
      "    0.015055190771818161,\n",
      "    -0.05871003493666649,\n",
      "    -0.015458920039236546,\n",
      "    0.030579227954149246,\n",
      "    0.003783332882449031,\n",
      "    0.0527973547577858,\n",
      "    -0.004974985029548407,\n",
      "    -0.01707383617758751,\n",
      "    -0.016618013381958008,\n",
      "    -0.02249162085354328,\n",
      "    -0.006668042857199907,\n",
      "    -0.09095627069473267,\n",
      "    -0.028052665293216705,\n",
      "    0.008882042020559311,\n",
      "    0.03946126997470856,\n",
      "    0.027193112298846245,\n",
      "    0.013544462621212006,\n",
      "    -0.002500516129657626,\n",
      "    0.033366262912750244,\n",
      "    -0.010809523053467274,\n",
      "    0.025669360533356667,\n",
      "    -0.010640216991305351,\n",
      "    -0.004747073631733656,\n",
      "    -0.019079457968473434,\n",
      "    0.017021741718053818,\n",
      "    0.05808490514755249,\n",
      "    0.007293172180652618,\n",
      "    -0.0003251810558140278,\n",
      "    -0.017555706202983856,\n",
      "    -0.006335943005979061,\n",
      "    0.014690532349050045,\n",
      "    0.0064075724221765995,\n",
      "    -0.01336213294416666,\n",
      "    0.023911185562610626,\n",
      "    -0.033366262912750244,\n",
      "    -0.04740561917424202,\n",
      "    0.010640216991305351,\n",
      "    -0.033913251012563705,\n",
      "    0.016917554661631584,\n",
      "    0.006765719503164291,\n",
      "    0.04315995052456856,\n",
      "    0.013466320931911469,\n",
      "    -0.003617282956838608,\n",
      "    -0.002451677806675434,\n",
      "    -0.005691278725862503,\n",
      "    -0.007618760224431753,\n",
      "    -0.003275415627285838,\n",
      "    -0.022100916132330894,\n",
      "    -0.02333815023303032,\n",
      "    0.030891792848706245,\n",
      "    -0.024588407948613167,\n",
      "    0.03339231014251709,\n",
      "    0.023715833202004433,\n",
      "    0.010737893171608448,\n",
      "    -0.027375441044569016,\n",
      "    -0.01462541427463293,\n",
      "    -0.011043946258723736,\n",
      "    0.007612248416990042,\n",
      "    -0.011936057358980179,\n",
      "    -0.002941687824204564,\n",
      "    -0.013830979354679585,\n",
      "    -0.0061829169280827045,\n",
      "    -0.026659147813916206,\n",
      "    3.5229641071055084e-05,\n",
      "    -0.0302406158298254,\n",
      "    0.00795737188309431,\n",
      "    0.008882042020559311,\n",
      "    0.002030041301622987,\n",
      "    0.017881294712424278,\n",
      "    -0.009611358866095543,\n",
      "    -0.0339653454720974,\n",
      "    -0.011838381178677082,\n",
      "    0.004177294671535492,\n",
      "    -0.03698680177330971,\n",
      "    0.02550005540251732,\n",
      "    0.014143544249236584,\n",
      "    0.01370074413716793,\n",
      "    -0.015016119927167892,\n",
      "    -0.007052236702293158,\n",
      "    0.02217905782163143,\n",
      "    -0.0318034403026104,\n",
      "    -0.021775327622890472,\n",
      "    0.029849911108613014,\n",
      "    -0.03623143583536148,\n",
      "    0.018623635172843933,\n",
      "    -0.019717611372470856,\n",
      "    0.01293235644698143,\n",
      "    -0.012131409719586372,\n",
      "    -0.021111128851771355,\n",
      "    0.011167669668793678,\n",
      "    -0.02659403160214424,\n",
      "    -0.010659752413630486,\n",
      "    -0.03946126997470856,\n",
      "    0.00040291520417667925,\n",
      "    0.0016018931055441499,\n",
      "    -0.002002366352826357,\n",
      "    0.018193859606981277,\n",
      "    -0.0005193129181861877,\n",
      "    -0.0011232787510380149,\n",
      "    0.0003589607949834317,\n",
      "    -0.0126588623970747,\n",
      "    -0.0014464248670265079,\n",
      "    0.019222717732191086,\n",
      "    0.015524037182331085,\n",
      "    -0.025487031787633896,\n",
      "    0.01313422154635191,\n",
      "    -0.017764084041118622,\n",
      "    -0.012782585807144642,\n",
      "    0.002526563126593828,\n",
      "    -0.004379158839583397,\n",
      "    0.0039428710006177425,\n",
      "    -0.03677842393517494,\n",
      "    -0.00046640486107207835,\n",
      "    -0.07574480026960373,\n",
      "    0.027375441044569016,\n",
      "    -0.003962406422942877,\n",
      "    0.0024288867134600878,\n",
      "    0.00392984738573432,\n",
      "    0.0011672331020236015,\n",
      "    -0.0023670250084251165,\n",
      "    -0.018011530861258507,\n",
      "    -0.0065475753508508205,\n",
      "    0.024757714942097664,\n",
      "    -0.03227228671312332,\n",
      "    0.027114972472190857,\n",
      "    -0.015458920039236546,\n",
      "    -0.00031398897408507764,\n",
      "    -0.015654273331165314,\n",
      "    -0.0163575429469347,\n",
      "    0.027114972472190857,\n",
      "    -0.005564299412071705,\n",
      "    -0.00020328903337940574,\n",
      "    0.01151279266923666,\n",
      "    -0.006668042857199907,\n",
      "    0.0077099245972931385,\n",
      "    0.029954100027680397,\n",
      "    0.028964310884475708,\n",
      "    -0.0028163364622741938,\n",
      "    0.020564140751957893,\n",
      "    -0.025578195229172707,\n",
      "    0.01861061155796051,\n",
      "    0.005199640989303589,\n",
      "    -0.0035814684815704823,\n",
      "    0.015537060797214508,\n",
      "    -0.014456109143793583,\n",
      "    -0.0017467797733843327,\n",
      "    0.03401743620634079,\n",
      "    0.011206740513443947,\n",
      "    -0.011695122346282005,\n",
      "    0.0044182296842336655,\n",
      "    0.019535282626748085,\n",
      "    0.03680447116494179,\n",
      "    -0.013003986328840256,\n",
      "    -0.016031954437494278,\n",
      "    -0.019170623272657394,\n",
      "    -0.0020365531090646982,\n",
      "    -0.004694979637861252,\n",
      "    -0.021410668268799782,\n",
      "    0.02022552862763405,\n",
      "    -0.015185425989329815,\n",
      "    0.019535282626748085,\n",
      "    0.017855247482657433,\n",
      "    0.008575988933444023,\n",
      "    0.019847847521305084,\n",
      "    0.021019963547587395,\n",
      "    0.0007944348035380244,\n",
      "    -0.00028692444902844727,\n",
      "    0.012365833856165409,\n",
      "    -0.00430427398532629,\n",
      "    0.0211371760815382,\n",
      "    -0.0065247840248048306,\n",
      "    0.034903038293123245,\n",
      "    -0.01608404889702797,\n",
      "    0.025382842868566513,\n",
      "    0.028443370014429092,\n",
      "    -0.0024142353795468807,\n",
      "    -0.019496211782097816,\n",
      "    0.011180693283677101,\n",
      "    -0.003946126904338598,\n",
      "    -0.01608404889702797,\n",
      "    -0.00291726877912879,\n",
      "    -0.02766195870935917,\n",
      "    -0.010047647170722485,\n",
      "    -0.007247589528560638,\n",
      "    -0.004545208998024464,\n",
      "    0.0004582651599776,\n",
      "    0.013375156559050083,\n",
      "    0.002204230986535549,\n",
      "    -0.011962104588747025,\n",
      "    0.0030377362854778767,\n",
      "    0.002591680735349655,\n",
      "    -0.007996441796422005,\n",
      "    0.029797816649079323,\n",
      "    0.0530838742852211,\n",
      "    0.007286660373210907,\n",
      "    -0.006417340133339167,\n",
      "    0.01703476533293724,\n",
      "    0.008543429896235466,\n",
      "    0.02815685234963894,\n",
      "    -0.0065899016335606575,\n",
      "    0.0072801485657691956,\n",
      "    -0.017646871507167816,\n",
      "    -0.0028081967029720545,\n",
      "    0.005258246790617704,\n",
      "    0.009201117791235447,\n",
      "    -0.007371312938630581,\n",
      "    0.00987182930111885,\n",
      "    0.025968901813030243,\n",
      "    0.021293457597494125,\n",
      "    -0.0001374591956846416,\n",
      "    -0.01815478876233101,\n",
      "    -5.346765829017386e-05,\n",
      "    0.022869303822517395,\n",
      "    -0.020707398653030396,\n",
      "    0.010724869556725025,\n",
      "    -0.029771769419312477,\n",
      "    -0.0020821355283260345,\n",
      "    -0.028443370014429092,\n",
      "    0.02256976254284382,\n",
      "    -0.028547558933496475,\n",
      "    -0.03326207399368286,\n",
      "    -0.0008921112166717649,\n",
      "    0.028990358114242554,\n",
      "    0.02568238414824009,\n",
      "    -0.003286811290308833,\n",
      "    0.02546098455786705,\n",
      "    0.011265345849096775,\n",
      "    -0.02342931553721428,\n",
      "    0.0002541621506679803,\n",
      "    -0.02388513833284378,\n",
      "    -0.022374410182237625,\n",
      "    -0.010464399121701717,\n",
      "    0.03646586090326309,\n",
      "    0.0002905873116105795,\n",
      "    0.031256452202796936,\n",
      "    -0.0040307799354195595,\n",
      "    -0.008120165206491947,\n",
      "    0.022452550008893013,\n",
      "    0.00624152272939682,\n",
      "    0.0274796299636364,\n",
      "    -0.02073344588279724,\n",
      "    -0.017998507246375084,\n",
      "    0.0008310634875670075,\n",
      "    -0.010229975916445255,\n",
      "    -0.006508504971861839,\n",
      "    0.005981052294373512,\n",
      "    -0.018962247297167778,\n",
      "    -0.02271302044391632,\n",
      "    -0.026190301403403282,\n",
      "    -0.0145082026720047,\n",
      "    0.008380635641515255,\n",
      "    -0.0031256452202796936,\n",
      "    0.08434032648801804,\n",
      "    0.03130854666233063,\n",
      "    0.012606768868863583,\n",
      "    -0.0017777106259018183,\n",
      "    0.0065703666768968105,\n",
      "    0.03597096726298332,\n",
      "    -0.019183646887540817,\n",
      "    0.01648777723312378,\n",
      "    -0.011473722755908966,\n",
      "    -0.028781982138752937,\n",
      "    0.00981973484158516,\n",
      "    -0.021645093336701393,\n",
      "    -0.028469417244195938,\n",
      "    -0.041518986225128174,\n",
      "    -0.0023540013935416937,\n",
      "    0.026880547404289246,\n",
      "    0.003480536164715886,\n",
      "    0.009090417996048927,\n",
      "    0.002878198167309165,\n",
      "    0.012248622253537178,\n",
      "    0.002438654424622655,\n",
      "    -0.03190762922167778,\n",
      "    0.020980892702937126,\n",
      "    0.020577164366841316,\n",
      "    -0.03597096726298332,\n",
      "    -0.005733605474233627,\n",
      "    -0.0020951589103788137,\n",
      "    -0.002723543904721737,\n",
      "    -0.001948644407093525,\n",
      "    -0.055532295256853104,\n",
      "    -0.002047948772087693,\n",
      "    0.009669964201748371,\n",
      "    -0.02807871252298355,\n",
      "    0.002593308687210083,\n",
      "    -0.009201117791235447,\n",
      "    -0.01275002770125866,\n",
      "    0.017060812562704086,\n",
      "    -0.026255419477820396,\n",
      "    0.010913711041212082,\n",
      "    -0.015524037182331085,\n",
      "    -0.016604989767074585,\n",
      "    0.009780664928257465,\n",
      "    -0.018988294526934624,\n",
      "    0.012984450906515121,\n",
      "    -0.0063424548134207726,\n",
      "    -0.0005380342481657863,\n",
      "    -0.01509426161646843,\n",
      "    0.02298651449382305,\n",
      "    -0.02758381888270378\n",
      "  ]\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìÅ existing_embeddings_with_meta_data.jsonl\n",
      "Entry 1:\n",
      "{\n",
      "  \"chunk_id\": \"row_0_chunk_0\",\n",
      "  \"text\": \"Cboe Global Markets, Inc. and Subsidiaries\\n\\nConsolidated Statements of Income\\n\\nYears ended December 31, 2023, 2022, and 2021\\n\\n(In millions, except per share data)\\n\\n\\n    \\n\\n2023\\n\\n    \\n\\n2022\\n\\n    \\n\\n2021\\n\\n \\n\\nRevenues:\\n\\nCash and spot markets\\n\\n\\n$\\n\\n1,445.1\\n\\n\\n$\\n\\n1,777.6\\n\\n\\n$\\n\\n1,660.5\\n\\n\\nData and access solutions\\n\\n539.2\\n\\n497.0\\n\\n427.7\\n\\n\\nDerivatives markets\\n\\n\\n \\n\\n1,789.2\\n\\n\\n \\n\\n1,683.9\\n\\n\\n \\n\\n1,406.6\\n\\n\\nTotal revenues\\n\\n\\n \\n\\n3,773.5\\n\\n\\n \\n\\n3,958.5\\n\\n\\n \\n\\n3,494.8\\n\\n\\nCost of revenues:\\n\\n  Liquidity payments\\n\\n\\n \\n\\n1,385.8\\n\\n\\n \\n\\n1,670.2\\n\\n\\n \\n\\n1,650.7\\n\\n\\n  Routing and clearing\\n\\n79.1\\n\\n83.2\\n\\n87.8\\n\\n\\n  Section 31 fees\\n\\n185.7\\n\\n329.8\\n\\n179.6\\n\\n\\n  Royalty fees and other cost of revenues\\n\\n\\n \\n\\n204.9\\n\\n\\n \\n\\n133.6\\n\\n\\n \\n\\n100.6\\n\\n\\nTotal cost of revenues\\n\\n\\n \\n\\n1,855.5\\n\\n\\n \\n\\n2,216.8\\n\\n\\n \\n\\n2,018.7\\n\\n\\nRevenues less cost of revenues\\n\\n\\n \\n\\n1,918.0\\n\\n\\n \\n\\n1,741.7\\n\\n\\n \\n\\n1,476.1\\n\\n\\nOperating expenses:\\n\\n  Compensation and benefits\\n\\n\\n \\n\\n425.8\\n\\n\\n \\n\\n363.0\\n\\n\\n \\n\\n288.5\\n\\n\\n  Depreciation and amortization\\n\\n\\n \\n\\n158.0\\n\\n\\n \\n\\n166.8\\n\\n\\n \\n\\n167.4\\n\\n\\n  Technology support services\\n\\n\\n \\n\\n99.7\\n\\n\\n \\n\\n77.7\\n\\n\\n \\n\\n66.7\\n\\n\\n  Professional fees and outside services\\n\\n\\n \\n\\n92.0\\n\\n\\n \\n\\n89.0\\n\\n\\n \\n\\n83.7\\n\\n\\n  Travel and promotional expenses\\n\\n\\n \\n\\n37.6\\n\\n\\n \\n\\n23.7\\n\\n\\n \\n\\n9.7\\n\\n\\n  Facilities costs\\n\\n\\n \\n\\n25.7\\n\\n\\n \\n\\n25.1\\n\\n\\n \\n\\n22.2\\n\\n\\n  Acquisition-related costs\\n\\n\\n \\n\\n7.4\\n\\n\\n \\n\\n19.9\\n\\n\\n \\n\\n15.6\\n\\n\\n  Goodwill impairment\\n\\n\\u2014\\n\\n460.9\\n\\n\\u2014\\n\\n\\n  Other expenses\\n\\n13.9\\n\\n26.0\\n\\n16.4\\n\\n\\nTotal operating expenses\\n\\n\\n \\n\\n860.1\\n\\n\\n \\n\\n1,252.1\\n\\n\\n \\n\\n670.2\\n\\n\\nOperating income\\n\\n\\n \\n\\n1,057.9\\n\\n\\n \\n\\n489.6\\n\\n\\n \\n\\n805.9\",\n",
      "  \"source\": \"Finder\",\n",
      "  \"source_id\": \"b33fcee7\",\n",
      "  \"ticker\": null,\n",
      "  \"year\": null,\n",
      "  \"page\": null\n",
      "}\n",
      "Entry 2:\n",
      "{\n",
      "  \"chunk_id\": \"row_0_chunk_1\",\n",
      "  \"text\": \"15.6\\n\\n\\n  Goodwill impairment\\n\\n\\u2014\\n\\n460.9\\n\\n\\u2014\\n\\n\\n  Other expenses\\n\\n13.9\\n\\n26.0\\n\\n16.4\\n\\n\\nTotal operating expenses\\n\\n\\n \\n\\n860.1\\n\\n\\n \\n\\n1,252.1\\n\\n\\n \\n\\n670.2\\n\\n\\nOperating income\\n\\n\\n \\n\\n1,057.9\\n\\n\\n \\n\\n489.6\\n\\n\\n \\n\\n805.9\\n\\n\\nNon-operating (expenses) income:\\n\\nInterest expense\\n\\n\\n \\n\\n(62.4)\\n\\n(60.0)\\n\\n(48.0)\\n\\n\\nInterest income\\n\\n12.0\\n\\n3.6\\n\\n0.6\\n\\n\\nEarnings in investments\\n\\n39.5\\n\\n7.2\\n\\n1.0\\n\\n\\nOther income (expense), net\\n\\n\\n \\n\\n0.6\\n\\n\\n \\n\\n(7.5)\\n\\n\\n \\n\\n(3.4)\\n\\n\\nIncome before income tax provision\\n\\n\\n \\n\\n1,047.6\\n\\n\\n \\n\\n432.9\\n\\n\\n \\n\\n756.1\\n\\n\\nIncome tax provision\\n\\n\\n \\n\\n286.2\\n\\n\\n \\n\\n197.9\\n\\n\\n \\n\\n227.1\\n\\n\\nNet income\\n\\n761.4\\n\\n235.0\\n\\n529.0\\n\\n\\nNet income allocated to participating securities\\n\\n(3.9)\\n\\n(0.9)\\n\\n(1.7)\\n\\n\\nNet income allocated to common stockholders\\n\\n\\n$\\n\\n757.5\\n\\n\\n$\\n\\n234.1\\n\\n\\n$\\n\\n527.3\\n\\n\\nBasic earnings per share\\n\\n\\n$\\n\\n7.16\\n\\n\\n$\\n\\n2.20\\n\\n\\n$\\n\\n4.93\\n\\n\\nDiluted earnings per share\\n\\n\\n$\\n\\n7.13\\n\\n\\n$\\n\\n2.19\\n\\n\\n$\\n\\n4.92\\n\\nBasic weighted average shares outstanding\\n\\n105.8\\n\\n106.3\\n\\n107.0\\n\\n\\nDiluted weighted average shares outstanding\\n\\n106.2\\n\\n106.7\\n\\n107.2\",\n",
      "  \"source\": \"Finder\",\n",
      "  \"source_id\": \"b33fcee7\",\n",
      "  \"ticker\": null,\n",
      "  \"year\": null,\n",
      "  \"page\": null\n",
      "}\n",
      "Entry 3:\n",
      "{\n",
      "  \"chunk_id\": \"row_1_chunk_0\",\n",
      "  \"text\": \"Employees\\n\\nAs of December 31, 2023, we employed 1,647 individuals in the following locations:\\n\\n\\nLocation\\n\\n\\nNumber of Employees\\n\\nUnited States\\n\\n\\n 1,107\\n\\nUnited Kingdom\\n\\n\\n 186\\n\\nNetherlands\\n\\n\\n 125\\n\\nCanada\\n\\n\\n 80\\n\\nAustralia\\n\\n\\n 78\\n\\nPhilippines\\n\\n\\n 30\\n\\nJapan\\n\\n\\n 26\\n\\nSingapore\\n\\n\\n 9\\n\\nHong Kong\\n\\n\\n 5\\n\\nSwitzerland\\n\\n\\n 1\\n\\nOf these employees, 595 were involved in technology operations and 185 were involved in direct support of trading operations. The remaining 867 employees provide business development, financial, regulation, human resources, compliance, legal, planning and research, administrative, and managerial support.  \\n\\nWe have three building engineers that are covered by a collective bargaining agreement, which expires on March 31, 2024, with the International Union of Operating Engineers Local 399, AFL-CIO. Management believes that we have strong relationships with our employees, and we have never experienced a work stoppage.\",\n",
      "  \"source\": \"Finder\",\n",
      "  \"source_id\": \"b8a1383c\",\n",
      "  \"ticker\": null,\n",
      "  \"year\": null,\n",
      "  \"page\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Paths to your files\n",
    "file1 = '/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/embedded_chunks.json'\n",
    "file2 = '/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/existing_embeddings_with_meta_data.jsonl'\n",
    "\n",
    "# Inspect first few entries from embedded_chunks.json\n",
    "print(\"üìÅ embedded_chunks.json\")\n",
    "with open(file1, 'r') as f:\n",
    "    data_json = json.load(f)\n",
    "\n",
    "print(f\"Type: {type(data_json)}\")\n",
    "if isinstance(data_json, list):\n",
    "    print(f\"Loaded {len(data_json)} entries\")\n",
    "    print(\"Sample entry:\")\n",
    "    print(json.dumps(data_json[0], indent=2))\n",
    "else:\n",
    "    print(\"Top-level keys:\", list(data_json.keys()))\n",
    "    first_key = next(iter(data_json))\n",
    "    print(\"Sample entry:\")\n",
    "    print(json.dumps(data_json[first_key], indent=2))\n",
    "\n",
    "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "\n",
    "# Inspect first few entries from existing_embeddings_with_meta_data.jsonl\n",
    "print(\"üìÅ existing_embeddings_with_meta_data.jsonl\")\n",
    "with open(file2, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        entry = json.loads(line)\n",
    "        print(f\"Entry {i+1}:\")\n",
    "        print(json.dumps(entry, indent=2))\n",
    "        if i >= 2:\n",
    "            break  # just show 3 entries max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838befd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS cosine index and metadata saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load embeddings from embedded_chunks.json\n",
    "with open('/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/embedded_chunks.json', 'r') as f:\n",
    "    embedded_data = json.load(f)\n",
    "\n",
    "# Create lists for vectors and IDs\n",
    "vectors = []\n",
    "ids = []\n",
    "texts = []\n",
    "\n",
    "for item in embedded_data:\n",
    "    vectors.append(item['embedding'])\n",
    "    ids.append(item['chunk_id'])\n",
    "    texts.append(item['text'])\n",
    "\n",
    "# Convert to float32 numpy array\n",
    "embedding_matrix = np.array(vectors).astype('float32')\n",
    "\n",
    "# üîÑ Normalize vectors to unit length (for cosine similarity)\n",
    "faiss.normalize_L2(embedding_matrix)\n",
    "\n",
    "# Use Inner Product index (cosine similarity after normalization)\n",
    "dimension = embedding_matrix.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(embedding_matrix)\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, 'faiss_index.idx')\n",
    "\n",
    "# Load metadata from JSONL\n",
    "metadata_dict = {}\n",
    "with open('/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/existing_embeddings_with_meta_data.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        meta = json.loads(line)\n",
    "        chunk_id = meta['chunk_id']\n",
    "        metadata_dict[chunk_id] = meta\n",
    "\n",
    "# Save chunk_id order and metadata\n",
    "with open('retriever_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump({'chunk_ids': ids, 'metadata': metadata_dict}, f)\n",
    "\n",
    "print(\"‚úÖ FAISS cosine index and metadata saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 results for query: \"What was the operating income for Cboe Global Markets in 2023?\"\n",
      "\n",
      "--- Rank 1 ---\n",
      "Score (cosine sim): 0.8828\n",
      "Source: Finder\n",
      "Text:\n",
      "Cboe Global Markets, Inc. and Subsidiaries\n",
      "\n",
      "Consolidated Statements of Income\n",
      "\n",
      "Years ended December 31, 2023, 2022, and 2021\n",
      "\n",
      "(In millions, except per share data)\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "2023\n",
      "\n",
      "    \n",
      "\n",
      "2022\n",
      "\n",
      "    \n",
      "\n",
      "2021\n",
      "\n",
      " \n",
      "\n",
      "Revenues:\n",
      "\n",
      "Cash and spot markets\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "1,445.1\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "1,777.6\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "1,660.5\n",
      "\n",
      "\n",
      "Data and access solutions\n",
      "\n",
      "539.2\n",
      "\n",
      "497.0\n",
      "\n",
      "427.7\n",
      "\n",
      "\n",
      "Derivatives markets\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "1,789.2\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "1,683.9\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "1,406.6\n",
      "\n",
      "\n",
      "Total revenues\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "3,773.5\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "3,958.5\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "3,494.8\n",
      "\n",
      "\n",
      "Cost of revenues:\n",
      "\n",
      "  Liquidity payments\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "1,385.8\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "1,670.2\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "1,650.7\n",
      "\n",
      "\n",
      "  Routing and clearing\n",
      "\n",
      "79.1\n",
      "\n",
      "83.2\n",
      "\n",
      "87.8\n",
      "\n",
      "\n",
      "  Section 31 fees\n",
      "\n",
      "185.7\n",
      "\n",
      "329.8\n",
      "\n",
      "179.6\n",
      "\n",
      "\n",
      "  Royalty fees and other cost of revenues\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "204.9\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "133.6\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "100.6\n",
      "\n",
      "\n",
      "Total cost of \n",
      "--------------------------------------------------------------------------------\n",
      "--- Rank 881 ---\n",
      "Score (cosine sim): 0.8424\n",
      "Source: None\n",
      "Text:\n",
      "Segment operating income increased $323 million (18.3%), primarily due to higher net pricing, the impact of our Clif Bar acquisition, higher operating results from the divested developed market gum business, lower costs incurred for the Simplify to Grow Program and lapping prior year inventory step-up charges. These favorable items were partially offset by higher raw material costs, higher advertising and consumer promotion costs, higher acquisition integration costs and contingent consideration adjustments, higher other selling, general and administrative expenses, an intangible asset impairment charge incurred in 2023, divestiture-related costs incurred in 2023, unfavorable volume/mix and \n",
      "--------------------------------------------------------------------------------\n",
      "--- Rank 1763 ---\n",
      "Score (cosine sim): 0.8415\n",
      "Source: Finder\n",
      "Text:\n",
      "The following is a description of our strategic initiatives:\n",
      "Maximize Futures and Options Growth Globally ‚Äî We continue to focus on driving growth and new customer acquisition by expanding, innovating and scaling our core offerings, and increasing participation from non-U.S. customers. We do this by optimizing our global sales team, cross-selling certain products, expanding the strength of our existing benchmark products, launching new products and services, strengthening our existing product and service offerings, securing intellectual property rights to new products, enhancing our relationships and broadening our base of distribution partners, and deepening open interest in our core future\n",
      "--------------------------------------------------------------------------------\n",
      "--- Rank 876 ---\n",
      "Score (cosine sim): 0.8369\n",
      "Source: None\n",
      "Text:\n",
      "Segment operating income increased $497 million (33.6%), primarily due to higher net pricing, lower impact from the European Commission legal matter, lapping the prior year incremental costs incurred due to the war in Ukraine, lower acquisition integration costs and favorable volume/mix. These favorable items were partially offset by higher raw material costs, higher advertising and consumer promotion costs, unfavorable currency, divestiture-related costs incurred in 2023, higher costs incurred for the Simplify to Grow Program, higher other selling, general and administrative expenses, higher remeasurement loss on net monetary position, higher manufacturing costs and an intangible asset impa\n",
      "--------------------------------------------------------------------------------\n",
      "--- Rank 31 ---\n",
      "Score (cosine sim): 0.8304\n",
      "Source: None\n",
      "Text:\n",
      "As a result of the items above, net income for the year ended December 31, 2023 was $761.4 million, or 40% of revenues less cost of revenues, compared to $235.0 million, or 14% of revenues less cost of revenues, for the year ended December 31, 2022, an increase of $526.4 million, or 224%.\n",
      "\n",
      "Segment Operating Results\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize your embedder\n",
    "embedder = init_embedder()\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/faiss_index.idx\")  # or your full path\n",
    "\n",
    "# Load metadata\n",
    "with open(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/retriever_metadata.pkl\", \"rb\") as f:\n",
    "    import pickle\n",
    "    data = pickle.load(f)\n",
    "    chunk_ids = data[\"chunk_ids\"]\n",
    "    metadata_dict = data[\"metadata\"]\n",
    "\n",
    "# Embed your query\n",
    "query = \"What was the operating income for Cboe Global Markets in 2023?\"\n",
    "query_embedding = embedder.embed_query(query)\n",
    "query_embedding = np.array(query_embedding, dtype=\"float32\").reshape(1, -1)\n",
    "faiss.normalize_L2(query_embedding)  # Ensure cosine norm\n",
    "\n",
    "# Search top-k\n",
    "k = 5\n",
    "D, I = index.search(query_embedding, k)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTop {k} results for query: \\\"{query}\\\"\\n\")\n",
    "for idx, score in zip(I[0], D[0]):\n",
    "    chunk_id = chunk_ids[idx]\n",
    "    metadata = metadata_dict[chunk_id]\n",
    "    \n",
    "    print(f\"--- Rank {idx+1} ---\")\n",
    "    print(f\"Score (cosine sim): {score:.4f}\")\n",
    "    print(f\"Source: {metadata.get('source', 'N/A')}\")\n",
    "    print(f\"Text:\\n{metadata.get('text', '')[:700]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73c040",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "773afab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Reference context NOT found in indexed chunks.\n",
      "‚ùå Reference context NOT found in indexed chunks.\n",
      "\n",
      "üîç Evaluating FinQA subset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b187048365456c97e3f463dfe757cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FinQA Metrics per Sample:\n",
      "\n",
      "--- Sample 1 ---\n",
      "Question: In the financial filing of Citigroup, what percentage of incremental risk-weighted assets are student loans at january 1 , 2010?\n",
      "Response: 3.54%\n",
      "Reference Answer: 4%\n",
      "Context Sample:\n",
      "['commitments .', 'for a further description of the loan loss reserve and related accounts , see 201cmanaging global risk 201d and notes 1 and 18 to the consolidated financial statements on pages 51 , 122 and 165 , respectively .', 'securitizations the company securitizes a number of different asset classes as a means of strengthening its balance sheet and accessing competitive financing rates in the market .', 'under these securitization programs , assets are sold into a trust and used as colla...\n",
      "\n",
      "reference_contexts: ['in billions of dollars the student loans of incremental gaap assets is 14.4 ; the student loans of incremental risk- weighted assets is 3.5 ;', 'in billions of dollars the total of incremental gaap assets is $ 179.0 ; the total of incremental risk- weighted assets is $ 98.9 ;']\n",
      "llm_context_precision_with_reference: 0.0000\n",
      "non_llm_context_precision_with_reference: 0.0000\n",
      "context_recall: 0.0000\n",
      "non_llm_context_recall: 0.0000\n",
      "context_entity_recall: 0.0000\n",
      "faithfulness: 1.0000\n",
      "nv_accuracy: 0.5000\n",
      "string_present: 1.0000\n",
      "\n",
      "--- Sample 2 ---\n",
      "Question: what is the growth rate in net revenue in 2003 for entergy corporation?\n",
      "Response: 0.1164\n",
      "Reference Answer: 0.1%\n",
      "Context Sample:\n",
      "[\"entergy corporation and subsidiaries management's financial discussion and analysis 2022 the deferral in august 2004 of $ 7.5 million of fossil plant maintenance and voluntary severance program costs at entergy new orleans as a result of a stipulation approved by the city council .\", \"2003 compared to 2002 net revenue , which is entergy's measure of gross margin , consists of operating revenues net of : 1 ) fuel , fuel-related , and purchased power expenses and 2 ) other regulatory credits .\",...\n",
      "\n",
      "reference_contexts: ['the 2002 net revenue of ( in millions ) is $ 4209.6 ;', 'the 2003 net revenue of ( in millions ) is $ 4214.5 ;']\n",
      "llm_context_precision_with_reference: 1.0000\n",
      "non_llm_context_precision_with_reference: 0.0000\n",
      "context_recall: 0.0000\n",
      "non_llm_context_recall: 0.0000\n",
      "context_entity_recall: 0.0000\n",
      "faithfulness: 1.0000\n",
      "nv_accuracy: 0.2500\n",
      "string_present: 0.0000\n",
      "\n",
      "üîç Evaluating FinDER subset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ff89bebcb246139911922a5ae8bae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FinDER Metrics per Sample:\n",
      "\n",
      "--- Sample 1 ---\n",
      "Question: GM operating margin 2023 vs 2022, GM.\n",
      "Response: 2023 = 5.4 %‚ÄÉvs.‚ÄÉ2022 = 6.6 %\n",
      "Reference Answer: To calculate the operating profit margin, we divide Operating Income by Total Net Sales and Revenue. For 2023, the calculation is as follows:\n",
      "\n",
      "‚Ä¢ 2023 Operating Profit Margin = 9,298 / 171,842 ‚âà 0.0541, or about 5.41%.\n",
      "\n",
      "For 2022, using the same method:\n",
      "\n",
      "‚Ä¢ 2022 Operating Profit Margin = 10,315 / 156,735 ‚âà 0.0658, or about 6.58%.\n",
      "\n",
      "This comparison shows that the operating margin declined from approximately 6.58% in 2022 to about 5.41% in 2023.\n",
      "Context Sample:\n",
      "Engineering\n",
      "(Dollar amounts in millions)\t\t \t\tVariance\n",
      "Year Ended December 31,\t\t2023\t\t2022\t\t2023 vs. 2022\n",
      "Sales\t\t$\t2,160 \t\t\t$\t2,762 \t\t\t(22)\t%\n",
      "Operating profit\t\t$\t491 \t\t\t$\t555 \t\t\t(12)\t%\n",
      "As a percent of sales\t\t22.7 \t%\t\t20.1 \t%\t\t\n",
      " \n",
      "2023 vs. 2022\n",
      " \t\t% Change\n",
      "Factors Contributing to Changes - Sales\t\t\n",
      "Currency\t\t1 \t%\n",
      "Other\t\t(23)\t%\n",
      "(22)\t%\n",
      " \n",
      "Sales\n",
      "Engineering segment sales decreased $602 million, or 22%, in 2023 versus 2022 . The decrease was driven by project timing.\n",
      "\n",
      "Projects for Russia that were sancti...\n",
      "\n",
      "faithfulness: 0.0000\n",
      "nv_accuracy: 1.0000\n",
      "\n",
      "--- Sample 2 ---\n",
      "Question: NGC's cyber investments boost investor confidence, enhance valuation, and bolster stability.\n",
      "Response: By continually expanding its cybersecurity spending, maintaining 16 SOC 2 certifications, engaging in sector ISACs, and giving the Board quarterly oversight, NGC shows a proactive, industry-leading defense posture that has so far prevented material breaches. This robust program signals prudent risk management to investors, supporting valuation multiples and reinforcing the company‚Äôs long-term financial stability.\n",
      "Reference Answer: The provided information allows us to assess how Northrop Grumman‚Äôs investments in cybersecurity can bolster investor confidence and reinforce long-term valuation stability. Specifically, the company‚Äôs focus on a multi-layered defense approach, including a dedicated Cybersecurity Operations Center that offers round-the-clock monitoring, continuous threat detection, and rapid incident response, minimizes the risk of cyber breaches. This proactive posture reduces the likelihood of disruptions that might otherwise negatively impact financial performance, cash flows, and overall operational stability.\n",
      "\n",
      "Additionally, regular third-party assessments further validate the robustness of the company‚Äôs cybersecurity measures. These independent reviews help ensure that any vulnerabilities are identified and addressed promptly while reinforcing the credibility of the company‚Äôs risk management strategies. The integration of these investments into regular risk oversight through the board, executive risk committees, and specialized groups (like the Audit and Risk Committee) supports transparency and effective governance.\n",
      "\n",
      "In summary, these cybersecurity investments contribute to investor confidence by mitigating potential risks linked to cyber threats, thereby protecting the company‚Äôs financial health and ensuring that valuation remains stable over the long term. While no direct calculations are provided, the qualitative link between enhanced cybersecurity measures and reduced uncertainty around operational and financial risks is evident from the details discussed.\n",
      "Context Sample:\n",
      "We invest in enhancing our cybersecurity capabilities and strengthening our partnerships with appropriate business partners, service partners, and government and law enforcement agencies to understand the range of cybersecurity risks in the operating environment, enhance defenses, and improve resiliency against cybersecurity threats. Additionally, we are a member of the Financial Services and Information Technology ISACs and both a founding member and board member of the Automotive ISAC. Our mem...\n",
      "\n",
      "faithfulness: 0.6667\n",
      "nv_accuracy: 0.7500\n",
      "\n",
      "‚úÖ Evaluation complete. Results saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "\n",
    "\n",
    "# === Paths ===\n",
    "BASE_DIR = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)\")\n",
    "FAISS_PATH = BASE_DIR / \"faiss_index.idx\"\n",
    "META_PATH = BASE_DIR / \"retriever_metadata.pkl\"\n",
    "GOLD_PATH = Path(\"../data/data_processed/Train_Val_Test/gold_test_data_updated.json\")\n",
    "\n",
    "# === Load Metadata and FAISS Index ===\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    chunk_ids = data[\"chunk_ids\"]\n",
    "    metadata_dict = data[\"metadata\"]\n",
    "\n",
    "index = faiss.read_index(str(FAISS_PATH))\n",
    "\n",
    "# === Load Embedder and Generator ===\n",
    "embedder = init_embedder()\n",
    "generator = ChatGPTGenerator()\n",
    "reranker = CrossEncoderReranker()\n",
    "\n",
    "# === Load Gold Test Data ===\n",
    "with open(GOLD_PATH) as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# === Generate Evaluation Dataset ===\n",
    "finqa_eval_dataset = []\n",
    "finder_eval_dataset = []\n",
    "finqa_count = 0\n",
    "finder_count = 0\n",
    "\n",
    "for sample in gold_data:\n",
    "    if finqa_count >= 2 and finder_count >= 2:\n",
    "        break\n",
    "\n",
    "    question = sample[\"question\"]\n",
    "    reference = sample[\"answer\"]\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "\n",
    "    # Embed and retrieve\n",
    "    query_embedding = np.array(embedder.embed_query(question), dtype=\"float32\").reshape(1, -1)\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    D, I = index.search(query_embedding, 50)\n",
    "\n",
    "    candidate_docs = [\n",
    "        metadata_dict[chunk_ids[i]]\n",
    "        for i in I[0]\n",
    "        if chunk_ids[i] in metadata_dict and \"text\" in metadata_dict[chunk_ids[i]]\n",
    "    ]\n",
    "    reranked_docs = reranker.rerank(question, candidate_docs, top_k=10)\n",
    "\n",
    "    # Generate answer\n",
    "    response = generator.generate(question, [doc[\"text\"] for doc in reranked_docs])\n",
    "\n",
    "    # Prepare record for RAGAS\n",
    "    record = {\n",
    "        \"user_input\": question,\n",
    "        \"retrieved_contexts\": [doc[\"text\"] for doc in reranked_docs],\n",
    "        \"response\": response,\n",
    "        \"reference\": reference,\n",
    "    }\n",
    "\n",
    "    # === Check if reference context exists in indexed corpus ===\n",
    "    reference_contexts = []\n",
    "    if isinstance(gold_context, dict):\n",
    "        reference_contexts = list(gold_context.values())\n",
    "    elif isinstance(gold_context, str) and gold_context.strip():\n",
    "        reference_contexts = [gold_context.strip()]\n",
    "\n",
    "    if reference_contexts:\n",
    "        record[\"reference_contexts\"] = reference_contexts\n",
    "        found = False\n",
    "        for ref in reference_contexts:\n",
    "            ref_clean = ref.lower().strip()\n",
    "            for chunk_data in metadata_dict.values():\n",
    "                if ref_clean in chunk_data.get(\"text\", \"\").lower():\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "        if found:\n",
    "            print(\"‚úÖ Reference context FOUND in indexed chunks.\")\n",
    "        else:\n",
    "            print(\"‚ùå Reference context NOT found in indexed chunks.\")\n",
    "\n",
    "    # === Append to dataset ===\n",
    "    if reference_contexts and finqa_count < 2:\n",
    "        finqa_eval_dataset.append(record)\n",
    "        finqa_count += 1\n",
    "    elif not reference_contexts and finder_count < 2:\n",
    "        finder_eval_dataset.append(record)\n",
    "        finder_count += 1\n",
    "\n",
    "# === Evaluate FinQA Subset ===\n",
    "print(\"\\nüîç Evaluating FinQA subset...\")\n",
    "finqa_result = asyncio.run(evaluate_ragas_dataset(finqa_eval_dataset))\n",
    "finqa_df = finqa_result.to_pandas()\n",
    "\n",
    "print(f\"\\nüéØ FinQA Metrics per Sample:\")\n",
    "for i, row in finqa_df.iterrows():\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Question: {row['user_input']}\")\n",
    "    print(f\"Response: {row['response']}\")\n",
    "    print(f\"Reference Answer: {row['reference']}\")\n",
    "    print(f\"Context Sample:\\n{row['retrieved_contexts'][0][:500]}...\\n\")\n",
    "\n",
    "    for col in finqa_df.columns:\n",
    "        if col not in ['user_input', 'retrieved_contexts', 'response', 'reference']:\n",
    "            value = row[col]\n",
    "            try:\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"{col}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{col}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{col}: ‚ö†Ô∏è Error printing value ({type(value)}): {e}\")\n",
    "\n",
    "# === Evaluate FinDER Subset ===\n",
    "print(\"\\nüîç Evaluating FinDER subset...\")\n",
    "finder_result = asyncio.run(evaluate_ragas_dataset(\n",
    "    finder_eval_dataset,\n",
    "    metrics_list=[\"faithfulness\", \"answer_accuracy\"]\n",
    "))\n",
    "finder_df = finder_result.to_pandas()\n",
    "\n",
    "print(f\"\\nüéØ FinDER Metrics per Sample:\")\n",
    "for i, row in finder_df.iterrows():\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Question: {row['user_input']}\")\n",
    "    print(f\"Response: {row['response']}\")\n",
    "    print(f\"Reference Answer: {row['reference']}\")\n",
    "    print(f\"Context Sample:\\n{row['retrieved_contexts'][0][:500]}...\\n\")\n",
    "\n",
    "    for col in finder_df.columns:\n",
    "        if col not in ['user_input', 'retrieved_contexts', 'response', 'reference']:\n",
    "            value = row[col]\n",
    "            try:\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"{col}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{col}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{col}: ‚ö†Ô∏è Error printing value ({type(value)}): {e}\")\n",
    "\n",
    "# === Save to CSV ===\n",
    "finqa_df.to_csv(\"finqa_eval_detailed.csv\", index=False)\n",
    "finder_df.to_csv(\"finder_eval_detailed.csv\", index=False)\n",
    "print(\"\\n‚úÖ Evaluation complete. Results saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1a9f91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Gold context coverage in index: 0/133 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def fuzzy_match(a, b, threshold=0.85):\n",
    "    return SequenceMatcher(None, a, b).ratio() >= threshold\n",
    "\n",
    "def check_gold_context_coverage(reference_contexts, metadata_dict):\n",
    "    for ref in reference_contexts:\n",
    "        ref = ref.lower().strip()\n",
    "        for chunk in metadata_dict.values():\n",
    "            text = chunk.get(\"text\", \"\").lower()\n",
    "            if fuzzy_match(ref, text):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Count how many reference contexts are covered\n",
    "found_count = 0\n",
    "total = 0\n",
    "\n",
    "for sample in gold_data:\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "    reference_contexts = []\n",
    "    if isinstance(gold_context, dict):\n",
    "        reference_contexts = list(gold_context.values())\n",
    "    elif isinstance(gold_context, str) and gold_context.strip():\n",
    "        reference_contexts = [gold_context.strip()]\n",
    "    \n",
    "    if reference_contexts:\n",
    "        total += 1\n",
    "        if check_gold_context_coverage(reference_contexts, metadata_dict):\n",
    "            found_count += 1\n",
    "\n",
    "print(f\"\\nüìä Gold context coverage in index: {found_count}/{total} ({found_count / total:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef57bf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Raw chunk match found for 118/201 samples\n"
     ]
    }
   ],
   "source": [
    "# Flatten all chunk texts for brute-force search\n",
    "all_texts = [chunk[\"text\"].lower() for chunk in metadata_dict.values()]\n",
    "\n",
    "# Check if each gold context is substring of any chunk\n",
    "def is_in_raw_chunks(context: str) -> bool:\n",
    "    return any(context.lower() in text for text in all_texts)\n",
    "\n",
    "count_found = 0\n",
    "for sample in gold_data:\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "    references = list(gold_context.values()) if isinstance(gold_context, dict) else [gold_context]\n",
    "    for ref in references:\n",
    "        if is_in_raw_chunks(ref):\n",
    "            count_found += 1\n",
    "            break  # only need one match to count the sample\n",
    "\n",
    "print(f\"‚úÖ Raw chunk match found for {count_found}/{len(gold_data)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0063dcba",
   "metadata": {},
   "source": [
    "Problem: Gold context not covered in FAISS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4d30273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10130/10130 [51:49<00:00,  3.26it/s]  \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Extract and embed all texts\n",
    "all_texts = [metadata_dict[cid][\"text\"] for cid in chunk_ids if \"text\" in metadata_dict[cid]]\n",
    "all_embeddings = [embedder.embed_query(text) for text in tqdm(all_texts)]\n",
    "\n",
    "# Convert to float32 array\n",
    "embedding_matrix = np.array(all_embeddings, dtype=\"float32\")\n",
    "faiss.normalize_L2(embedding_matrix)\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = embedding_matrix.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(embedding_matrix)\n",
    "\n",
    "# Save new index (overwrite or rename)\n",
    "faiss.write_index(index, str(BASE_DIR / \"faiss_index_complete.idx\"))\n",
    "\n",
    "# Save updated mapping order\n",
    "with open(BASE_DIR / \"retriever_metadata_complete.pkl\", \"wb\") as f:\n",
    "    pickle.dump({'chunk_ids': chunk_ids, 'metadata': metadata_dict}, f)\n",
    "\n",
    "print(\"‚úÖ Re-indexing complete with full corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5d1141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Gold context found in embedded chunks: 0/133 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Load gold contexts\n",
    "with open(\"../data/data_processed/Train_Val_Test/gold_test_data_updated.json\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# Load existing embedded text chunks\n",
    "with open(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/embedded_chunks.json\") as f:\n",
    "    embedded_chunks = json.load(f)\n",
    "\n",
    "embedded_texts = [chunk[\"text\"].lower().strip() for chunk in embedded_chunks]\n",
    "\n",
    "# Fuzzy match gold context against embedded texts\n",
    "def fuzzy_match(a, b, threshold=0.85):\n",
    "    return SequenceMatcher(None, a.strip().lower(), b.strip().lower()).ratio() >= threshold\n",
    "\n",
    "def context_is_embedded(reference_contexts):\n",
    "    for ref in reference_contexts:\n",
    "        for text in embedded_texts:\n",
    "            if fuzzy_match(ref, text):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "found = 0\n",
    "total = 0\n",
    "\n",
    "for sample in gold_data:\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "    reference_contexts = []\n",
    "\n",
    "    if isinstance(gold_context, dict):\n",
    "        reference_contexts = list(gold_context.values())\n",
    "    elif isinstance(gold_context, str) and gold_context.strip():\n",
    "        reference_contexts = [gold_context.strip()]\n",
    "\n",
    "    if reference_contexts:\n",
    "        total += 1\n",
    "        if context_is_embedded(reference_contexts):\n",
    "            found += 1\n",
    "\n",
    "print(f\"\\nüìä Gold context found in embedded chunks: {found}/{total} ({found/total:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9df7490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Gold contexts in JSONL: 0/133 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# === Load existing embeddings file ===\n",
    "jsonl_path = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/existing_embeddings_with_meta_data.jsonl\")\n",
    "with open(jsonl_path) as f:\n",
    "    existing_chunks = [json.loads(line) for line in f]\n",
    "\n",
    "# Build fast search index\n",
    "all_texts = [chunk[\"text\"].lower() for chunk in existing_chunks]\n",
    "\n",
    "def fuzzy_match(a, b, threshold=0.85):\n",
    "    return SequenceMatcher(None, a, b).ratio() >= threshold\n",
    "\n",
    "# === Load gold data ===\n",
    "with open(\"../data/data_processed/Train_Val_Test/gold_test_data_updated.json\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# === Match gold context against existing chunks ===\n",
    "found = 0\n",
    "total = 0\n",
    "\n",
    "for sample in gold_data:\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "    reference_contexts = []\n",
    "\n",
    "    if isinstance(gold_context, dict):\n",
    "        reference_contexts = list(gold_context.values())\n",
    "    elif isinstance(gold_context, str) and gold_context.strip():\n",
    "        reference_contexts = [gold_context.strip()]\n",
    "\n",
    "    if reference_contexts:\n",
    "        total += 1\n",
    "        for ref in reference_contexts:\n",
    "            ref = ref.lower().strip()\n",
    "            if any(fuzzy_match(ref, chunk) for chunk in all_texts):\n",
    "                found += 1\n",
    "                break\n",
    "\n",
    "print(f\"\\nüì¶ Gold contexts in JSONL: {found}/{total} ({found / total:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27c4b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding + Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102/102 [02:45<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS + metadata written safely with streaming.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "from retrievers.vectorrag.embedder import init_embedder\n",
    "\n",
    "embedder = init_embedder()\n",
    "\n",
    "# Load raw chunk metadata\n",
    "with open(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/existing_embeddings_with_meta_data.jsonl\") as f:\n",
    "    metadata_dict = {json.loads(line)[\"chunk_id\"]: json.loads(line) for line in f}\n",
    "\n",
    "chunk_ids = list(metadata_dict.keys())\n",
    "all_texts = [metadata_dict[cid][\"text\"] for cid in chunk_ids]\n",
    "\n",
    "# === Parameters ===\n",
    "BATCH_SIZE = 100\n",
    "dimension = 1536  # for ada-002\n",
    "\n",
    "# === Init empty index\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "chunk_id_order = []\n",
    "\n",
    "# === Stream embedding and indexing\n",
    "for i in tqdm(range(0, len(all_texts), BATCH_SIZE), desc=\"Embedding + Indexing\"):\n",
    "    batch_ids = chunk_ids[i:i+BATCH_SIZE]\n",
    "    batch_texts = all_texts[i:i+BATCH_SIZE]\n",
    "\n",
    "    try:\n",
    "        embeddings = embedder.embed_documents(batch_texts)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Batch {i}-{i+BATCH_SIZE} failed: {e}\")\n",
    "        time.sleep(5)\n",
    "        embeddings = embedder.embed_documents(batch_texts)\n",
    "\n",
    "    emb_np = np.array(embeddings).astype(\"float32\")\n",
    "    faiss.normalize_L2(emb_np)\n",
    "\n",
    "    index.add(emb_np)\n",
    "    chunk_id_order.extend(batch_ids)\n",
    "\n",
    "# ‚úÖ Save final FAISS index and metadata\n",
    "faiss.write_index(index, \"faiss_index_full.idx\")\n",
    "with open(\"retriever_metadata_full.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"chunk_ids\": chunk_id_order, \"metadata\": metadata_dict}, f)\n",
    "\n",
    "print(\"‚úÖ FAISS + metadata written safely with streaming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32d9685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Index contains 10130 vectors\n",
      "üß† Metadata contains 10130 chunks\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/faiss_index_full.idx\")\n",
    "\n",
    "# Load metadata\n",
    "with open(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)/retriever_metadata_full.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "chunk_ids = meta[\"chunk_ids\"]\n",
    "metadata_dict = meta[\"metadata\"]\n",
    "\n",
    "# Sanity check\n",
    "print(f\"üî¢ Index contains {index.ntotal} vectors\")\n",
    "print(f\"üß† Metadata contains {len(metadata_dict)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0c1b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gold context match found for 118/201 samples\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load gold data\n",
    "with open(\"../data/data_processed/Train_Val_Test/gold_test_data_updated.json\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# Lowercased all chunk texts\n",
    "all_texts = [chunk[\"text\"].lower() for chunk in metadata_dict.values()]\n",
    "\n",
    "# Match function\n",
    "def is_in_indexed_chunks(context):\n",
    "    return any(context.lower() in chunk_text for chunk_text in all_texts)\n",
    "\n",
    "# Run test\n",
    "count_found = 0\n",
    "for sample in gold_data:\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "    references = list(gold_context.values()) if isinstance(gold_context, dict) else [gold_context]\n",
    "    for ref in references:\n",
    "        if is_in_indexed_chunks(ref):\n",
    "            count_found += 1\n",
    "            break  # only one match needed per sample\n",
    "\n",
    "print(f\"‚úÖ Gold context match found for {count_found}/{len(gold_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cac9863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "from ragas import EvaluationDataset, evaluate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "async def evaluate_ragas_dataset(\n",
    "    dataset: List[Dict[str, Any]],\n",
    "    metrics_list: Optional[List[str]] = None,\n",
    "    llm_model: str = \"gpt-4o-2024-11-20\",\n",
    "    llm_type: str = \"openai\",  # 'openai' or 'vllm'\n",
    "    vllm_base_url: str = \"http://localhost:8000/v1\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate a dataset using RAGAS with the new API.\n",
    "\n",
    "    Args:\n",
    "        dataset: List of dicts with keys: user_input, retrieved_contexts, response, reference\n",
    "        metrics_list: List of metric names to compute (see available_metrics below). If None, all are used.\n",
    "        llm_model: Model name (e.g., 'gpt-4o', 'gpt-3.5-turbo', 'Fin-R1')\n",
    "        llm_type: 'openai' (default) or 'vllm'\n",
    "        vllm_base_url: Base URL for vllm server (if using vllm)\n",
    "    Returns:\n",
    "        Dictionary of metric results\n",
    "    \"\"\"\n",
    "    # Metric mapping\n",
    "    from ragas.metrics import (\n",
    "        LLMContextPrecisionWithReference,\n",
    "        NonLLMContextPrecisionWithReference,\n",
    "        LLMContextRecall,\n",
    "        NonLLMContextRecall,\n",
    "        ContextEntityRecall,\n",
    "        Faithfulness,\n",
    "        AnswerAccuracy,\n",
    "        StringPresence,\n",
    "    )\n",
    "    available_metrics = {\n",
    "        \"context_precision_llm\": LLMContextPrecisionWithReference,\n",
    "        \"context_precision_nonllm\": NonLLMContextPrecisionWithReference,\n",
    "        \"context_recall_llm\": LLMContextRecall,\n",
    "        \"context_recall_nonllm\": NonLLMContextRecall,\n",
    "        \"context_entity_recall\": ContextEntityRecall,\n",
    "        \"faithfulness\": Faithfulness,\n",
    "        \"answer_accuracy\": AnswerAccuracy,\n",
    "        \"string_presence\": StringPresence,\n",
    "    }\n",
    "    # If no metrics_list, use all\n",
    "    if metrics_list is None:\n",
    "        metrics_list = list(available_metrics.keys())\n",
    "    # Instantiate metrics\n",
    "    metrics = [available_metrics[name]() for name in metrics_list if name in available_metrics]\n",
    "    if not metrics:\n",
    "        raise ValueError(\"No valid metrics selected.\")\n",
    "\n",
    "    load_dotenv()\n",
    "    if llm_type == \"openai\":\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        from ragas.llms import LangchainLLMWrapper\n",
    "        OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not OPENAI_API_KEY:\n",
    "            raise ValueError(\"OPENAI_API_KEY not found in .env file.\")\n",
    "        llm = ChatOpenAI(\n",
    "            model=llm_model,\n",
    "            api_key=OPENAI_API_KEY,\n",
    "            max_tokens=1024,         # or more, depending on context length\n",
    "            timeout=60               # increase timeout to 60s\n",
    "        )\n",
    "        evaluator_llm = LangchainLLMWrapper(llm)\n",
    "    elif llm_type == \"vllm\":\n",
    "        from langchain_community.llms import VLLMOpenAI\n",
    "        from ragas.llms import LangchainLLMWrapper\n",
    "        llm = VLLMOpenAI(model=llm_model, base_url=vllm_base_url)\n",
    "        evaluator_llm = LangchainLLMWrapper(llm)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown llm_type: {llm_type}\")\n",
    "\n",
    "    evaluation_dataset = EvaluationDataset.from_list(dataset)\n",
    "    return evaluate(\n",
    "        dataset=evaluation_dataset,\n",
    "        metrics=metrics,\n",
    "        llm=evaluator_llm\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0934c119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Reference context NOT found in indexed chunks.\n",
      "‚ùå Reference context NOT found in indexed chunks.\n",
      "\n",
      "üîç Evaluating FinQA subset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c92226a646343b4a00fffc92b4f210a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FinQA Metrics per Sample:\n",
      "\n",
      "--- Sample 1 ---\n",
      "Question: In the financial filing of Citigroup, what percentage of incremental risk-weighted assets are student loans at january 1 , 2010?\n",
      "Response: 3.54%\n",
      "Reference Answer: 4%\n",
      "Context Sample:\n",
      "['commitments .', 'for a further description of the loan loss reserve and related accounts , see 201cmanaging global risk 201d and notes 1 and 18 to the consolidated financial statements on pages 51 , 122 and 165 , respectively .', 'securitizations the company securitizes a number of different asset classes as a means of strengthening its balance sheet and accessing competitive financing rates in the market .', 'under these securitization programs , assets are sold into a trust and used as colla...\n",
      "\n",
      "reference_contexts: ['in billions of dollars the student loans of incremental gaap assets is 14.4 ; the student loans of incremental risk- weighted assets is 3.5 ;', 'in billions of dollars the total of incremental gaap assets is $ 179.0 ; the total of incremental risk- weighted assets is $ 98.9 ;']\n",
      "llm_context_precision_with_reference: 1.0000\n",
      "non_llm_context_precision_with_reference: 0.0000\n",
      "context_recall: 0.0000\n",
      "non_llm_context_recall: 0.0000\n",
      "context_entity_recall: 0.0000\n",
      "faithfulness: 1.0000\n",
      "nv_accuracy: 0.5000\n",
      "string_present: 1.0000\n",
      "\n",
      "--- Sample 2 ---\n",
      "Question: what is the growth rate in net revenue in 2003 for entergy corporation?\n",
      "Response: 0.12%\n",
      "Reference Answer: 0.1%\n",
      "Context Sample:\n",
      "[\"entergy corporation and subsidiaries management's financial discussion and analysis 2022 the deferral in august 2004 of $ 7.5 million of fossil plant maintenance and voluntary severance program costs at entergy new orleans as a result of a stipulation approved by the city council .\", \"2003 compared to 2002 net revenue , which is entergy's measure of gross margin , consists of operating revenues net of : 1 ) fuel , fuel-related , and purchased power expenses and 2 ) other regulatory credits .\",...\n",
      "\n",
      "reference_contexts: ['the 2002 net revenue of ( in millions ) is $ 4209.6 ;', 'the 2003 net revenue of ( in millions ) is $ 4214.5 ;']\n",
      "llm_context_precision_with_reference: 1.0000\n",
      "non_llm_context_precision_with_reference: 0.0000\n",
      "context_recall: 0.0000\n",
      "non_llm_context_recall: 0.0000\n",
      "context_entity_recall: 0.0000\n",
      "faithfulness: 1.0000\n",
      "nv_accuracy: 0.2500\n",
      "string_present: 0.0000\n",
      "\n",
      "üîç Evaluating FinDER subset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00b21be02f34fd1aba86b3f2288fac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FinDER Metrics per Sample:\n",
      "\n",
      "--- Sample 1 ---\n",
      "Question: GM operating margin 2023 vs 2022, GM.\n",
      "Response: 2023: 5.4 %‚ÄÉvs‚ÄÉ2022: 6.6 %\n",
      "Reference Answer: To calculate the operating profit margin, we divide Operating Income by Total Net Sales and Revenue. For 2023, the calculation is as follows:\n",
      "\n",
      "‚Ä¢ 2023 Operating Profit Margin = 9,298 / 171,842 ‚âà 0.0541, or about 5.41%.\n",
      "\n",
      "For 2022, using the same method:\n",
      "\n",
      "‚Ä¢ 2022 Operating Profit Margin = 10,315 / 156,735 ‚âà 0.0658, or about 6.58%.\n",
      "\n",
      "This comparison shows that the operating margin declined from approximately 6.58% in 2022 to about 5.41% in 2023.\n",
      "Context Sample:\n",
      "Engineering\n",
      "(Dollar amounts in millions)\t\t \t\tVariance\n",
      "Year Ended December 31,\t\t2023\t\t2022\t\t2023 vs. 2022\n",
      "Sales\t\t$\t2,160 \t\t\t$\t2,762 \t\t\t(22)\t%\n",
      "Operating profit\t\t$\t491 \t\t\t$\t555 \t\t\t(12)\t%\n",
      "As a percent of sales\t\t22.7 \t%\t\t20.1 \t%\t\t\n",
      " \n",
      "2023 vs. 2022\n",
      " \t\t% Change\n",
      "Factors Contributing to Changes - Sales\t\t\n",
      "Currency\t\t1 \t%\n",
      "Other\t\t(23)\t%\n",
      "(22)\t%\n",
      " \n",
      "Sales\n",
      "Engineering segment sales decreased $602 million, or 22%, in 2023 versus 2022 . The decrease was driven by project timing.\n",
      "\n",
      "Projects for Russia that were sancti...\n",
      "\n",
      "faithfulness: 0.0000\n",
      "nv_accuracy: 1.0000\n",
      "\n",
      "--- Sample 2 ---\n",
      "Question: NGC's cyber investments boost investor confidence, enhance valuation, and bolster stability.\n",
      "Response: NGC‚Äôs ongoing spend on SOC-2-certified, ISO-27001-aligned defenses, third-party penetration tests, cloud-vendor audits and board-level oversight signals rigorous risk management, giving investors confidence that major breaches‚Äîand their financial fallout‚Äîare unlikely. That credibility supports a stronger valuation multiple and preserves the firm‚Äôs long-term operating and liquidity stability.\n",
      "Reference Answer: The provided information allows us to assess how Northrop Grumman‚Äôs investments in cybersecurity can bolster investor confidence and reinforce long-term valuation stability. Specifically, the company‚Äôs focus on a multi-layered defense approach, including a dedicated Cybersecurity Operations Center that offers round-the-clock monitoring, continuous threat detection, and rapid incident response, minimizes the risk of cyber breaches. This proactive posture reduces the likelihood of disruptions that might otherwise negatively impact financial performance, cash flows, and overall operational stability.\n",
      "\n",
      "Additionally, regular third-party assessments further validate the robustness of the company‚Äôs cybersecurity measures. These independent reviews help ensure that any vulnerabilities are identified and addressed promptly while reinforcing the credibility of the company‚Äôs risk management strategies. The integration of these investments into regular risk oversight through the board, executive risk committees, and specialized groups (like the Audit and Risk Committee) supports transparency and effective governance.\n",
      "\n",
      "In summary, these cybersecurity investments contribute to investor confidence by mitigating potential risks linked to cyber threats, thereby protecting the company‚Äôs financial health and ensuring that valuation remains stable over the long term. While no direct calculations are provided, the qualitative link between enhanced cybersecurity measures and reduced uncertainty around operational and financial risks is evident from the details discussed.\n",
      "Context Sample:\n",
      "We invest in enhancing our cybersecurity capabilities and strengthening our partnerships with appropriate business partners, service partners, and government and law enforcement agencies to understand the range of cybersecurity risks in the operating environment, enhance defenses, and improve resiliency against cybersecurity threats. Additionally, we are a member of the Financial Services and Information Technology ISACs and both a founding member and board member of the Automotive ISAC. Our mem...\n",
      "\n",
      "faithfulness: 0.5455\n",
      "nv_accuracy: 0.7500\n",
      "\n",
      "‚úÖ Evaluation complete. Results saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "\n",
    "\n",
    "# === Paths ===\n",
    "BASE_DIR = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)\")\n",
    "FAISS_PATH = BASE_DIR / \"faiss_index_full.idx\"\n",
    "META_PATH = BASE_DIR / \"retriever_metadata_full.pkl\"\n",
    "GOLD_PATH = Path(\"../data/data_processed/Train_Val_Test/gold_test_data_updated.json\")\n",
    "\n",
    "# === Load Metadata and FAISS Index ===\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    chunk_ids = data[\"chunk_ids\"]\n",
    "    metadata_dict = data[\"metadata\"]\n",
    "\n",
    "index = faiss.read_index(str(FAISS_PATH))\n",
    "\n",
    "# === Load Embedder and Generator ===\n",
    "embedder = init_embedder()\n",
    "generator = ChatGPTGenerator()\n",
    "reranker = CrossEncoderReranker()\n",
    "\n",
    "# === Load Gold Test Data ===\n",
    "with open(GOLD_PATH) as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# === Generate Evaluation Dataset ===\n",
    "finqa_eval_dataset = []\n",
    "finder_eval_dataset = []\n",
    "finqa_count = 0\n",
    "finder_count = 0\n",
    "\n",
    "for sample in gold_data:\n",
    "    if finqa_count >= 2 and finder_count >= 2:\n",
    "        break\n",
    "\n",
    "    question = sample[\"question\"]\n",
    "    reference = sample[\"answer\"]\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "\n",
    "    # Embed and retrieve\n",
    "    query_embedding = np.array(embedder.embed_query(question), dtype=\"float32\").reshape(1, -1)\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    D, I = index.search(query_embedding, 50)\n",
    "\n",
    "    candidate_docs = [\n",
    "        metadata_dict[chunk_ids[i]]\n",
    "        for i in I[0]\n",
    "        if chunk_ids[i] in metadata_dict and \"text\" in metadata_dict[chunk_ids[i]]\n",
    "    ]\n",
    "    reranked_docs = reranker.rerank(question, candidate_docs, top_k=10)\n",
    "\n",
    "    # Generate answer\n",
    "    response = generator.generate(question, [doc[\"text\"] for doc in reranked_docs])\n",
    "\n",
    "    # Prepare record for RAGAS\n",
    "    record = {\n",
    "        \"user_input\": question,\n",
    "        \"retrieved_contexts\": [doc[\"text\"] for doc in reranked_docs],\n",
    "        \"response\": response,\n",
    "        \"reference\": reference,\n",
    "    }\n",
    "\n",
    "    # === Check if reference context exists in indexed corpus ===\n",
    "    reference_contexts = []\n",
    "    if isinstance(gold_context, dict):\n",
    "        reference_contexts = list(gold_context.values())\n",
    "    elif isinstance(gold_context, str) and gold_context.strip():\n",
    "        reference_contexts = [gold_context.strip()]\n",
    "\n",
    "    if reference_contexts:\n",
    "        record[\"reference_contexts\"] = reference_contexts\n",
    "        found = False\n",
    "        for ref in reference_contexts:\n",
    "            ref_clean = ref.lower().strip()\n",
    "            for chunk_data in metadata_dict.values():\n",
    "                if ref_clean in chunk_data.get(\"text\", \"\").lower():\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "        if found:\n",
    "            print(\"‚úÖ Reference context FOUND in indexed chunks.\")\n",
    "        else:\n",
    "            print(\"‚ùå Reference context NOT found in indexed chunks.\")\n",
    "\n",
    "    # === Append to dataset ===\n",
    "    if reference_contexts and finqa_count < 2:\n",
    "        finqa_eval_dataset.append(record)\n",
    "        finqa_count += 1\n",
    "    elif not reference_contexts and finder_count < 2:\n",
    "        finder_eval_dataset.append(record)\n",
    "        finder_count += 1\n",
    "\n",
    "# === Evaluate FinQA Subset ===\n",
    "print(\"\\nüîç Evaluating FinQA subset...\")\n",
    "finqa_result = asyncio.run(evaluate_ragas_dataset(finqa_eval_dataset))\n",
    "finqa_df = finqa_result.to_pandas()\n",
    "\n",
    "print(f\"\\nüéØ FinQA Metrics per Sample:\")\n",
    "for i, row in finqa_df.iterrows():\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Question: {row['user_input']}\")\n",
    "    print(f\"Response: {row['response']}\")\n",
    "    print(f\"Reference Answer: {row['reference']}\")\n",
    "    print(f\"Context Sample:\\n{row['retrieved_contexts'][0][:500]}...\\n\")\n",
    "\n",
    "    for col in finqa_df.columns:\n",
    "        if col not in ['user_input', 'retrieved_contexts', 'response', 'reference']:\n",
    "            value = row[col]\n",
    "            try:\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"{col}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{col}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{col}: ‚ö†Ô∏è Error printing value ({type(value)}): {e}\")\n",
    "\n",
    "# === Evaluate FinDER Subset ===\n",
    "print(\"\\nüîç Evaluating FinDER subset...\")\n",
    "finder_result = asyncio.run(evaluate_ragas_dataset(\n",
    "    finder_eval_dataset,\n",
    "    metrics_list=[\"faithfulness\", \"answer_accuracy\"]\n",
    "))\n",
    "finder_df = finder_result.to_pandas()\n",
    "\n",
    "print(f\"\\nüéØ FinDER Metrics per Sample:\")\n",
    "for i, row in finder_df.iterrows():\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Question: {row['user_input']}\")\n",
    "    print(f\"Response: {row['response']}\")\n",
    "    print(f\"Reference Answer: {row['reference']}\")\n",
    "    print(f\"Context Sample:\\n{row['retrieved_contexts'][0][:500]}...\\n\")\n",
    "\n",
    "    for col in finder_df.columns:\n",
    "        if col not in ['user_input', 'retrieved_contexts', 'response', 'reference']:\n",
    "            value = row[col]\n",
    "            try:\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"{col}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{col}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{col}: ‚ö†Ô∏è Error printing value ({type(value)}): {e}\")\n",
    "\n",
    "# === Save to CSV ===\n",
    "finqa_df.to_csv(\"finqa_eval_detailed.csv\", index=False)\n",
    "finder_df.to_csv(\"finder_eval_detailed.csv\", index=False)\n",
    "print(\"\\n‚úÖ Evaluation complete. Results saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7af50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finqa_eval_detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f11e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gold context match found for 118/201 samples\n",
      "‚úÖ Saved filtered dataset to filtered_gold_eval_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# === Load gold test data ===\n",
    "GOLD_PATH = Path(\"../data/data_processed/Train_Val_Test/gold_test_data_updated.json\")\n",
    "with open(GOLD_PATH) as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# === Lowercase all chunk texts for matching ===\n",
    "all_texts = [chunk[\"text\"].lower() for chunk in metadata_dict.values()]\n",
    "\n",
    "# === Helper: match function ===\n",
    "def is_in_indexed_chunks(context):\n",
    "    return any(context.lower() in chunk_text for chunk_text in all_texts)\n",
    "\n",
    "# === Filter matching samples ===\n",
    "filtered_eval_dataset = []\n",
    "count_found = 0\n",
    "\n",
    "for sample in gold_data:\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "    references = list(gold_context.values()) if isinstance(gold_context, dict) else [gold_context]\n",
    "\n",
    "    for ref in references:\n",
    "        if is_in_indexed_chunks(ref):\n",
    "            sample[\"reference_contexts\"] = references\n",
    "            filtered_eval_dataset.append(sample)\n",
    "            count_found += 1\n",
    "            break  # only one match needed per sample\n",
    "\n",
    "# === Report + Save ===\n",
    "print(f\"‚úÖ Gold context match found for {count_found}/{len(gold_data)} samples\")\n",
    "\n",
    "with open(\"filtered_gold_eval_dataset.json\", \"w\") as f:\n",
    "    json.dump(filtered_eval_dataset, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Saved filtered dataset to filtered_gold_eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Gold context retrieved for:\n",
      "Q: GM operating margin 2023 vs 2022, GM.\n",
      "‚úÖ Gold context RETAINED in reranked docs for:\n",
      "Q: GM operating margin 2023 vs 2022, GM.\n",
      "\n",
      "‚úÖ Gold context retrieved for:\n",
      "Q: NGC's cyber investments boost investor confidence, enhance valuation, and bolster stability.\n",
      "‚úÖ Gold context RETAINED in reranked docs for:\n",
      "Q: NGC's cyber investments boost investor confidence, enhance valuation, and bolster stability.\n",
      "‚úÖ Reference context FOUND in indexed chunks.\n",
      "\n",
      "‚úÖ Gold context retrieved for:\n",
      "Q: what was the cost per tower in American Tower‚Äôs colombia movil acquisition?\n",
      "‚úÖ Gold context RETAINED in reranked docs for:\n",
      "Q: what was the cost per tower in American Tower‚Äôs colombia movil acquisition?\n",
      "‚úÖ Reference context FOUND in indexed chunks.\n",
      "\n",
      "üîç Evaluating FinQA subset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d12c51446c4a8bb50b8a0c487d44f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FinQA Metrics per Sample:\n",
      "\n",
      "--- Sample 1 ---\n",
      "Question: Q: For GPN, what was the fair value of share awards vested in 2009?\n",
      "A: 6.2\n",
      "Q: what was the value in 2007?\n",
      "A: 1.7\n",
      "Q: what was the net change in value?\n",
      "A: A0\n",
      "Q: what is the net change divided by the 2007 value?\n",
      "Response: Simulated answer from: ['notes to consolidated financial statements 2014 ( continued ) the following table summarizes the c...\n",
      "Reference Answer: 265% increase\n",
      "Context Sample:\n",
      "['notes to consolidated financial statements 2014 ( continued ) the following table summarizes the changes in non-vested restricted stock awards for the year ended may 31 , 2009 ( share awards in thousands ) : share awards weighted average grant-date fair value .'] share awards weighted average grant-date fair value non-vested at may 31 2007 278 $ 37 granted 400 38 vested -136 ( 136 ) 30 forfeited -24 ( 24 ) 40 non-vested at may 31 2008 518 39 granted 430 43 vested -159 ( 159 ) 39 forfeited -27 ...\n",
      "\n",
      "reference_contexts: ['the total fair value of share awards vested during the years ended may 31 , 2009 , 2008 and 2007 was $ 6.2 million , $ 4.1 million and $ 1.7 million , respectively .']\n",
      "llm_context_precision_with_reference: 1.0000\n",
      "non_llm_context_precision_with_reference: 0.0000\n",
      "context_recall: 0.0000\n",
      "non_llm_context_recall: 0.0000\n",
      "context_entity_recall: nan\n",
      "faithfulness: nan\n",
      "nv_accuracy: 0.0000\n",
      "string_present: 0.0000\n",
      "\n",
      "--- Sample 2 ---\n",
      "Question: what was the cost per tower in American Tower‚Äôs colombia movil acquisition?\n",
      "Response: Simulated answer from: ['american tower corporation and subsidiaries notes to consolidated financial statements u.s .', 'ac...\n",
      "Reference Answer: 856067\n",
      "Context Sample:\n",
      "['american tower corporation and subsidiaries notes to consolidated financial statements u.s .', 'acquisitions 2014during the year ended december 31 , 2010 , the company acquired 548 towers through multiple acquisitions in the united states for an aggregate purchase price of $ 329.3 million and contingent consideration of approximately $ 4.6 million .', 'the acquisition of these towers is consistent with the company 2019s strategy to expand in selected geographic areas and have been accounted fo...\n",
      "\n",
      "reference_contexts: ['( 201ccolombia movil 201d ) , whereby atc sitios infraco , s.a.s. , a colombian subsidiary of the company ( 201catc infraco 201d ) , would purchase up to 2126 communications sites from colombia movil for an aggregate purchase price of approximately $ 182.0 million .']\n",
      "llm_context_precision_with_reference: 0.0000\n",
      "non_llm_context_precision_with_reference: 0.0000\n",
      "context_recall: 0.0000\n",
      "non_llm_context_recall: 0.0000\n",
      "context_entity_recall: 0.0000\n",
      "faithfulness: 1.0000\n",
      "nv_accuracy: 0.0000\n",
      "string_present: 0.0000\n",
      "\n",
      "üîç Evaluating FinDER subset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc970b272ae4c0f918ba6784a512cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FinDER Metrics per Sample:\n",
      "\n",
      "--- Sample 1 ---\n",
      "Question: GM operating margin 2023 vs 2022, GM.\n",
      "Response: Simulated answer from: Engineering\n",
      "(Dollar amounts in millions)\t\t \t\tVariance\n",
      "Year Ended December 31,\t\t2023\t\t2022\t\t2023 vs. ...\n",
      "Reference Answer: To calculate the operating profit margin, we divide Operating Income by Total Net Sales and Revenue. For 2023, the calculation is as follows:\n",
      "\n",
      "‚Ä¢ 2023 Operating Profit Margin = 9,298 / 171,842 ‚âà 0.0541, or about 5.41%.\n",
      "\n",
      "For 2022, using the same method:\n",
      "\n",
      "‚Ä¢ 2022 Operating Profit Margin = 10,315 / 156,735 ‚âà 0.0658, or about 6.58%.\n",
      "\n",
      "This comparison shows that the operating margin declined from approximately 6.58% in 2022 to about 5.41% in 2023.\n",
      "Context Sample:\n",
      "Engineering\n",
      "(Dollar amounts in millions)\t\t \t\tVariance\n",
      "Year Ended December 31,\t\t2023\t\t2022\t\t2023 vs. 2022\n",
      "Sales\t\t$\t2,160 \t\t\t$\t2,762 \t\t\t(22)\t%\n",
      "Operating profit\t\t$\t491 \t\t\t$\t555 \t\t\t(12)\t%\n",
      "As a percent of sales\t\t22.7 \t%\t\t20.1 \t%\t\t\n",
      " \n",
      "2023 vs. 2022\n",
      " \t\t% Change\n",
      "Factors Contributing to Changes - Sales\t\t\n",
      "Currency\t\t1 \t%\n",
      "Other\t\t(23)\t%\n",
      "(22)\t%\n",
      " \n",
      "Sales\n",
      "Engineering segment sales decreased $602 million, or 22%, in 2023 versus 2022 . The decrease was driven by project timing.\n",
      "\n",
      "Projects for Russia that were sancti...\n",
      "\n",
      "faithfulness: 0.8571\n",
      "nv_accuracy: 0.0000\n",
      "\n",
      "--- Sample 2 ---\n",
      "Question: NGC's cyber investments boost investor confidence, enhance valuation, and bolster stability.\n",
      "Response: Simulated answer from: We invest in enhancing our cybersecurity capabilities and strengthening our partnerships with approp...\n",
      "Reference Answer: The provided information allows us to assess how Northrop Grumman‚Äôs investments in cybersecurity can bolster investor confidence and reinforce long-term valuation stability. Specifically, the company‚Äôs focus on a multi-layered defense approach, including a dedicated Cybersecurity Operations Center that offers round-the-clock monitoring, continuous threat detection, and rapid incident response, minimizes the risk of cyber breaches. This proactive posture reduces the likelihood of disruptions that might otherwise negatively impact financial performance, cash flows, and overall operational stability.\n",
      "\n",
      "Additionally, regular third-party assessments further validate the robustness of the company‚Äôs cybersecurity measures. These independent reviews help ensure that any vulnerabilities are identified and addressed promptly while reinforcing the credibility of the company‚Äôs risk management strategies. The integration of these investments into regular risk oversight through the board, executive risk committees, and specialized groups (like the Audit and Risk Committee) supports transparency and effective governance.\n",
      "\n",
      "In summary, these cybersecurity investments contribute to investor confidence by mitigating potential risks linked to cyber threats, thereby protecting the company‚Äôs financial health and ensuring that valuation remains stable over the long term. While no direct calculations are provided, the qualitative link between enhanced cybersecurity measures and reduced uncertainty around operational and financial risks is evident from the details discussed.\n",
      "Context Sample:\n",
      "We invest in enhancing our cybersecurity capabilities and strengthening our partnerships with appropriate business partners, service partners, and government and law enforcement agencies to understand the range of cybersecurity risks in the operating environment, enhance defenses, and improve resiliency against cybersecurity threats. Additionally, we are a member of the Financial Services and Information Technology ISACs and both a founding member and board member of the Automotive ISAC. Our mem...\n",
      "\n",
      "faithfulness: 0.4000\n",
      "nv_accuracy: 0.0000\n",
      "\n",
      "‚úÖ Evaluation complete. Results saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "\n",
    "\n",
    "# === Paths ===\n",
    "BASE_DIR = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)\")\n",
    "FAISS_PATH = BASE_DIR / \"faiss_index_full.idx\"\n",
    "META_PATH = BASE_DIR / \"retriever_metadata_full.pkl\"\n",
    "GOLD_PATH = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/notebooks/filtered_gold_eval_dataset.json\")\n",
    "\n",
    "# === Load Metadata and FAISS Index ===\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    chunk_ids = data[\"chunk_ids\"]\n",
    "    metadata_dict = data[\"metadata\"]\n",
    "\n",
    "index = faiss.read_index(str(FAISS_PATH))\n",
    "\n",
    "# === Load Embedder and Generator ===\n",
    "embedder = init_embedder()\n",
    "generator = ChatGPTGenerator()\n",
    "reranker = CrossEncoderReranker()\n",
    "\n",
    "# === Load Gold Test Data ===\n",
    "with open(GOLD_PATH) as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# === Generate Evaluation Dataset ===\n",
    "finqa_eval_dataset = []\n",
    "finder_eval_dataset = []\n",
    "finqa_count = 0\n",
    "finder_count = 0\n",
    "\n",
    "for sample in gold_data:\n",
    "    if finqa_count >= 2 and finder_count >= 2:\n",
    "        break\n",
    "\n",
    "    question = sample[\"question\"]\n",
    "    reference = sample[\"answer\"]\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "\n",
    "    # Embed and retrieve\n",
    "    query_embedding = np.array(embedder.embed_query(question), dtype=\"float32\").reshape(1, -1)\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "        # === FAISS retrieval ===\n",
    "    D, I = index.search(query_embedding, 50)\n",
    "\n",
    "    retrieved_chunks = [metadata_dict[chunk_ids[i]][\"text\"].lower() for i in I[0]]\n",
    "    candidate_docs = [\n",
    "        metadata_dict[chunk_ids[i]]\n",
    "        for i in I[0]\n",
    "        if chunk_ids[i] in metadata_dict and \"text\" in metadata_dict[chunk_ids[i]]\n",
    "    ]\n",
    "\n",
    "    # === Check if gold_context is in top-50 retrieved chunks ===\n",
    "    gold_contexts = list(gold_context.values()) if isinstance(gold_context, dict) else [gold_context]\n",
    "    gold_contexts = [ctx.lower().strip() for ctx in gold_contexts if isinstance(ctx, str)]\n",
    "\n",
    "    match_found = False\n",
    "    for gold_ctx in gold_contexts:\n",
    "        for chunk in retrieved_chunks:\n",
    "            if gold_ctx in chunk:\n",
    "                match_found = True\n",
    "                break\n",
    "        if match_found:\n",
    "            break\n",
    "\n",
    "    # Only show logs if we‚Äôre about to evaluate this question\n",
    "    if (reference_contexts and finqa_count < 2) or (not reference_contexts and finder_count < 2):\n",
    "        if not match_found:\n",
    "            print(f\"\\nGold context NOT retrieved for:\\nQ: {question}\\nGold: {gold_contexts[0][:200]}...\\n\")\n",
    "        else:\n",
    "            print(f\"\\nGold context retrieved for:\\nQ: {question}\")\n",
    "    reranked_docs = reranker.rerank(question, candidate_docs, top_k=20)\n",
    "\n",
    "    # === Check if gold_context is in reranked_docs ===\n",
    "    reranked_texts = [doc[\"text\"].lower() for doc in reranked_docs]\n",
    "    gold_in_reranked = any(\n",
    "        gold_ctx in doc_text\n",
    "        for gold_ctx in gold_contexts\n",
    "        for doc_text in reranked_texts\n",
    "    )\n",
    "\n",
    "    if (reference_contexts and finqa_count < 2) or (not reference_contexts and finder_count < 2):\n",
    "        if not gold_in_reranked:\n",
    "            print(f\"Gold context LOST after reranking for:\\nQ: {question}\")\n",
    "        else:\n",
    "            print(f\"Gold context RETAINED in reranked docs for:\\nQ: {question}\")\n",
    "\n",
    "    # Generate answer\n",
    "    response = generator.generate(question, [doc[\"text\"] for doc in reranked_docs])\n",
    "\n",
    "    # Prepare record for RAGAS\n",
    "    record = {\n",
    "        \"user_input\": question,\n",
    "        \"retrieved_contexts\": [doc[\"text\"] for doc in reranked_docs],\n",
    "        \"response\": response,\n",
    "        \"reference\": reference,\n",
    "    }\n",
    "\n",
    "    # === Check if reference context exists in indexed corpus ===\n",
    "    reference_contexts = []\n",
    "    if isinstance(gold_context, dict):\n",
    "        reference_contexts = list(gold_context.values())\n",
    "    elif isinstance(gold_context, str) and gold_context.strip():\n",
    "        reference_contexts = [gold_context.strip()]\n",
    "\n",
    "    if reference_contexts:\n",
    "        record[\"reference_contexts\"] = reference_contexts\n",
    "        found = False\n",
    "        for ref in reference_contexts:\n",
    "            ref_clean = ref.lower().strip()\n",
    "            for chunk_data in metadata_dict.values():\n",
    "                if ref_clean in chunk_data.get(\"text\", \"\").lower():\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "        if found:\n",
    "            print(\"Reference context FOUND in indexed chunks.\")\n",
    "        else:\n",
    "            print(\"Reference context NOT found in indexed chunks.\")\n",
    "\n",
    "    # === Append to dataset ===\n",
    "    if reference_contexts and finqa_count < 2:\n",
    "        finqa_eval_dataset.append(record)\n",
    "        finqa_count += 1\n",
    "    elif not reference_contexts and finder_count < 2:\n",
    "        finder_eval_dataset.append(record)\n",
    "        finder_count += 1\n",
    "\n",
    "# === Evaluate FinQA Subset ===\n",
    "print(\"\\nüîç Evaluating FinQA subset...\")\n",
    "finqa_result = asyncio.run(evaluate_ragas_dataset(finqa_eval_dataset))\n",
    "finqa_df = finqa_result.to_pandas()\n",
    "\n",
    "print(f\"\\nüéØ FinQA Metrics per Sample:\")\n",
    "for i, row in finqa_df.iterrows():\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Question: {row['user_input']}\")\n",
    "    print(f\"Response: {row['response']}\")\n",
    "    print(f\"Reference Answer: {row['reference']}\")\n",
    "    print(f\"Context Sample:\\n{row['retrieved_contexts'][0][:500]}...\\n\")\n",
    "\n",
    "    for col in finqa_df.columns:\n",
    "        if col not in ['user_input', 'retrieved_contexts', 'response', 'reference']:\n",
    "            value = row[col]\n",
    "            try:\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"{col}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{col}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{col}: ‚ö†Ô∏è Error printing value ({type(value)}): {e}\")\n",
    "\n",
    "# === Evaluate FinDER Subset ===\n",
    "print(\"\\nüîç Evaluating FinDER subset...\")\n",
    "finder_result = asyncio.run(evaluate_ragas_dataset(\n",
    "    finder_eval_dataset,\n",
    "    metrics_list=[\"faithfulness\", \"answer_accuracy\"]\n",
    "))\n",
    "finder_df = finder_result.to_pandas()\n",
    "\n",
    "print(f\"\\nüéØ FinDER Metrics per Sample:\")\n",
    "for i, row in finder_df.iterrows():\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Question: {row['user_input']}\")\n",
    "    print(f\"Response: {row['response']}\")\n",
    "    print(f\"Reference Answer: {row['reference']}\")\n",
    "    print(f\"Context Sample:\\n{row['retrieved_contexts'][0][:500]}...\\n\")\n",
    "\n",
    "    for col in finder_df.columns:\n",
    "        if col not in ['user_input', 'retrieved_contexts', 'response', 'reference']:\n",
    "            value = row[col]\n",
    "            try:\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"{col}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{col}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{col}: ‚ö†Ô∏è Error printing value ({type(value)}): {e}\")\n",
    "\n",
    "# === Save to CSV ===\n",
    "finqa_df.to_csv(\"finqa_eval_detailed.csv\", index=False)\n",
    "finder_df.to_csv(\"finder_eval_detailed.csv\", index=False)\n",
    "print(\"\\n‚úÖ Evaluation complete. Results saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b564e3ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfinqa_eval_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62916b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [00:40<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retriever Recall@50: 106/118 ‚Üí 89.83%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# === Setup Paths ===\n",
    "BASE_DIR = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)\")\n",
    "FAISS_PATH = BASE_DIR / \"faiss_index_full.idx\"\n",
    "META_PATH = BASE_DIR / \"retriever_metadata_full.pkl\"\n",
    "GOLD_PATH = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/notebooks/filtered_gold_eval_dataset.json\")\n",
    "\n",
    "# === Load FAISS Index and Metadata ===\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    chunk_ids = data[\"chunk_ids\"]\n",
    "    metadata_dict = data[\"metadata\"]\n",
    "\n",
    "index = faiss.read_index(str(FAISS_PATH))\n",
    "\n",
    "# === Load your OpenAI embedder ===\n",
    "embedder = init_embedder()\n",
    "\n",
    "# === Load Gold QA Dataset ===\n",
    "with open(GOLD_PATH) as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# === Evaluation Loop ===\n",
    "def evaluate_retriever(gold_data, embedder, top_k=50):\n",
    "    results = []\n",
    "\n",
    "    for sample in tqdm(gold_data):\n",
    "        question = sample[\"question\"]\n",
    "        gold_context_raw = sample.get(\"gold_context\", {})\n",
    "\n",
    "        # Normalize gold context\n",
    "        gold_contexts = list(gold_context_raw.values()) if isinstance(gold_context_raw, dict) else [gold_context_raw]\n",
    "        gold_contexts = [g.lower().strip() for g in gold_contexts if isinstance(g, str)]\n",
    "\n",
    "        # Embed and search\n",
    "        try:\n",
    "            q_embed = np.array(embedder.embed_query(question)).astype(\"float32\").reshape(1, -1)\n",
    "            faiss.normalize_L2(q_embed)\n",
    "            D, I = index.search(q_embed, top_k)\n",
    "        except Exception as e:\n",
    "            print(f\"Embedding failed for question: {question}\\nError: {e}\")\n",
    "            continue\n",
    "\n",
    "        retrieved_chunks = [metadata_dict[chunk_ids[i]][\"text\"].lower() for i in I[0]]\n",
    "        found = any(g in r for g in gold_contexts for r in retrieved_chunks)\n",
    "\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"gold_found_in_top_k\": found,\n",
    "            \"gold_context\": gold_contexts[0][:120] if gold_contexts else None,\n",
    "            \"first_hit_index\": next((i for i, r in enumerate(retrieved_chunks) if any(g in r for g in gold_contexts)), -1)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# === Run Evaluation ===\n",
    "df = evaluate_retriever(gold_data, embedder=embedder, top_k=50)\n",
    "df.to_csv(\"retriever_eval.csv\", index=False)\n",
    "\n",
    "# === Print Summary ===\n",
    "total = len(df)\n",
    "hits = (df[\"gold_found_in_top_k\"] == True).sum()\n",
    "print(f\"\\nRetriever Recall@50: {hits}/{total} ‚Üí {100 * hits / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e93621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reranker(gold_data, top_k_faiss=50, top_k_reranked=10):\n",
    "    reranker = CrossEncoderReranker()  # your existing reranker class\n",
    "    results = []\n",
    "\n",
    "    for sample in tqdm(gold_data):\n",
    "        question = sample[\"question\"]\n",
    "        gold_contexts = sample.get(\"gold_context\", {})\n",
    "        gold_contexts = list(gold_contexts.values()) if isinstance(gold_contexts, dict) else [gold_contexts]\n",
    "        gold_contexts = [g.lower().strip() for g in gold_contexts if isinstance(g, str)]\n",
    "\n",
    "        # FAISS\n",
    "        q_embed = np.array(init_embedder().embed_query(question)).astype(\"float32\").reshape(1, -1)\n",
    "        faiss.normalize_L2(q_embed)\n",
    "        D, I = index.search(q_embed, top_k_faiss)\n",
    "\n",
    "        candidate_docs = [\n",
    "            metadata_dict[chunk_ids[i]]\n",
    "            for i in I[0]\n",
    "            if chunk_ids[i] in metadata_dict and \"text\" in metadata_dict[chunk_ids[i]]\n",
    "        ]\n",
    "        reranked = reranker.rerank(question, candidate_docs, top_k=top_k_reranked)\n",
    "        reranked_texts = [doc[\"text\"].lower() for doc in reranked]\n",
    "\n",
    "        found = any(g in r for g in gold_contexts for r in reranked_texts)\n",
    "\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"gold_found_after_rerank\": found,\n",
    "            \"gold_context\": gold_contexts[0][:120] if gold_contexts else None,\n",
    "            \"gold_context_rank_post_rerank\": next((i for i, r in enumerate(reranked_texts) if any(g in r for g in gold_contexts)), -1)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6009d119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [01:45<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reranker Recall@10: 104/118 ‚Üí 88.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_reranked = evaluate_reranker(gold_data)\n",
    "df_reranked.to_csv(\"reranker_eval_r10.csv\", index=False)\n",
    "\n",
    "hits = (df_reranked[\"gold_found_after_rerank\"] == True).sum()\n",
    "print(f\"\\nReranker Recall@10: {hits}/{len(df_reranked)} ‚Üí {100 * hits / len(df_reranked):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bc817d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [01:19<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retriever Recall@50: 106/201 ‚Üí 52.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# === Setup Paths ===\n",
    "BASE_DIR = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)\")\n",
    "FAISS_PATH = BASE_DIR / \"faiss_index_full.idx\"\n",
    "META_PATH = BASE_DIR / \"retriever_metadata_full.pkl\"\n",
    "GOLD_PATH = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/data_processed/Train_Val_Test/gold_test_data_updated.json\")\n",
    "\n",
    "# === Load FAISS Index and Metadata ===\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    chunk_ids = data[\"chunk_ids\"]\n",
    "    metadata_dict = data[\"metadata\"]\n",
    "\n",
    "index = faiss.read_index(str(FAISS_PATH))\n",
    "\n",
    "# === Load your OpenAI embedder ===\n",
    "embedder = init_embedder()\n",
    "\n",
    "# === Load Gold QA Dataset ===\n",
    "with open(GOLD_PATH) as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# === Evaluation Loop ===\n",
    "def evaluate_retriever(gold_data, embedder, top_k=50):\n",
    "    results = []\n",
    "\n",
    "    for sample in tqdm(gold_data):\n",
    "        question = sample[\"question\"]\n",
    "        gold_context_raw = sample.get(\"gold_context\", {})\n",
    "\n",
    "        # Normalize gold context\n",
    "        gold_contexts = list(gold_context_raw.values()) if isinstance(gold_context_raw, dict) else [gold_context_raw]\n",
    "        gold_contexts = [g.lower().strip() for g in gold_contexts if isinstance(g, str)]\n",
    "\n",
    "        # Embed and search\n",
    "        try:\n",
    "            q_embed = np.array(embedder.embed_query(question)).astype(\"float32\").reshape(1, -1)\n",
    "            faiss.normalize_L2(q_embed)\n",
    "            D, I = index.search(q_embed, top_k)\n",
    "        except Exception as e:\n",
    "            print(f\"Embedding failed for question: {question}\\nError: {e}\")\n",
    "            continue\n",
    "\n",
    "        retrieved_chunks = [metadata_dict[chunk_ids[i]][\"text\"].lower() for i in I[0]]\n",
    "        found = any(g in r for g in gold_contexts for r in retrieved_chunks)\n",
    "\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"gold_found_in_top_k\": found,\n",
    "            \"gold_context\": gold_contexts[0][:120] if gold_contexts else None,\n",
    "            \"first_hit_index\": next((i for i, r in enumerate(retrieved_chunks) if any(g in r for g in gold_contexts)), -1)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# === Run Evaluation ===\n",
    "df = evaluate_retriever(gold_data, embedder=embedder, top_k=50)\n",
    "df.to_csv(\"retriever_eval.csv\", index=False)\n",
    "\n",
    "# === Print Summary ===\n",
    "total = len(df)\n",
    "hits = (df[\"gold_found_in_top_k\"] == True).sum()\n",
    "print(f\"\\nRetriever Recall@50: {hits}/{total} ‚Üí {100 * hits / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "def2ec1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [02:45<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reranker Recall@10: 104/201 ‚Üí 51.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_reranked = evaluate_reranker(gold_data)\n",
    "df_reranked.to_csv(\"reranker_eval_r10.csv\", index=False)\n",
    "\n",
    "hits = (df_reranked[\"gold_found_after_rerank\"] == True).sum()\n",
    "print(f\"\\nReranker Recall@10: {hits}/{len(df_reranked)} ‚Üí {100 * hits / len(df_reranked):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5a23e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [00:55<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retriever Recall@50: 106/118 ‚Üí 89.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# === Setup Paths ===\n",
    "BASE_DIR = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)\")\n",
    "FAISS_PATH = BASE_DIR / \"faiss_index.idx\"\n",
    "META_PATH = BASE_DIR / \"retriever_metadata.pkl\"\n",
    "GOLD_PATH = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/notebooks/filtered_gold_eval_dataset.json\")\n",
    "\n",
    "# === Load FAISS Index and Metadata ===\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    chunk_ids = data[\"chunk_ids\"]\n",
    "    metadata_dict = data[\"metadata\"]\n",
    "\n",
    "index = faiss.read_index(str(FAISS_PATH))\n",
    "\n",
    "# === Load your OpenAI embedder ===\n",
    "embedder = init_embedder()\n",
    "\n",
    "# === Load Gold QA Dataset ===\n",
    "with open(GOLD_PATH) as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# === Evaluation Loop ===\n",
    "def evaluate_retriever(gold_data, embedder, top_k=50):\n",
    "    results = []\n",
    "\n",
    "    for sample in tqdm(gold_data):\n",
    "        question = sample[\"question\"]\n",
    "        gold_context_raw = sample.get(\"gold_context\", {})\n",
    "\n",
    "        # Normalize gold context\n",
    "        gold_contexts = list(gold_context_raw.values()) if isinstance(gold_context_raw, dict) else [gold_context_raw]\n",
    "        gold_contexts = [g.lower().strip() for g in gold_contexts if isinstance(g, str)]\n",
    "\n",
    "        # Embed and search\n",
    "        try:\n",
    "            q_embed = np.array(embedder.embed_query(question)).astype(\"float32\").reshape(1, -1)\n",
    "            faiss.normalize_L2(q_embed)\n",
    "            D, I = index.search(q_embed, top_k)\n",
    "        except Exception as e:\n",
    "            print(f\"Embedding failed for question: {question}\\nError: {e}\")\n",
    "            continue\n",
    "\n",
    "        retrieved_chunks = [metadata_dict[chunk_ids[i]][\"text\"].lower() for i in I[0]]\n",
    "        found = any(g in r for g in gold_contexts for r in retrieved_chunks)\n",
    "\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"gold_found_in_top_k\": found,\n",
    "            \"gold_context\": gold_contexts[0][:120] if gold_contexts else None,\n",
    "            \"first_hit_index\": next((i for i, r in enumerate(retrieved_chunks) if any(g in r for g in gold_contexts)), -1)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# === Run Evaluation ===\n",
    "df = evaluate_retriever(gold_data, embedder=embedder, top_k=50)\n",
    "df.to_csv(\"retriever_eval.csv\", index=False)\n",
    "\n",
    "# === Print Summary ===\n",
    "total = len(df)\n",
    "hits = (df[\"gold_found_in_top_k\"] == True).sum()\n",
    "print(f\"\\nRetriever Recall@50: {hits}/{total} ‚Üí {100 * hits / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e075d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_context_recall(\n",
    "    dataset: List[Dict],\n",
    "    top_k_context_key: str = \"retrieved_contexts\",\n",
    "    gold_context_key: str = \"reference_contexts\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates context recall for each QA sample in a dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset: List of dicts. Each dict should include:\n",
    "            - \"user_input\": question\n",
    "            - top_k_context_key: list of retrieved context strings\n",
    "            - gold_context_key: list of gold/reference context strings\n",
    "        top_k_context_key: name of field containing retrieved contexts\n",
    "        gold_context_key: name of field containing gold/reference contexts\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with question, context recall, and detailed hits\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for sample in tqdm(dataset):\n",
    "        question = sample.get(\"user_input\", \"N/A\")\n",
    "        retrieved = sample.get(top_k_context_key, [])\n",
    "        gold = sample.get(gold_context_key, [])\n",
    "\n",
    "        # Normalize\n",
    "        retrieved = [r.lower().strip() for r in retrieved]\n",
    "        gold = [g.lower().strip() for g in gold]\n",
    "\n",
    "        hits = sum(any(g in r for r in retrieved) for g in gold)\n",
    "        total = len(gold)\n",
    "        recall = hits / total if total > 0 else 0.0\n",
    "\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"context_recall\": recall,\n",
    "            \"total_gold\": total,\n",
    "            \"hits_found\": hits,\n",
    "            \"missing_gold\": [g for g in gold if not any(g in r for r in retrieved)]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70437678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 295.99it/s]\n"
     ]
    }
   ],
   "source": [
    "context_recall_df = evaluate_context_recall(finqa_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "edd41596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(context_recall_df[\"context_recall\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def evaluate_context_recall(\n",
    "    dataset: List[Dict],\n",
    "    embedder,\n",
    "    top_k_context_key: str = \"retrieved_contexts\",\n",
    "    gold_context_key: str = \"reference_contexts\",\n",
    "    method: str = \"embedding\",  # \"exact\", \"embedding\", or \"both\"\n",
    "    sim_threshold: float = 0.85\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates context recall via exact match or embedding-based similarity.\n",
    "\n",
    "    Args:\n",
    "        dataset: List of QA samples with user_input, retrieved_contexts, reference_contexts\n",
    "        embedder: an object with .embed_documents() method (e.g., OpenAIEmbedder or SentenceTransformer)\n",
    "        method: \"exact\", \"embedding\", or \"both\"\n",
    "        sim_threshold: similarity threshold for embedding-based match\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with recall scores and detailed diagnostics\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for sample in tqdm(dataset):\n",
    "        question = sample.get(\"user_input\", \"N/A\")\n",
    "        retrieved = sample.get(top_k_context_key, [])\n",
    "        gold = sample.get(gold_context_key, [])\n",
    "\n",
    "        retrieved = [r.lower().strip() for r in retrieved if isinstance(r, str)]\n",
    "        gold = [g.lower().strip() for g in gold if isinstance(g, str)]\n",
    "\n",
    "        em_hits = 0\n",
    "        emb_hits = 0\n",
    "\n",
    "        # === Exact Match ===\n",
    "        if method in {\"exact\", \"both\"}:\n",
    "            em_hits = sum(any(g in r for r in retrieved) for g in gold)\n",
    "\n",
    "        # === Embedding Similarity ===\n",
    "        if method in {\"embedding\", \"both\"} and gold and retrieved:\n",
    "            try:\n",
    "                gold_emb = np.array(embedder.embed_documents(gold)).astype(\"float32\")\n",
    "                retrieved_emb = np.array(embedder.embed_documents(retrieved)).astype(\"float32\")\n",
    "                sim_matrix = cosine_similarity(gold_emb, retrieved_emb)\n",
    "                emb_hits = sum(np.any(sim_row >= sim_threshold) for sim_row in sim_matrix)\n",
    "            except Exception as e:\n",
    "                print(f\"Embedding error for question: {question}\\n{e}\")\n",
    "\n",
    "        # Pick which metric to use for recall\n",
    "        total = len(gold)\n",
    "        recall_em = em_hits / total if total else 0\n",
    "        recall_emb = emb_hits / total if total else 0\n",
    "\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"total_gold\": total,\n",
    "            \"recall_em\": recall_em,\n",
    "            \"recall_emb\": recall_emb,\n",
    "            \"missing_em\": [g for g in gold if not any(g in r for r in retrieved)],\n",
    "            \"missing_emb\": [g for idx, g in enumerate(gold)\n",
    "                            if method in {\"embedding\", \"both\"} and\n",
    "                            (idx >= len(sim_matrix) or not np.any(sim_matrix[idx] >= sim_threshold))]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8cc7d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg EM Recall: 1.0\n",
      "Avg Embedding Recall: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recall_df = evaluate_context_recall(\n",
    "    dataset=finqa_eval_dataset,\n",
    "    embedder=embedder,\n",
    "    method=\"both\",\n",
    "    sim_threshold=0.85\n",
    ")\n",
    "print(\"Avg EM Recall:\", recall_df[\"recall_em\"].mean())\n",
    "print(\"Avg Embedding Recall:\", recall_df[\"recall_emb\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d42fe9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_precision_with_reference(\n",
    "    dataset: List[Dict],\n",
    "    embedder,\n",
    "    top_k_context_key: str = \"retrieved_contexts\",\n",
    "    gold_context_key: str = \"reference_contexts\",\n",
    "    method: str = \"embedding\",  # \"exact\", \"embedding\", or \"both\"\n",
    "    sim_threshold: float = 0.85\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates context precision via exact match or embedding-based similarity.\n",
    " \n",
    "    Args:\n",
    "        dataset: List of QA samples with user_input, retrieved_contexts, reference_contexts\n",
    "        embedder: an object with .embed_documents() method\n",
    "        method: \"exact\", \"embedding\", or \"both\"\n",
    "        sim_threshold: similarity threshold for embedding-based match\n",
    " \n",
    "    Returns:\n",
    "        pd.DataFrame with precision scores and detailed diagnostics\n",
    "    \"\"\"\n",
    "    results = []\n",
    " \n",
    "    for sample in tqdm(dataset):\n",
    "        question = sample.get(\"user_input\", \"N/A\")\n",
    "        retrieved = sample.get(top_k_context_key, [])\n",
    "        gold = sample.get(gold_context_key, [])\n",
    " \n",
    "        retrieved = [r.lower().strip() for r in retrieved if isinstance(r, str)]\n",
    "        gold = [g.lower().strip() for g in gold if isinstance(g, str)]\n",
    " \n",
    "        em_hits = 0\n",
    "        emb_hits = 0\n",
    " \n",
    "        # === Exact Match ===\n",
    "        if method in {\"exact\", \"both\"}:\n",
    "            em_hits = sum(any(g in r for g in gold) for r in retrieved)\n",
    " \n",
    "        # === Embedding Similarity ===\n",
    "        if method in {\"embedding\", \"both\"} and gold and retrieved:\n",
    "            try:\n",
    "                gold_emb = np.array(embedder.embed_documents(gold)).astype(\"float32\")\n",
    "                retrieved_emb = np.array(embedder.embed_documents(retrieved)).astype(\"float32\")\n",
    "                sim_matrix = cosine_similarity(retrieved_emb, gold_emb)\n",
    "                emb_hits = sum(np.any(sim_row >= sim_threshold) for sim_row in sim_matrix)\n",
    "            except Exception as e:\n",
    "                print(f\"Embedding error for question: {question}\\n{e}\")\n",
    " \n",
    "        # Pick which metric to use for precision\n",
    "        total = len(retrieved)\n",
    "        precision_em = em_hits / total if total else 0\n",
    "        precision_emb = emb_hits / total if total else 0\n",
    " \n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"total_retrieved\": total,\n",
    "            \"precision_em\": precision_em,\n",
    "            \"precision_emb\": precision_emb,\n",
    "            \"irrelevant_em\": [r for r in retrieved if not any(g in r for g in gold)],\n",
    "            \"irrelevant_emb\": [r for idx, r in enumerate(retrieved)\n",
    "                               if method in {\"embedding\", \"both\"} and\n",
    "                               (idx >= len(sim_matrix) or not np.any(sim_matrix[idx] >= sim_threshold))]\n",
    "        })\n",
    " \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6db083db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Context Precision Summary:\n",
      "Average Exact Match Precision:     0.0500\n",
      "Average Embedding-Based Precision: 0.1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate context precision\n",
    "precision_results = context_precision_with_reference(\n",
    "    dataset=finqa_eval_dataset,\n",
    "    embedder=embedder,\n",
    "    method=\"both\",  # or \"embedding\" or \"exact\"\n",
    "    sim_threshold=0.85\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nüìä Context Precision Summary:\")\n",
    "print(f\"Average Exact Match Precision:     {precision_results['precision_em'].mean():.4f}\")\n",
    "print(f\"Average Embedding-Based Precision: {precision_results['precision_emb'].mean():.4f}\")\n",
    "\n",
    "# Optional: Save detailed results\n",
    "precision_results.to_csv(\"finqa_context_precision_diagnostics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d42517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ragas import EvaluationDataset, evaluate\n",
    "import re\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize text for evaluation by:\n",
    "    - lowercasing\n",
    "    - removing excess whitespace\n",
    "    - optional: removing punctuation or %/$\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "async def evaluate_ragas_dataset(\n",
    "    dataset: List[Dict[str, Any]],\n",
    "    metrics_list: Optional[List[str]] = None,\n",
    "    llm_model: str = \"gpt-4o-mini\",\n",
    "    llm_type: str = \"openai\",  # 'openai' or 'vllm'\n",
    "    vllm_base_url: str = \"http://localhost:8000/v1\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate a dataset using RAGAS with normalized inputs.\n",
    "\n",
    "    Args:\n",
    "        dataset: List of dicts with keys: user_input, retrieved_contexts, response, reference\n",
    "        metrics_list: Which metrics to use\n",
    "        llm_model: LLM name (e.g., 'gpt-4o')\n",
    "        llm_type: 'openai' or 'vllm'\n",
    "        vllm_base_url: if using vllm locally\n",
    "    \"\"\"\n",
    "    from ragas.metrics import (\n",
    "        LLMContextPrecisionWithReference,\n",
    "        NonLLMContextPrecisionWithReference,\n",
    "        LLMContextRecall,\n",
    "        NonLLMContextRecall,\n",
    "        ContextEntityRecall,\n",
    "        Faithfulness,\n",
    "        AnswerAccuracy,\n",
    "        StringPresence,\n",
    "    )\n",
    "    available_metrics = {\n",
    "        \"context_precision_llm\": LLMContextPrecisionWithReference,\n",
    "        \"context_precision_nonllm\": NonLLMContextPrecisionWithReference,\n",
    "        \"context_recall_llm\": LLMContextRecall,\n",
    "        \"context_recall_nonllm\": NonLLMContextRecall,\n",
    "        \"context_entity_recall\": ContextEntityRecall,\n",
    "        \"faithfulness\": Faithfulness,\n",
    "        \"answer_accuracy\": AnswerAccuracy,\n",
    "        \"string_presence\": StringPresence,\n",
    "    }\n",
    "\n",
    "    if metrics_list is None:\n",
    "        metrics_list = list(available_metrics.keys())\n",
    "\n",
    "    metrics = [available_metrics[name]() for name in metrics_list if name in available_metrics]\n",
    "\n",
    "    # === Normalize dataset ===\n",
    "    normalized_dataset = []\n",
    "    for row in dataset:\n",
    "        norm_row = {\n",
    "            \"user_input\": normalize(row.get(\"user_input\", \"\")),\n",
    "            \"retrieved_contexts\": [normalize(c) for c in row.get(\"retrieved_contexts\", [])],\n",
    "            \"response\": normalize(row.get(\"response\", \"\")),\n",
    "            \"reference\": normalize(row.get(\"reference\", \"\")),\n",
    "        }\n",
    "\n",
    "        # Optional: normalize reference_contexts too\n",
    "        if \"reference_contexts\" in row:\n",
    "            norm_row[\"reference_contexts\"] = [normalize(c) for c in row[\"reference_contexts\"]]\n",
    "        \n",
    "        normalized_dataset.append(norm_row)\n",
    "\n",
    "    # === Load LLM ===\n",
    "    load_dotenv()\n",
    "    if llm_type == \"openai\":\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        from ragas.llms import LangchainLLMWrapper\n",
    "        OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not OPENAI_API_KEY:\n",
    "            raise ValueError(\"OPENAI_API_KEY not found in .env file.\")\n",
    "        llm = ChatOpenAI(model=llm_model, api_key=OPENAI_API_KEY)\n",
    "        evaluator_llm = LangchainLLMWrapper(llm)\n",
    "    elif llm_type == \"vllm\":\n",
    "        from langchain_community.llms import VLLMOpenAI\n",
    "        from ragas.llms import LangchainLLMWrapper\n",
    "        llm = VLLMOpenAI(model=llm_model, base_url=vllm_base_url)\n",
    "        evaluator_llm = LangchainLLMWrapper(llm)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown llm_type: {llm_type}\")\n",
    "\n",
    "    evaluation_dataset = EvaluationDataset.from_list(normalized_dataset)\n",
    "    return evaluate(\n",
    "        dataset=evaluation_dataset,\n",
    "        metrics=metrics,\n",
    "        llm=evaluator_llm\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "206e7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    " \n",
    "def context_entity_recall(\n",
    "    dataset: List[Dict],\n",
    "    nlp,\n",
    "    top_k_context_key: str = \"retrieved_contexts\",\n",
    "    gold_context_key: str = \"reference_contexts\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes entity-level recall: proportion of gold named entities found in retrieved contexts.\n",
    " \n",
    "    Args:\n",
    "        dataset: List of samples with user_input, retrieved_contexts, and reference_contexts\n",
    "        nlp: spaCy language model for NER\n",
    "        top_k_context_key: Key for retrieved contexts\n",
    "        gold_context_key: Key for reference (gold) contexts\n",
    " \n",
    "    Returns:\n",
    "        pd.DataFrame with entity recall metrics and diagnostics\n",
    "    \"\"\"\n",
    "    results = []\n",
    " \n",
    "    for sample in tqdm(dataset):\n",
    "        question = sample.get(\"user_input\", \"N/A\")\n",
    "        retrieved = sample.get(top_k_context_key, [])\n",
    "        gold = sample.get(gold_context_key, [])\n",
    " \n",
    "        # Join all contexts into one string each\n",
    "        retrieved_text = \" \".join([r for r in retrieved if isinstance(r, str)])\n",
    "        gold_text = \" \".join([g for g in gold if isinstance(g, str)])\n",
    " \n",
    "        # Run NER\n",
    "        retrieved_doc = nlp(retrieved_text)\n",
    "        gold_doc = nlp(gold_text)\n",
    " \n",
    "        # Extract unique entities (as strings)\n",
    "        retrieved_ents = set(ent.text.strip().lower() for ent in retrieved_doc.ents)\n",
    "        gold_ents = set(ent.text.strip().lower() for ent in gold_doc.ents)\n",
    " \n",
    "        # Calculate overlap\n",
    "        common_ents = retrieved_ents & gold_ents\n",
    "        total_gold_ents = len(gold_ents)\n",
    "        recall = len(common_ents) / total_gold_ents if total_gold_ents else 0\n",
    " \n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"retrieved_entities\": list(retrieved_ents),\n",
    "            \"gold_entities\": list(gold_ents),\n",
    "            \"common_entities\": list(common_ents),\n",
    "            \"num_common_entities\": len(common_ents),\n",
    "            \"total_gold_entities\": total_gold_ents,\n",
    "            \"entity_recall\": recall\n",
    "        })\n",
    " \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c48223a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Average Entity Recall: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy English model (small is fast; medium or large is more accurate)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Run entity-level recall evaluation\n",
    "entity_results = context_entity_recall(\n",
    "    dataset=finqa_eval_dataset,\n",
    "    nlp=nlp,\n",
    "    top_k_context_key=\"retrieved_contexts\",\n",
    "    gold_context_key=\"reference_contexts\"\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nüìä Average Entity Recall: {entity_results['entity_recall'].mean():.4f}\")\n",
    "\n",
    "# Optional: Save diagnostics to CSV\n",
    "entity_results.to_csv(\"finqa_entity_recall_diagnostics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25d533c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_from_precision_recall_dfs(\n",
    "    precision_df: pd.DataFrame,\n",
    "    recall_df: pd.DataFrame,\n",
    "    precision_col: str = \"precision_emb\",\n",
    "    recall_col: str = \"recall_emb\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combines precision and recall DataFrames to compute F1 score per sample.\n",
    " \n",
    "    Args:\n",
    "        precision_df: Output of context_precision_with_reference()\n",
    "        recall_df: Output of context_recall_with_reference()\n",
    "        precision_col: Column name for precision score\n",
    "        recall_col: Column name for recall score\n",
    " \n",
    "    Returns:\n",
    "        A merged DataFrame with F1 score added\n",
    "    \"\"\"\n",
    "    # Join on 'question'\n",
    "    merged = pd.merge(precision_df, recall_df, on=\"question\", suffixes=(\"_prec\", \"_rec\"))\n",
    " \n",
    "    def safe_f1(p, r):\n",
    "        return (2 * p * r / (p + r)) if (p + r) > 0 else 0.0\n",
    " \n",
    "    merged[\"f1\"] = merged.apply(lambda row: safe_f1(row[precision_col], row[recall_col]), axis=1)\n",
    " \n",
    "    return merged\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c5d3bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.18it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Average F1 Score: 0.2476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Compute context precision and recall separately\n",
    "precision_df = context_precision_with_reference(\n",
    "    dataset=finqa_eval_dataset,\n",
    "    embedder=embedder,\n",
    "    method=\"embedding\",   # or \"both\"\n",
    "    sim_threshold=0.85\n",
    ")\n",
    "\n",
    "recall_df = evaluate_context_recall(\n",
    "    dataset=finqa_eval_dataset,\n",
    "    embedder=embedder,\n",
    "    method=\"embedding\",   # or \"both\"\n",
    "    sim_threshold=0.85\n",
    ")\n",
    "\n",
    "# Step 2: Compute F1 score from the two\n",
    "f1_df = compute_f1_from_precision_recall_dfs(\n",
    "    precision_df=precision_df,\n",
    "    recall_df=recall_df,\n",
    "    precision_col=\"precision_emb\",  # use \"precision_em\" if using exact match\n",
    "    recall_col=\"recall_emb\"         # or \"recall_em\"\n",
    ")\n",
    "\n",
    "# Step 3: Print summary\n",
    "print(f\"\\nüîç Average F1 Score: {f1_df['f1'].mean():.4f}\")\n",
    "\n",
    "# Step 4 (optional): Save to CSV\n",
    "f1_df.to_csv(\"finqa_precision_recall_f1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d4ba9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    " \n",
    "def mean_reciprocal_rank(\n",
    "    dataset: List[Dict],\n",
    "    embedder = None,\n",
    "    top_k_context_key: str = \"retrieved_contexts\",\n",
    "    gold_context_key: str = \"reference_contexts\",\n",
    "    method: str = \"embedding\",  # \"exact\" or \"embedding\"\n",
    "    sim_threshold: float = 0.85\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates MRR for retrieved contexts given gold reference contexts.\n",
    " \n",
    "    Returns:\n",
    "        pd.DataFrame with reciprocal ranks and full MRR score\n",
    "    \"\"\"\n",
    "    results = []\n",
    " \n",
    "    for sample in tqdm(dataset):\n",
    "        question = sample.get(\"user_input\", \"N/A\")\n",
    "        retrieved = sample.get(top_k_context_key, [])\n",
    "        gold = sample.get(gold_context_key, [])\n",
    " \n",
    "        retrieved = [r.lower().strip() for r in retrieved if isinstance(r, str)]\n",
    "        gold = [g.lower().strip() for g in gold if isinstance(g, str)]\n",
    " \n",
    "        rr = 0.0  # Reciprocal rank\n",
    " \n",
    "        if method == \"exact\":\n",
    "            for rank, ret in enumerate(retrieved, start=1):\n",
    "                if any(g in ret for g in gold):\n",
    "                    rr = 1.0 / rank\n",
    "                    break\n",
    " \n",
    "        elif method == \"embedding\" and embedder and gold and retrieved:\n",
    "            try:\n",
    "                gold_emb = np.array(embedder.embed_documents(gold)).astype(\"float32\")\n",
    "                retrieved_emb = np.array(embedder.embed_documents(retrieved)).astype(\"float32\")\n",
    "                sim_matrix = cosine_similarity(retrieved_emb, gold_emb)\n",
    "                for rank, sim_row in enumerate(sim_matrix, start=1):\n",
    "                    if np.any(sim_row >= sim_threshold):\n",
    "                        rr = 1.0 / rank\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(f\"Embedding error for question: {question}\\n{e}\")\n",
    " \n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"reciprocal_rank\": rr\n",
    "        })\n",
    " \n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"mrr\"] = df[\"reciprocal_rank\"].mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "237970dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reciprocal_rank</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q: For GPN, what was the fair value of share a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what was the cost per tower in American Tower‚Äô...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  reciprocal_rank   mrr\n",
       "0  Q: For GPN, what was the fair value of share a...              1.0  0.75\n",
       "1  what was the cost per tower in American Tower‚Äô...              0.5  0.75"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mean_reciprocal_rank(finqa_eval_dataset, embedder=embedder)\n",
    "\n",
    "print(\"MRR:\", df['mrr'].iloc[0])\n",
    "\n",
    "df.head()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7c10079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    " \n",
    "def compute_ndcg(\n",
    "    dataset: List[Dict],\n",
    "    embedder = None,\n",
    "    top_k_context_key: str = \"retrieved_contexts\",\n",
    "    gold_context_key: str = \"reference_contexts\",\n",
    "    method: str = \"embedding\",  # \"exact\" or \"embedding\"\n",
    "    sim_threshold: float = 0.85,\n",
    "    k: int = 10\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute nDCG@k for retrieved contexts.\n",
    " \n",
    "    Returns:\n",
    "        DataFrame with nDCG@k per sample and average\n",
    "    \"\"\"\n",
    "    results = []\n",
    " \n",
    "    for sample in tqdm(dataset):\n",
    "        question = sample.get(\"user_input\", \"N/A\")\n",
    "        retrieved = sample.get(top_k_context_key, [])[:k]\n",
    "        gold = sample.get(gold_context_key, [])\n",
    " \n",
    "        retrieved = [r.lower().strip() for r in retrieved if isinstance(r, str)]\n",
    "        gold = [g.lower().strip() for g in gold if isinstance(g, str)]\n",
    " \n",
    "        relevance = [0] * len(retrieved)  # Relevance at each rank\n",
    " \n",
    "        if method == \"exact\":\n",
    "            for i, r in enumerate(retrieved):\n",
    "                if any(g in r for g in gold):\n",
    "                    relevance[i] = 1\n",
    " \n",
    "        elif method == \"embedding\" and embedder and gold and retrieved:\n",
    "            try:\n",
    "                gold_emb = np.array(embedder.embed_documents(gold)).astype(\"float32\")\n",
    "                retrieved_emb = np.array(embedder.embed_documents(retrieved)).astype(\"float32\")\n",
    "                sim_matrix = cosine_similarity(retrieved_emb, gold_emb)\n",
    "                for i, sim_row in enumerate(sim_matrix):\n",
    "                    if np.any(sim_row >= sim_threshold):\n",
    "                        relevance[i] = 1\n",
    "            except Exception as e:\n",
    "                print(f\"Embedding error for question: {question}\\n{e}\")\n",
    " \n",
    "        # === Compute DCG and nDCG ===\n",
    "        dcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(relevance))  # +2 because log2(i+1) with 0-indexing\n",
    "        ideal_relevance = sorted(relevance, reverse=True)\n",
    "        idcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(ideal_relevance))\n",
    " \n",
    "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    " \n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"dcg\": dcg,\n",
    "            \"idcg\": idcg,\n",
    "            \"ndcg@{}\".format(k): ndcg\n",
    "        })\n",
    " \n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"mean_ndcg\"] = df[\"ndcg@{}\".format(k)].mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3eeddfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:09<00:00,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average nDCG@10: 0.7817254227631407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ndcg_df = compute_ndcg(finqa_eval_dataset, embedder=embedder, k=10)\n",
    "print(\"Average nDCG@10:\", ndcg_df[\"mean_ndcg\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0944063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gold context NOT retrieved for:\n",
      "Q: GM operating margin 2023 vs 2022, GM.\n",
      "Gold: (empty)\n",
      "\n",
      "Gold context LOST after reranking for:\n",
      "Q: GM operating margin 2023 vs 2022, GM.\n",
      "\n",
      "Gold context NOT retrieved for:\n",
      "Q: NGC's cyber investments boost investor confidence, enhance valuation, and bolster stability.\n",
      "Gold: (empty)\n",
      "\n",
      "Gold context LOST after reranking for:\n",
      "Q: NGC's cyber investments boost investor confidence, enhance valuation, and bolster stability.\n",
      "\n",
      "Gold context retrieved for:\n",
      "Q: Q: For GPN, what was the fair value of share awards vested in 2009?\n",
      "A: 6.2\n",
      "Q: what was the value in 2007?\n",
      "A: 1.7\n",
      "Q: what was the net change in value?\n",
      "A: A0\n",
      "Q: what is the net change divided by the 2007 value?\n",
      "Gold context RETAINED in reranked docs for:\n",
      "Q: Q: For GPN, what was the fair value of share awards vested in 2009?\n",
      "A: 6.2\n",
      "Q: what was the value in 2007?\n",
      "A: 1.7\n",
      "Q: what was the net change in value?\n",
      "A: A0\n",
      "Q: what is the net change divided by the 2007 value?\n",
      "Reference context FOUND in indexed chunks.\n",
      "\n",
      "Gold context retrieved for:\n",
      "Q: what was the cost per tower in American Tower‚Äôs colombia movil acquisition?\n",
      "Gold context RETAINED in reranked docs for:\n",
      "Q: what was the cost per tower in American Tower‚Äôs colombia movil acquisition?\n",
      "Reference context FOUND in indexed chunks.\n",
      "\n",
      "üîç Evaluating FinQA subset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd864885e4f4ca8832c2c1d08ea1c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FinQA Metrics per Sample:\n",
      "\n",
      "--- Sample 1 ---\n",
      "Question: q: for gpn, what was the fair value of share awards vested in 2009? a: 6.2 q: what was the value in 2007? a: 1.7 q: what was the net change in value? a: a0 q: what is the net change divided by the 2007 value?\n",
      "Response: 2.647058823\n",
      "Reference Answer: 265% increase\n",
      "Context Sample:\n",
      "['notes to consolidated financial statements 2014 ( continued ) the following table summarizes the changes in non-vested restricted stock awards for the year ended may 31 , 2009 ( share awards in thousands ) : share awards weighted average grant-date fair value .'] share awards weighted average grant-date fair value non-vested at may 31 2007 278 $ 37 granted 400 38 vested -136 ( 136 ) 30 forfeited -24 ( 24 ) 40 non-vested at may 31 2008 518 39 granted 430 43 vested -159 ( 159 ) 39 forfeited -27 ...\n",
      "\n",
      "reference_contexts: ['the total fair value of share awards vested during the years ended may 31 , 2009 , 2008 and 2007 was $ 6.2 million , $ 4.1 million and $ 1.7 million , respectively .']\n",
      "llm_context_precision_with_reference: 1.0000\n",
      "non_llm_context_precision_with_reference: 0.0000\n",
      "context_recall: 0.0000\n",
      "non_llm_context_recall: 0.0000\n",
      "context_entity_recall: nan\n",
      "faithfulness: nan\n",
      "nv_accuracy: 0.2500\n",
      "string_present: 0.0000\n",
      "\n",
      "--- Sample 2 ---\n",
      "Question: what was the cost per tower in american tower‚Äôs colombia movil acquisition?\n",
      "Response: ‚âà85600\n",
      "Reference Answer: 856067\n",
      "Context Sample:\n",
      "['american tower corporation and subsidiaries notes to consolidated financial statements u.s .', 'acquisitions 2014during the year ended december 31 , 2010 , the company acquired 548 towers through multiple acquisitions in the united states for an aggregate purchase price of $ 329.3 million and contingent consideration of approximately $ 4.6 million .', 'the acquisition of these towers is consistent with the company 2019s strategy to expand in selected geographic areas and have been accounted fo...\n",
      "\n",
      "reference_contexts: ['( 201ccolombia movil 201d ) , whereby atc sitios infraco , s.a.s. , a colombian subsidiary of the company ( 201catc infraco 201d ) , would purchase up to 2126 communications sites from colombia movil for an aggregate purchase price of approximately $ 182.0 million .']\n",
      "llm_context_precision_with_reference: 0.0000\n",
      "non_llm_context_precision_with_reference: 0.0000\n",
      "context_recall: 0.0000\n",
      "non_llm_context_recall: 0.0000\n",
      "context_entity_recall: nan\n",
      "faithfulness: 0.0000\n",
      "nv_accuracy: 0.0000\n",
      "string_present: 0.0000\n",
      "\n",
      "üîç Evaluating FinDER subset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006f38419b154584a80777c2abb5100d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-b9EC73CxcpNUA7w9Zh1KhBEH on tokens per min (TPM): Limit 30000, Used 30000, Requested 334. Please try again in 668ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Skipping a sample by assigning it nan score.\n",
      "An error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-b9EC73CxcpNUA7w9Zh1KhBEH on tokens per min (TPM): Limit 30000, Used 30000, Requested 729. Please try again in 1.458s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Skipping a sample by assigning it nan score.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FinDER Metrics per Sample:\n",
      "\n",
      "--- Sample 1 ---\n",
      "Question: gm operating margin 2023 vs 2022, gm.\n",
      "Response: approximately 5.4% in 2023 versus about 6.6% in 2022.\n",
      "Reference Answer: to calculate the operating profit margin we divide operating income by total net sales and revenue. for 2023 the calculation is as follows: ‚Ä¢ 2023 operating profit margin = 9298 / 171842 ‚âà 0.0541 or about 5.41%. for 2022 using the same method: ‚Ä¢ 2022 operating profit margin = 10315 / 156735 ‚âà 0.0658 or about 6.58%. this comparison shows that the operating margin declined from approximately 6.58% in 2022 to about 5.41% in 2023.\n",
      "Context Sample:\n",
      "engineering (dollar amounts in millions) variance year ended december 31, 2023 2022 2023 vs. 2022 sales $ 2,160 $ 2,762 (22) % operating profit $ 491 $ 555 (12) % as a percent of sales 22.7 % 20.1 % 2023 vs. 2022 % change factors contributing to changes - sales currency 1 % other (23) % (22) % sales engineering segment sales decreased $602 million, or 22%, in 2023 versus 2022 . the decrease was driven by project timing. projects for russia that were sanctioned, and therefore terminated or suspen...\n",
      "\n",
      "faithfulness: 0.0000\n",
      "nv_accuracy: nan\n",
      "\n",
      "--- Sample 2 ---\n",
      "Question: ngc's cyber investments boost investor confidence, enhance valuation, and bolster stability.\n",
      "Response: by continually expanding its cybersecurity program‚Äîthrough soc 2‚Äìcertified controls isac partnerships independent penetration tests board-level oversight employee training and dedicated cyber-risk insurance‚Äîngc demonstrates proactive risk management that reduces the likelihood of material breaches. this visible commitment reassures investors supports a premium valuation and helps preserve the company‚Äôs long-term financial stability.\n",
      "Reference Answer: the provided information allows us to assess how northrop grumman‚Äôs investments in cybersecurity can bolster investor confidence and reinforce long-term valuation stability. specifically the company‚Äôs focus on a multi-layered defense approach including a dedicated cybersecurity operations center that offers round-the-clock monitoring continuous threat detection and rapid incident response minimizes the risk of cyber breaches. this proactive posture reduces the likelihood of disruptions that might otherwise negatively impact financial performance cash flows and overall operational stability. additionally regular third-party assessments further validate the robustness of the company‚Äôs cybersecurity measures. these independent reviews help ensure that any vulnerabilities are identified and addressed promptly while reinforcing the credibility of the company‚Äôs risk management strategies. the integration of these investments into regular risk oversight through the board executive risk committees and specialized groups (like the audit and risk committee) supports transparency and effective governance. in summary these cybersecurity investments contribute to investor confidence by mitigating potential risks linked to cyber threats thereby protecting the company‚Äôs financial health and ensuring that valuation remains stable over the long term. while no direct calculations are provided the qualitative link between enhanced cybersecurity measures and reduced uncertainty around operational and financial risks is evident from the details discussed.\n",
      "Context Sample:\n",
      "we invest in enhancing our cybersecurity capabilities and strengthening our partnerships with appropriate business partners, service partners, and government and law enforcement agencies to understand the range of cybersecurity risks in the operating environment, enhance defenses, and improve resiliency against cybersecurity threats. additionally, we are a member of the financial services and information technology isacs and both a founding member and board member of the automotive isac. our mem...\n",
      "\n",
      "faithfulness: 0.1000\n",
      "nv_accuracy: nan\n",
      "\n",
      "‚úÖ Evaluation complete. Results saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import re\n",
    "\n",
    "\n",
    "# === Paths ===\n",
    "BASE_DIR = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)\")\n",
    "FAISS_PATH = BASE_DIR / \"faiss_index_full.idx\"\n",
    "META_PATH = BASE_DIR / \"retriever_metadata_full.pkl\"\n",
    "GOLD_PATH = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/notebooks/filtered_gold_eval_dataset.json\")\n",
    "\n",
    "# === Load Metadata and FAISS Index ===\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    chunk_ids = data[\"chunk_ids\"]\n",
    "    metadata_dict = data[\"metadata\"]\n",
    "\n",
    "index = faiss.read_index(str(FAISS_PATH))\n",
    "\n",
    "# === Load Embedder and Generator ===\n",
    "embedder = init_embedder()\n",
    "generator = ChatGPTGenerator()\n",
    "reranker = CrossEncoderReranker()\n",
    "\n",
    "# === Load Gold Test Data ===\n",
    "with open(GOLD_PATH) as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# === Helper: Normalize strings and percentages ===\n",
    "def normalize_answer(ans: str) -> str:\n",
    "    ans = ans.strip().lower()\n",
    "    ans = re.sub(r\"[,$]\", \"\", ans)              # Remove commas, dollar signs\n",
    "    ans = re.sub(r\"\\s+\", \" \", ans)              # Collapse whitespace\n",
    "    ans = ans.replace(\" percent\", \"%\")\n",
    "    ans = re.sub(r\"(\\d)\\s*%\", r\"\\1%\", ans)      # \"20 %\" ‚Üí \"20%\"\n",
    "    return ans\n",
    "\n",
    "# === Generate Evaluation Dataset ===\n",
    "finqa_eval_dataset = []\n",
    "finder_eval_dataset = []\n",
    "finqa_count = 0\n",
    "finder_count = 0\n",
    "\n",
    "for sample in gold_data:\n",
    "    if finqa_count >= 2 and finder_count >= 2:\n",
    "        break\n",
    "\n",
    "    question = sample[\"question\"]\n",
    "    reference = normalize_answer(sample[\"answer\"])\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "\n",
    "    # === Check if reference context exists in indexed corpus ===\n",
    "    reference_contexts = []\n",
    "    if isinstance(gold_context, dict):\n",
    "        reference_contexts = list(gold_context.values())\n",
    "    elif isinstance(gold_context, str) and gold_context.strip():\n",
    "        reference_contexts = [gold_context.strip()]\n",
    "\n",
    "    # Embed and retrieve\n",
    "    query_embedding = np.array(embedder.embed_query(question), dtype=\"float32\").reshape(1, -1)\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    D, I = index.search(query_embedding, 50)\n",
    "\n",
    "    retrieved_chunks = [metadata_dict[chunk_ids[i]][\"text\"].lower() for i in I[0]]\n",
    "    candidate_docs = [\n",
    "        metadata_dict[chunk_ids[i]]\n",
    "        for i in I[0]\n",
    "        if chunk_ids[i] in metadata_dict and \"text\" in metadata_dict[chunk_ids[i]]\n",
    "    ]\n",
    "\n",
    "    # === Check if gold_context is in top-50 retrieved chunks ===\n",
    "    gold_contexts = [ctx.lower().strip() for ctx in reference_contexts if isinstance(ctx, str)]\n",
    "    match_found = any(g in r for g in gold_contexts for r in retrieved_chunks)\n",
    "\n",
    "    # Only show logs for selected samples\n",
    "    if (reference_contexts and finqa_count < 2) or (not reference_contexts and finder_count < 2):\n",
    "        if not match_found:\n",
    "            gold_preview = gold_contexts[0][:200] if gold_contexts else \"(empty)\"\n",
    "            print(f\"\\nGold context NOT retrieved for:\\nQ: {question}\\nGold: {gold_preview}\\n\")\n",
    "        else:\n",
    "            print(f\"\\nGold context retrieved for:\\nQ: {question}\")\n",
    "\n",
    "    reranked_docs = reranker.rerank(question, candidate_docs, top_k=20)\n",
    "    reranked_texts = [doc[\"text\"].lower() for doc in reranked_docs]\n",
    "    gold_in_reranked = any(g in d for g in gold_contexts for d in reranked_texts)\n",
    "\n",
    "    if (reference_contexts and finqa_count < 2) or (not reference_contexts and finder_count < 2):\n",
    "        if not gold_in_reranked:\n",
    "            print(f\"Gold context LOST after reranking for:\\nQ: {question}\")\n",
    "        else:\n",
    "            print(f\"Gold context RETAINED in reranked docs for:\\nQ: {question}\")\n",
    "\n",
    "    # Generate answer\n",
    "    raw_response = generator.generate(question, [doc[\"text\"] for doc in reranked_docs])\n",
    "    response = normalize_answer(raw_response)\n",
    "\n",
    "    # === Record for RAGAS ===\n",
    "    record = {\n",
    "        \"user_input\": question,\n",
    "        \"retrieved_contexts\": [doc[\"text\"] for doc in reranked_docs],\n",
    "        \"response\": response,\n",
    "        \"reference\": reference,\n",
    "    }\n",
    "\n",
    "    if reference_contexts:\n",
    "        record[\"reference_contexts\"] = reference_contexts\n",
    "        found = False\n",
    "        for ref in reference_contexts:\n",
    "            ref_clean = ref.lower().strip()\n",
    "            for chunk_data in metadata_dict.values():\n",
    "                if ref_clean in chunk_data.get(\"text\", \"\").lower():\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "        print(\"Reference context FOUND in indexed chunks.\" if found else \"Reference context NOT found in indexed chunks.\")\n",
    "\n",
    "    # Append to correct eval set\n",
    "    if reference_contexts and finqa_count < 2:\n",
    "        finqa_eval_dataset.append(record)\n",
    "        finqa_count += 1\n",
    "    elif not reference_contexts and finder_count < 2:\n",
    "        finder_eval_dataset.append(record)\n",
    "        finder_count += 1\n",
    "\n",
    "# === Evaluate FinQA Subset ===\n",
    "print(\"\\nüîç Evaluating FinQA subset...\")\n",
    "finqa_result = asyncio.run(evaluate_ragas_dataset(finqa_eval_dataset))\n",
    "finqa_df = finqa_result.to_pandas()\n",
    "\n",
    "print(f\"\\nüéØ FinQA Metrics per Sample:\")\n",
    "for i, row in finqa_df.iterrows():\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Question: {row['user_input']}\")\n",
    "    print(f\"Response: {row['response']}\")\n",
    "    print(f\"Reference Answer: {row['reference']}\")\n",
    "    print(f\"Context Sample:\\n{row['retrieved_contexts'][0][:500]}...\\n\")\n",
    "\n",
    "    for col in finqa_df.columns:\n",
    "        if col not in ['user_input', 'retrieved_contexts', 'response', 'reference']:\n",
    "            value = row[col]\n",
    "            try:\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"{col}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{col}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{col}: ‚ö†Ô∏è Error printing value ({type(value)}): {e}\")\n",
    "\n",
    "# === Evaluate FinDER Subset ===\n",
    "print(\"\\nüîç Evaluating FinDER subset...\")\n",
    "finder_result = asyncio.run(evaluate_ragas_dataset(\n",
    "    finder_eval_dataset,\n",
    "    metrics_list=[\"faithfulness\", \"answer_accuracy\"]\n",
    "))\n",
    "finder_df = finder_result.to_pandas()\n",
    "\n",
    "print(f\"\\nüéØ FinDER Metrics per Sample:\")\n",
    "for i, row in finder_df.iterrows():\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Question: {row['user_input']}\")\n",
    "    print(f\"Response: {row['response']}\")\n",
    "    print(f\"Reference Answer: {row['reference']}\")\n",
    "    print(f\"Context Sample:\\n{row['retrieved_contexts'][0][:500]}...\\n\")\n",
    "\n",
    "    for col in finder_df.columns:\n",
    "        if col not in ['user_input', 'retrieved_contexts', 'response', 'reference']:\n",
    "            value = row[col]\n",
    "            try:\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"{col}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{col}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{col}: ‚ö†Ô∏è Error printing value ({type(value)}): {e}\")\n",
    "\n",
    "# === Save to CSV ===\n",
    "finqa_df.to_csv(\"finqa_eval_detailed.csv\", index=False)\n",
    "finder_df.to_csv(\"finder_eval_detailed.csv\", index=False)\n",
    "print(\"\\n‚úÖ Evaluation complete. Results saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ace83a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2408' coro=<evaluate_ragas_dataset() done, defined at /var/folders/hp/hkpqf03x0qdg7_8s3s9sy7gw0000gn/T/ipykernel_68125/1842337027.py:8> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/hp/hkpqf03x0qdg7_8s3s9sy7gw0000gn/T/ipykernel_68125/3351570119.py\", line 139, in <module>\n",
      "    finqa_result = asyncio.run(evaluate_ragas_dataset(finqa_eval_dataset))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hp/hkpqf03x0qdg7_8s3s9sy7gw0000gn/T/ipykernel_68125/1842337027.py\", line 79, in evaluate_ragas_dataset\n",
      "    return evaluate(\n",
      "           ^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/ragas/_analytics.py\", line 227, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/ragas/evaluation.py\", line 294, in evaluate\n",
      "    results = executor.results()\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/ragas/executor.py\", line 213, in results\n",
      "    results = asyncio.run(self._process_jobs())\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 115, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/selectors.py\", line 566, in select\n",
      "    kev_list = self._selector.control(None, max_ev, timeout)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2223' coro=<evaluate_ragas_dataset() done, defined at /var/folders/hp/hkpqf03x0qdg7_8s3s9sy7gw0000gn/T/ipykernel_68125/1842337027.py:8> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/hp/hkpqf03x0qdg7_8s3s9sy7gw0000gn/T/ipykernel_68125/3351570119.py\", line 139, in <module>\n",
      "    finqa_result = asyncio.run(evaluate_ragas_dataset(finqa_eval_dataset))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hp/hkpqf03x0qdg7_8s3s9sy7gw0000gn/T/ipykernel_68125/1842337027.py\", line 79, in evaluate_ragas_dataset\n",
      "    return evaluate(\n",
      "           ^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/ragas/_analytics.py\", line 227, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/ragas/evaluation.py\", line 294, in evaluate\n",
      "    results = executor.results()\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/ragas/executor.py\", line 213, in results\n",
      "    results = asyncio.run(self._process_jobs())\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/nest_asyncio.py\", line 115, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alex/anaconda3/envs/fin_rag_env/lib/python3.11/selectors.py\", line 566, in select\n",
      "    kev_list = self._selector.control(None, max_ev, timeout)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m retrieved_contexts = top_chunks[:\u001b[32m10\u001b[39m]\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m answer = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieved_contexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# === Simple Metrics ===\u001b[39;00m\n\u001b[32m     48\u001b[39m gold_retrieved = \u001b[38;5;28many\u001b[39m(ctx.lower().strip() \u001b[38;5;129;01min\u001b[39;00m chunk.lower() \u001b[38;5;28;01mfor\u001b[39;00m ctx \u001b[38;5;129;01min\u001b[39;00m gold_contexts \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m top_chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Data Science Master/thesis_RAG/src/generator/generator.py:36\u001b[39m, in \u001b[36mChatGPTGenerator.generate\u001b[39m\u001b[34m(self, question, retrieved_docs, max_tokens)\u001b[39m\n\u001b[32m     30\u001b[39m context = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(retrieved_docs)\n\u001b[32m     31\u001b[39m messages = [\n\u001b[32m     32\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.system_prompt},\n\u001b[32m     33\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mContext:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnswer:\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     34\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1087\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1044\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1084\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1085\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1086\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1087\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/openai/_base_client.py:972\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    970\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    978\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/ssl.py:1295\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1292\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1293\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1294\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fin_rag_env/lib/python3.11/ssl.py:1168\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# === Paths ===\n",
    "BASE_DIR = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/Retriever_Context (Eval)\")\n",
    "FAISS_PATH = BASE_DIR / \"faiss_index_full.idx\"\n",
    "META_PATH = BASE_DIR / \"retriever_metadata_full.pkl\"\n",
    "GOLD_PATH = Path(\"/Users/alex/Documents/Data Science Master/thesis_RAG/data/data_processed/Train_Val_Test/gold_test_data_updated.json\")\n",
    "\n",
    "# === Load ===\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    metadata = pickle.load(f)\n",
    "    chunk_ids = metadata[\"chunk_ids\"]\n",
    "    metadata_dict = metadata[\"metadata\"]\n",
    "\n",
    "index = faiss.read_index(str(FAISS_PATH))\n",
    "embedder = init_embedder()\n",
    "generator = ChatGPTGenerator()\n",
    "\n",
    "with open(GOLD_PATH) as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "# === Evaluation loop ===\n",
    "results = []\n",
    "for sample in gold_data[:10]:  # Adjust the slice to test more\n",
    "    question = sample[\"question\"]\n",
    "    reference = sample[\"answer\"]\n",
    "    gold_contexts = sample.get(\"gold_context\", {})\n",
    "    if isinstance(gold_contexts, dict):\n",
    "        gold_contexts = list(gold_contexts.values())\n",
    "\n",
    "    # Retrieve from FAISS\n",
    "    query_vec = np.array(embedder.embed_query(question)).astype(\"float32\").reshape(1, -1)\n",
    "    faiss.normalize_L2(query_vec)\n",
    "    D, I = index.search(query_vec, 50)\n",
    "\n",
    "    top_chunks = [metadata_dict[chunk_ids[i]][\"text\"] for i in I[0]]\n",
    "    retrieved_contexts = top_chunks[:10]\n",
    "\n",
    "    # Generate response\n",
    "    answer = generator.generate(question, retrieved_contexts)\n",
    "\n",
    "    # === Simple Metrics ===\n",
    "    gold_retrieved = any(ctx.lower().strip() in chunk.lower() for ctx in gold_contexts for chunk in top_chunks)\n",
    "    exact_match = answer.strip().lower() == reference.strip().lower()\n",
    "    partial_match = reference.strip().lower() in answer.strip().lower()\n",
    "    context_used = any(ctx.lower().strip() in answer.lower() for ctx in gold_contexts)\n",
    "\n",
    "    results.append({\n",
    "        \"question\": question,\n",
    "        \"reference\": reference,\n",
    "        \"answer\": answer,\n",
    "        \"gold_retrieved\": gold_retrieved,\n",
    "        \"exact_match\": exact_match,\n",
    "        \"partial_match\": partial_match,\n",
    "        \"faithful_to_context\": context_used,\n",
    "    })\n",
    "\n",
    "# === Print summary ===\n",
    "correct = sum(r[\"exact_match\"] for r in results)\n",
    "partial = sum(r[\"partial_match\"] for r in results)\n",
    "retrieval_success = sum(r[\"gold_retrieved\"] for r in results)\n",
    "context_faithful = sum(r[\"faithful_to_context\"] for r in results)\n",
    "\n",
    "print(f\"\\nEvaluation Summary (n={len(results)}):\")\n",
    "print(f\"‚úÖ Gold Context Retrieved: {retrieval_success}/{len(results)}\")\n",
    "print(f\"‚úÖ Exact Matches: {correct}/{len(results)}\")\n",
    "print(f\"‚úÖ Partial Matches: {partial}/{len(results)}\")\n",
    "print(f\"‚úÖ Context-Faithful Generations: {context_faithful}/{len(results)}\")\n",
    "\n",
    "# Optional: save results\n",
    "import pandas as pd\n",
    "pd.DataFrame(results).to_csv(\"local_eval_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7455802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS dim: 1536\n",
      "Query dim: 1536\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "query = \"sample financial question\"\n",
    "embedding = np.array(embedder.embed_query(query)).astype(\"float32\").reshape(1, -1)\n",
    "\n",
    "print(\"FAISS dim:\", index.d)\n",
    "print(\"Query dim:\", embedding.shape[1])\n",
    "assert index.d == embedding.shape[1], \"‚ùå Embedding dimension mismatch!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21843c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gold context retrieved for:\n",
      "Q: what was the cost per tower in American Tower‚Äôs colombia movil acquisition?\n"
     ]
    }
   ],
   "source": [
    "# After FAISS search\n",
    "retrieved_chunks = [metadata_dict[chunk_ids[i]][\"text\"].lower() for i in I[0]]\n",
    "\n",
    "# Check if any gold_context is present in retrieved chunks\n",
    "gold_contexts = list(gold_context.values()) if isinstance(gold_context, dict) else [gold_context]\n",
    "gold_contexts = [ctx.lower().strip() for ctx in gold_contexts if isinstance(ctx, str)]\n",
    "\n",
    "# Check match\n",
    "match_found = False\n",
    "for gold_ctx in gold_contexts:\n",
    "    for chunk in retrieved_chunks:\n",
    "        if gold_ctx in chunk:\n",
    "            match_found = True\n",
    "            break\n",
    "    if match_found:\n",
    "        break\n",
    "\n",
    "if not match_found:\n",
    "    print(f\"‚ùå Gold context NOT retrieved for:\\nQ: {question}\\nGold: {gold_contexts[0]}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Gold context retrieved for:\\nQ: {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: GM operating margin 2023 vs 2022, GM.\n",
      "Generated Answer: 2023: 5.4 % vs 2022: 6.6 %\n",
      "--------------------------------------------------------------------------------\n",
      "Question: In the financial filing of Citigroup, what percentage of incremental risk-weighted assets are student loans at january 1 , 2010?\n",
      "Generated Answer: 24%\n",
      "--------------------------------------------------------------------------------\n",
      "Question: what is the growth rate in net revenue in 2003 for entergy corporation?\n",
      "Generated Answer: I don‚Äôt know\n",
      "--------------------------------------------------------------------------------\n",
      "Question: NGC's cyber investments boost investor confidence, enhance valuation, and bolster stability.\n",
      "Generated Answer: NGC‚Äôs ongoing spending on cyber defenses, industry‚Äêwide information‚Äêsharing memberships, and third-party maturity assessments demonstrate proactive risk management, which reassures investors, helps preserve firm value, and supports the company‚Äôs operational and financial stability by preventing any material cyber incidents in recent years.\n",
      "--------------------------------------------------------------------------------\n",
      "Question: SBA Comm., credit evals & DTA quality receivables.\n",
      "Generated Answer: The company continually runs credit checks on customers, rarely requires collateral, and records an allowance that reflects customer-specific risk, aging, historical loss trends, and macro conditions; balances over 90 days are reserved and ultimately written off if collection fails.  Net accounts receivable were 2.17 billion on 06/28/24 (one customer 15 %) versus 1.60 billion on 06/30/23 (two customers 15 % and 13 %), and management considers credit-loss reserves immaterial, indicating high-quality receivables.\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Q: For GPN, what was the fair value of share awards vested in 2009?\n",
      "A: 6.2\n",
      "Q: what was the value in 2007?\n",
      "A: 1.7\n",
      "Q: what was the net change in value?\n",
      "A: A0\n",
      "Q: what is the net change divided by the 2007 value?\n",
      "Generated Answer: 2.65\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Q: For Apple Inc., what was the difference between the net sales of 2011 and 2010, in millions?\n",
      "A: A0\n",
      "Q: how much, in percentage, does that difference represent in relation to the total net sales of 2010, counted in millions?\n",
      "Generated Answer: 66%\n",
      "--------------------------------------------------------------------------------\n",
      "Question: what was the cost per tower in American Tower‚Äôs colombia movil acquisition?\n",
      "Generated Answer: I don‚Äôt know\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Q: what was the fair value of the msr reported by Citigroup in 2008?\n",
      "A: 4273\n",
      "Q: and what was it in 2007?\n",
      "Generated Answer: 6392\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Q: what is the implicit interest cost rate reported by Entergy in 2016?\n",
      "A: 5.13\n",
      "Q: what is the rate divided by 100?\n",
      "A: A0\n",
      "Q: what is the value of lease payments due after 2021?\n",
      "A: 257812\n",
      "Q: what is the product of the rate and those payments?\n",
      "Generated Answer: 13225.7556\n",
      "--------------------------------------------------------------------------------\n",
      "Question: what was the percentage change in total trade receivables net from 2015 to 2016 for Fidelity National Information Services?\n",
      "Generated Answer: I don‚Äôt know\n",
      "--------------------------------------------------------------------------------\n",
      "Question: R&D expense as a % of net product revs for VRTX in 2023.\n",
      "Generated Answer: I don‚Äôt know\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Q: For CME, what was the total value of outstanding balance in 2011?\n",
      "A: A0\n",
      "Q: what was the number of shares in 2012?\n",
      "A: 1913527\n",
      "Q: and what was the weighted average grant date fair value of each of these shares?\n",
      "A: 54\n",
      "Q: what was, then, the total value of those shares, or the total value of outstanding balance?\n",
      "A: A1\n",
      "Q: and what is, then, the change in this total value of outstanding balance form 2011 to 2012?\n",
      "A: A2\n",
      "Q: how much does this change represent in relation to that total value in 2011, in percentage?\n",
      "Generated Answer: 26.54%\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Q: For Humana Inc. what was the amount per share paid in 2018?\n",
      "A: 1.90\n",
      "Q: what was the amount paid per share in 2017?\n",
      "A: 1.49\n",
      "Q: what is the ratio of the payments made from 2018 to 2017?\n",
      "Generated Answer: 1.28\n",
      "--------------------------------------------------------------------------------\n",
      "Question: For AES corporation, what percentage of non-recourse debt is current as of december 31 , 2010?\n",
      "Generated Answer: 11%\n",
      "--------------------------------------------------------------------------------\n",
      "Question: % of part-time workforce and flexibility in labor costs for SPG.\n",
      "Generated Answer: Part-time employees represent about 0.6% of SPG‚Äôs workforce (47 of 7,411 employees), and with just 34% of the workforce under union contracts that do not expire until 2026‚Äì2027, the company maintains considerable flexibility to manage and adjust its labor costs.\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Q: What was the change in total regulatory liabilities from 2017 to 2018 for American Water Works?\n",
      "A: A0\n",
      "Q: and what were those total regulatory liabilities in 2017?\n",
      "A: 1664\n",
      "Q: how much, then, does that change represent in relation to this 2017 amount?\n",
      "Generated Answer: 0.0625\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Competitor mix impact on pricing & positioning for NRG Energy (NRG).\n",
      "Generated Answer: NRG competes against a wide mix of regulated utilities, independent power producers, retail energy providers, and new entrants that often have greater scale, financial resources, or government subsidies for renewables (Tee41a440). This diverse competitor set intensifies price pressure and forces NRG to position itself on the ability to generate and market electricity at lower cost, secure transmission capacity, and continually invest in technology and customer service to differentiate its retail offerings.\n",
      "--------------------------------------------------------------------------------\n",
      "Question: For INTC, as of december 292017 what was the percent of the net cash provided by ( used for ) financing activities to the net cash provided by operating activities\n",
      "Generated Answer: -48.3%\n",
      "--------------------------------------------------------------------------------\n",
      "Question: For Citigroup, what was the percentage discount given in the reset of convertible preferred stock issued in the private offering ?\n",
      "Generated Answer: 16.67%\n",
      "--------------------------------------------------------------------------------\n",
      "Question: AEP's EPS FY23 recon check: basic EPS vs net inc.\n",
      "Generated Answer: Basic EPS for FY23 is 3.14, calculated by dividing net income available to common stockholders (1,491) by the weighted-average basic shares outstanding (475.089 million), i.e., 1,491 √∑ 475.089 ‚âà 3.14.\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Howmet Aerospace CBA expiry & UAW coverage at Whitehall, MI; ticker at end.\n",
      "Generated Answer: The UAW collective bargaining agreement at Howmet‚Äôs Whitehall, Michigan plant covers about 1,400 employees and expires on April 1 2028. HWM\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Q: what was the value of net revenue in 2007 for Entergy Mississippi?\n",
      "A: 486.9\n",
      "Q: and in 2006?\n",
      "Generated Answer: I don‚Äôt know\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Feb 23 signature date for Wynn governance board continuity.\n",
      "Generated Answer: February 23, 2024\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Marsh & McLennan's cybersecurity risk mitigation framework outlines the fin. impacts associated with its strategies, specifically for ticker.\n",
      "Generated Answer: MMC\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üîç Evaluating FinQA subset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226b3a89544c46e9901e74a26b147f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llm_context_precision_with_reference': 0.5500, 'non_llm_context_precision_with_reference': 0.0333, 'context_recall': 0.1250, 'non_llm_context_recall': 0.0500, 'context_entity_recall': 0.0000, 'faithfulness': 0.3056, 'nv_accuracy': 0.3000, 'string_present': 0.3000}\n",
      "\n",
      "üîç Evaluating FinDER subset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7595b82348e64959a065199e763f79bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-b9EC73CxcpNUA7w9Zh1KhBEH on tokens per min (TPM): Limit 30000, Used 30000, Requested 571. Please try again in 1.142s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Skipping a sample by assigning it nan score.\n",
      "An error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-b9EC73CxcpNUA7w9Zh1KhBEH on tokens per min (TPM): Limit 30000, Used 30000, Requested 771. Please try again in 1.542s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Skipping a sample by assigning it nan score.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.5358, 'nv_accuracy': 0.4062}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = ChatGPTGenerator()\n",
    "\n",
    "# Load gold test data\n",
    "with open(\"../data/data_processed/Train_Val_Test/gold_test_data_updated.json\") as f:\n",
    "    gold_data = json.load(f)\n",
    "\n",
    "df_meta = pd.read_parquet(OUT_DIR / \"chunk_meta.parquet\")\n",
    "all_docs = df_meta.to_dict(orient=\"records\")  # becomes list of dicts with 'text' key\n",
    "\n",
    "# Load FAISS index#\n",
    "OUT_DIR = Path(\"outputs/2025-08-01\")   \n",
    "faiss_index = FAISS.load_local(\n",
    "    folder_path=OUT_DIR,\n",
    "    embeddings=embedder,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Separate datasets\n",
    "finqa_eval_dataset = []\n",
    "finder_eval_dataset = []\n",
    "\n",
    "finqa_count = 0\n",
    "finder_count = 0\n",
    "\n",
    "for sample in gold_data:\n",
    "    if finqa_count >= 10 and finder_count >= 10:\n",
    "        break\n",
    "\n",
    "    question = sample[\"question\"]\n",
    "    reference = sample[\"answer\"]\n",
    "    gold_context = sample.get(\"gold_context\", {})\n",
    "\n",
    "    # Embed and search\n",
    "    query_embedding = np.array(embedder.embed_query(question), dtype=\"float32\").reshape(1, -1)\n",
    "    D, I = faiss_index.index.search(query_embedding, 10)\n",
    "    candidate_texts = [all_docs[i] for i in I[0] if \"text\" in all_docs[i]]\n",
    "\n",
    "    # Rerank\n",
    "    reranked_docs = CrossEncoderReranker().rerank(question, candidate_texts, top_k=5)\n",
    "\n",
    "    # Generate\n",
    "    response = generator.generate(question, [doc[\"text\"] for doc in reranked_docs])\n",
    "    print(\"Question:\", question)\n",
    "    print(\"Generated Answer:\", response)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Determine reference contexts\n",
    "    reference_contexts = []\n",
    "    if isinstance(gold_context, dict):\n",
    "        reference_contexts = list(gold_context.values())\n",
    "    elif isinstance(gold_context, str) and gold_context.strip():\n",
    "        reference_contexts = [gold_context.strip()]\n",
    "\n",
    "    record = {\n",
    "        \"user_input\": question,\n",
    "        \"retrieved_contexts\": [doc[\"text\"] for doc in reranked_docs],\n",
    "        \"response\": response,\n",
    "        \"reference\": reference,\n",
    "    }\n",
    "\n",
    "    # Append based on presence of gold context\n",
    "    if reference_contexts and finqa_count < 10:\n",
    "        record[\"reference_contexts\"] = reference_contexts\n",
    "        finqa_eval_dataset.append(record)\n",
    "        finqa_count += 1\n",
    "    elif not reference_contexts and finder_count < 10:\n",
    "        finder_eval_dataset.append(record)\n",
    "        finder_count += 1\n",
    "\n",
    "# Evaluate\n",
    "import asyncio\n",
    "\n",
    "print(\"\\nüîç Evaluating FinQA subset...\")\n",
    "finqa_results = asyncio.run(evaluate_ragas_dataset(finqa_eval_dataset))\n",
    "print(finqa_results)\n",
    "\n",
    "print(\"\\nüîç Evaluating FinDER subset...\")\n",
    "finder_results = asyncio.run(evaluate_ragas_dataset(\n",
    "    finder_eval_dataset,\n",
    "    metrics_list=[\"faithfulness\", \"answer_accuracy\"]\n",
    "))\n",
    "print(finder_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c5535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.7500, 'nv_accuracy': 0.7500}\n"
     ]
    }
   ],
   "source": [
    "print(finder_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceda229",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_ceiling_performance(\n",
    "    #train_path=\"/Users/christel/Desktop/Thesis/thesis_repo/data/data_processed/Train_Val_Test/df_test.json\",\n",
    "    # data/data_processed/Train_Val_Test/gold_test_data.json\n",
    "    num_samples=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Test ceiling performance using gold context, limited to FinQA-only samples.\n",
    "    \"\"\"\n",
    "    # Load and filter dataset\n",
    "    train_data = load_train_data(train_path)\n",
    "    train_data = [s for s in train_data if s.get(\"source\") == \"FinQA\" or s.get(\"source\") == \"ConvFinQA\"]\n",
    "\n",
    "    # Apply sample limit *after* filtering\n",
    "    if num_samples:\n",
    "        train_data = train_data[num_samples:num_samples+10]\n",
    "\n",
    "    # Instantiate generator (prompts now handled internally)\n",
    "    generator = ChatGPTGenerator()\n",
    "\n",
    "    dataset = []\n",
    "    print(\"\\nProcessing samples...\")\n",
    "\n",
    "    for i, sample in enumerate(train_data, 1):\n",
    "        question = sample[\"question\"]\n",
    "        true_answer = sample[\"answer\"]\n",
    "        source = sample.get(\"source\", \"Unknown\")\n",
    "\n",
    "        relevant_context = get_gold_context(sample)\n",
    "        # get real dataset results\n",
    "        \n",
    "\n",
    "        start = time.time()\n",
    "        generated_answer = generator.generate(\n",
    "            question=question,\n",
    "            retrieved_docs=[relevant_context],\n",
    "        )\n",
    "        end = time.time()\n",
    "\n",
    "        dataset.append({\n",
    "            \"user_input\": question,\n",
    "            \"retrieved_contexts\": [relevant_context],\n",
    "            \"response\": generated_answer,\n",
    "            \"reference\": true_answer\n",
    "        })\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"Source: {source}\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Gold Context: {relevant_context}\")\n",
    "        print(f\"Generated Answer: {generated_answer}\")\n",
    "        print(f\"True Answer: {true_answer}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    # Evaluate with RAGAS\n",
    "    metrics_list = [\"answer_accuracy\", \"string_presence\"]\n",
    "    print(\"\\nEvaluating ceiling performance...\")\n",
    "    results = await evaluate_ragas_dataset(dataset, metrics_list=metrics_list)\n",
    "\n",
    "    print(\"\\nCeiling Performance Results:\")\n",
    "    print(results)\n",
    "\n",
    "    # Additional stats\n",
    "    total_samples = len(dataset)\n",
    "    exact_matches = sum(1 for sample in dataset if sample['response'].strip() == sample['reference'].strip())\n",
    "\n",
    "    print(\"\\nAdditional Statistics:\")\n",
    "    print(f\"Total Samples: {total_samples}\")\n",
    "    print(f\"Exact Matches: {exact_matches}\")\n",
    "    print(f\"Exact Match Rate: {exact_matches / total_samples:.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(test_ceiling_performance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latency logging in retriever required"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin_rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
